# ========================
# CLEAN GPU/TF HEADER (Windows-safe)
# ========================
import os, sys, json, time, gc
import numpy as np
import tensorflow as tf
import cv2, tifffile
import matplotlib.pyplot as plt
import os, tensorflow as tf

print("[TF]", tf.__version__)
print("[Devices]", tf.config.list_physical_devices())
print("[GPUs]", tf.config.list_physical_devices("GPU"))

# DirectML: let memory grow on demand
for g in tf.config.list_physical_devices('GPU'):
    try:
        tf.config.experimental.set_memory_growth(g, True)
    except Exception as e:
        print("set_memory_growth failed:", e)

# Optional: log where ops run (chatty)
# tf.debugging.set_log_device_placement(True)
# --------- Environment (set BEFORE importing TF) ----------
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"
os.environ["TF_GPU_THREAD_MODE"] = "gpu_private"
os.environ["TF_GPU_THREAD_COUNT"] = "2"
os.environ["TF_FORCE_GPU_ALLOW_GROWTH"] = "true"
os.environ["TF_GPU_ALLOCATOR"] = "cuda_malloc_async"      # TF>=2.10
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"                 # fewer surprises on Windows
os.environ["TF_DETERMINISTIC_OPS"] = "1"
os.environ["TF_JIT_DISABLE"] = "1"                        # keep XLA/JIT off on Windows
# DO NOT set TF_ENABLE_EAGER_EXECUTION (TF2 already eager)
# DO NOT set TF_XLA_FLAGS unless you really need XLA

# Optional quick test: to force CPU for a run, uncomment the next line
# os.environ["CUDA_VISIBLE_DEVICES"] = "-1"

# --------- NumPy & friends ----------
import numpy as np
print(f"‚úÖ NumPy {np.__version__} loaded", flush=True)

import pandas as pd
import cv2
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from scipy import ndimage
from scipy.linalg import sqrtm
from scipy.spatial import cKDTree
import tifffile, json
from collections import OrderedDict
# --------- TensorFlow (single import, after env) ----------
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import backend as K
_TF_DEVICES_FROZEN = False
# ===== GPU SANITY CHECK =====
try:
    print("\n===== GPU SANITY CHECK =====")
    print("TF version:", tf.__version__)
    phys_gpus = tf.config.experimental.list_physical_devices('GPU')
    logi_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(f"Physical GPUs: {len(phys_gpus)} | Logical GPUs: {len(logi_gpus)}")

    # Print detailed GPU info if available
    for i, lg in enumerate(logi_gpus):
        try:
            det = tf.config.experimental.get_device_details(lg)
            print(f"  ‚Ä¢ /GPU:{i} ->", det.get('device_name', 'unknown'))
        except Exception:
            print(f"  ‚Ä¢ /GPU:{i}")

    # Quick matmul timing on GPU vs CPU
    import time
    N = 2048
    a = tf.random.normal([N, N])
    b = tf.random.normal([N, N])

    # Warmup (graph build)
    _ = tf.matmul(a, b)

    t0 = time.time()
    with tf.device('/GPU:0'):
        _ = tf.matmul(a, b)
    t_gpu = time.time() - t0

    t0 = time.time()
    with tf.device('/CPU:0'):
        _ = tf.matmul(a, b)
    t_cpu = time.time() - t0

    print(f"MatMul 2048x2048 ‚Äî GPU: {t_gpu:.3f}s | CPU: {t_cpu:.3f}s")
    print("‚úÖ GPU appears ACTIVE" if t_gpu < t_cpu else "‚ö†Ô∏è GPU not faster than CPU (driver/CUDA mismatch?)")
    print("============================================\n")
except Exception as e:
    print(f"‚ö†Ô∏è GPU check failed: {e}\n")
# === ADD AFTER: import tensorflow.keras.backend as K ===
class SpectralNorm(layers.Wrapper):
    """Spectral Normalization for Keras layers with a kernel (Conv/Dense)."""
    def __init__(self, layer, power_iterations=1, **kwargs):
        super().__init__(layer, **kwargs)
        self.power_iterations = int(power_iterations)
        self.u = None
        self.w_shape = None

    def build(self, input_shape):
        # Build the wrapped layer first so `.kernel` exists
        super().build(input_shape)
        if not hasattr(self.layer, "kernel"):
            raise ValueError("SpectralNorm can only wrap layers that have a 'kernel' (Conv/Dense).")

        self.w_shape = K.int_shape(self.layer.kernel)  # e.g. (kh, kw, in_ch, out_ch) or (in, out)
        out_dim = self.w_shape[-1]

        # u is the persistent left singular vector estimate
        self.u = self.add_weight(
            name="sn_u",
            shape=(1, out_dim),
            initializer=tf.random_normal_initializer(stddev=0.02),
            trainable=False
        )

    def call(self, inputs, training=None):
        w = self.layer.kernel
        w_mat = K.reshape(w, (-1, self.w_shape[-1]))  # [N, out_dim]

        u = self.u
        for _ in range(self.power_iterations):
            v = tf.math.l2_normalize(K.dot(u, K.transpose(w_mat)))   # [1, N]
            u = tf.math.l2_normalize(K.dot(v, w_mat))                # [1, out_dim]

        # œÉ = u * W * v^T (scalar)
        sigma = K.dot(K.dot(v, w_mat), K.transpose(u))
        w_sn = w / sigma

        # Assign normalized weights to the wrapped layer
        self.layer.kernel.assign(w_sn)

        return self.layer(inputs, training=training)
def freeze_tf_devices_once():
    """Call exactly once early; never call set_memory_growth later."""
    global _TF_DEVICES_FROZEN
    if _TF_DEVICES_FROZEN:
        return
    try:
        gpus = tf.config.experimental.list_physical_devices('GPU')
        for g in gpus:
            try:
                tf.config.experimental.set_memory_growth(g, True)
            except Exception:
                # Already initialized -> ignore to avoid: 'Visible devices cannot be modified...'
                pass
    except Exception:
        pass
    _TF_DEVICES_FROZEN = True

# call it immediately after imports, before any model/tensor is created
freeze_tf_devices_once()
print(f"üîß TensorFlow {tf.__version__} importing done", flush=True)
# --- Determinism requires seeds for all RNGs ---
def set_global_seed(seed: int = 42):
    import random as _random, numpy as _np, tensorflow as _tf
    _random.seed(seed); _np.random.seed(seed); _tf.random.set_seed(seed)

set_global_seed(42)
# --------- Threading & memory growth ----------
try:
    tf.config.threading.set_intra_op_parallelism_threads(2)
    tf.config.threading.set_inter_op_parallelism_threads(2)
except Exception:
    pass

def _enable_gpu_memory_growth():
    try:
        gpus = tf.config.list_physical_devices("GPU")
        if gpus:
            for g in gpus:
                try:
                    tf.config.experimental.set_memory_growth(g, True)
                except Exception:
                    pass
            print(f"‚úÖ GPU memory growth enabled for {len(gpus)} GPU(s)", flush=True)
        else:
            print("‚ÑπÔ∏è No GPU detected ‚Äî running on CPU", flush=True)
    except Exception as e:
        print(f"‚ö†Ô∏è Could not configure GPU memory growth: {e}", flush=True)

_enable_gpu_memory_growth()

# --------- Precision policy (float32; flip later if stable) ----------
try:
    from tensorflow.keras import mixed_precision
    mixed_precision.set_global_policy("float32")
    print("‚úÖ Global precision: float32", flush=True)
except Exception as e:
    print(f"‚ö†Ô∏è Mixed precision policy set failed: {e}", flush=True)
# ========= Add-back imports & safe fallbacks (paste after the header) =========

# Common stdlib helpers used later
from dataclasses import dataclass
from functools import lru_cache

# Optional libs used by exports/visuals (guarded)
try:
    import meshio
    MESHIO_AVAILABLE = True
except Exception:
    MESHIO_AVAILABLE = False

try:
    import pyvista as pv
    PYVISTA_AVAILABLE = True
except Exception:
    PYVISTA_AVAILABLE = False

try:
    from pyacvd import Clustering
    PYACVD_AVAILABLE = True
except Exception:
    PYACVD_AVAILABLE = False

# ---- scikit-image operators or compatible fallbacks ----
# If skimage is available, use it; otherwise define light replacements.
try:
    from skimage.morphology import ball as _sk_ball, binary_closing as _sk_bclose, \
                                     binary_opening as _sk_bopen, remove_small_objects as _sk_rso
    from skimage.measure import label as _sk_label
    SKIMAGE_AVAILABLE = True

    def ball(r=3):                   return _sk_ball(r)
    def binary_closing(x, st=None):  return _sk_bclose(x, footprint=st)
    def binary_opening(x, st=None):  return _sk_bopen(x, footprint=st)
    def remove_small_objects(x, min_size=64): return _sk_rso(x, min_size=min_size)
    def label(x):                    return _sk_label(x)
except Exception:
    SKIMAGE_AVAILABLE = False
    from scipy.ndimage import binary_closing as _bc, binary_opening as _bo, label as _lb

    def ball(radius=3):
        coords = np.arange(-radius, radius + 1)
        z, y, x = np.meshgrid(coords, coords, coords, indexing="ij")
        return (z*z + y*y + x*x) <= radius*radius

    def binary_closing(image, structure=None): return _bc(image, structure=np.ones((3,3,3)) if structure is None else structure)
    def binary_opening(image, structure=None): return _bo(image, structure=np.ones((3,3,3)) if structure is None else structure)
    def remove_small_objects(ar, min_size=64):
        labeled, _ = _lb(ar)
        sizes = np.bincount(labeled.ravel())
        mask = sizes < min_size
        out = ar.copy()
        out[mask[labeled]] = 0
        return out
    def label(image): return _lb(image)[0]

# Binary hole fill (scipy name differs from skimage)
from scipy.ndimage import binary_fill_holes as binary_fill_holes_3d

# Frequently used ndimage op (spelled explicitly later)
from scipy.ndimage import gaussian_filter

# Small utils used later in visuals/exports
def clear_gpu_memory():
    try:
        K.clear_session()
    except Exception:
        pass
    gc.collect()
    print("üßπ TF session cleared", flush=True)

def save_png_grid(stack, grid=(4, 4), tile_size=64, out_path="grid.png"):
    s = stack[..., 0] if (stack.ndim == 4 and stack.shape[-1] == 1) else stack
    s = s.astype(np.float32)
    s = (s - s.min()) / (s.max() - s.min() + 1e-8)
    N = s.shape[0]
    rows, cols = grid
    canvas = np.zeros((rows * tile_size, cols * tile_size), dtype=np.float32)
    n = min(N, rows * cols)
    for idx in range(n):
        r, c = divmod(idx, cols)
        tile = cv2.resize(s[idx], (tile_size, tile_size), interpolation=cv2.INTER_AREA)
        canvas[r*tile_size:(r+1)*tile_size, c*tile_size:(c+1)*tile_size] = tile
    cv2.imwrite(out_path, (np.clip(canvas, 0, 1) * 255).astype(np.uint8))
# --------- Quick non-blocking device smoke (with timeout) ----------
def quick_gpu_test(timeout_sec=5):
    if not tf.config.list_physical_devices("GPU"):
        return False
    import threading
    ok = {"v": False}
    def _job():
        try:
            with tf.device("/GPU:0"):
                g = tf.random.Generator.from_seed(42)
                a = g.normal((512, 512))
                b = g.normal((512, 512))
                _ = tf.reduce_sum(tf.matmul(a, b)).numpy()
            ok["v"] = True
        except Exception:
            ok["v"] = False
    t = threading.Thread(target=_job, daemon=True)
    t.start(); t.join(timeout=timeout_sec)
    print(("‚úÖ Basic GPU matmul OK" if ok["v"] else "‚õî GPU smoke timed out ‚Äî prefer CPU this run"),
          flush=True)
    return ok["v"]

GPU_OK = quick_gpu_test()

# --------- Small helpers ----------
def clear_tf_memory():
    try: K.clear_session()
    except: pass
    gc.collect()
    print("üßπ TF session cleared", flush=True)

def optimize_batch_size_for_gpu(base_batch_size=32):
    try:
        info = tf.config.experimental.get_memory_info("GPU:0")
        avail = info.get("available", 0)
        return base_batch_size * 2 if avail and avail > 6e9 else base_batch_size
    except Exception:
        return base_batch_size

print("üéâ Utilities & GPU setup ready.", flush=True)

if __name__ == "__main__":
    print("‚ñ∂Ô∏è  Sanity run starting...", flush=True)
    # 1) confirm device policy
    print("Devices:", tf.config.list_physical_devices(), flush=True)
    # 2) quick CPU matmul (deterministic)
    with tf.device("/CPU:0"):
        g = tf.random.Generator.from_seed(42)
        x = g.normal((1024,1024))
        y = g.normal((1024,1024))
        _ = tf.reduce_sum(tf.matmul(x, y)).numpy()
    print("‚úÖ CPU matmul OK", flush=True)
    # 3) quick GPU if available (non-blocking already done)
    if GPU_OK:
        with tf.device("/GPU:0"):
            x = tf.random.normal((1024,1024)); y = tf.random.normal((1024,1024))
            _ = tf.reduce_sum(tf.matmul(x,y)).numpy()
        print("‚úÖ GPU matmul OK (post-header)", flush=True)
    print("‚úÖ Header sanity complete ‚Äî continue to data & training‚Ä¶", flush=True)
# ========================
# PROJECT DIRS / UTILITIES
# ========================
# --- ensure_project_dirs (guarded) ---
if 'ensure_project_dirs' not in globals():
    def ensure_project_dirs(base_path):
        d = {
            "Training_Data": os.path.join(base_path, "Training_Data"),
            "Visualisations": os.path.join(base_path, "Visualisations"),
            "tiff_stack": os.path.join(base_path, "tiff_stack"),
            "abaqus": os.path.join(base_path, "abaqus"),
        }
        for p in d.values():
            os.makedirs(p, exist_ok=True)
        return d

if 'save_png_grid' not in globals():
    def save_png_grid(tiles, grid=(4,4), tile_size=64, out_path="grid.png"):
        import numpy as _np, cv2 as _cv2
        r, c = grid
        H, W = r*tile_size, c*tile_size
        canvas = _np.zeros((H, W), dtype=_np.uint8)
        tiles01 = tiles[..., 0] if tiles.ndim == 4 else tiles
        idx = 0
        for i in range(r):
            for j in range(c):
                if idx >= len(tiles01): break
                t = tiles01[idx]
                t = (np.clip(t,0,1)*255).astype(np.uint8)
                t = _cv2.resize(t, (tile_size, tile_size), interpolation=_cv2.INTER_AREA)
                canvas[i*tile_size:(i+1)*tile_size, j*tile_size:(j+1)*tile_size] = t
                idx += 1
        _cv2.imwrite(out_path, canvas)

# --- JSON encoder for numpy (added) ---
class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        try:
            import numpy as _np
            if isinstance(obj, (_np.floating, _np.integer)):
                return obj.item()
        except Exception:
            pass
        return super().default(obj)

def quick_inp_sanity(path):
    ok = True
    need = ["*PART", "*NODE", "*ELEMENT", "*ELSET", "*MATERIAL", "*STEP"]
    s = open(path, "r", encoding="utf-8", errors="ignore").read().upper()
    missing = [t for t in need if t not in s]
    if missing:
        print("‚ùå Missing sections:", missing); ok = False
    if "TYPE=C3D8" not in s:
        print("‚ö†Ô∏è No C3D8 found"); ok = False
    print("‚úÖ INP basic sanity passed" if ok else "‚ö†Ô∏è INP needs fixes")
    return ok

def clear_gpu_memory():
    """Release graphs and trigger GC; safe on CPU-only too."""
    try:
        K.clear_session()
    except Exception:
        pass
    gc.collect()
    print("üßπ TF session cleared")

def optimize_batch_size_for_gpu(base_batch_size=32):
    """Heuristic based on memory info; returns base if not available."""
    try:
        info = tf.config.experimental.get_memory_info("GPU:0")
        avail = info.get("available", 0)
        return base_batch_size * 2 if avail and avail > 6e9 else base_batch_size
    except Exception:
        return base_batch_size

# ========================
# scikit-image REPLACEMENTS (minimal)
# ========================
def ball(radius=3):
    coords = np.arange(-radius, radius + 1)
    z, y, x = np.meshgrid(coords, coords, coords, indexing="ij")
    return (z*z + y*y + x*x) <= radius*radius

def binary_closing(image, structure=None):
    from scipy.ndimage import binary_closing as _bc
    return _bc(image, structure=np.ones((3, 3)) if structure is None else structure)

def binary_opening(image, structure=None):
    from scipy.ndimage import binary_opening as _bo
    return _bo(image, structure=np.ones((3, 3)) if structure is None else structure)

def remove_small_objects(ar, min_size=64, connectivity=1):
    from scipy.ndimage import label as _label
    labeled, _ = _label(ar)
    sizes = np.bincount(labeled.ravel())
    mask = sizes < min_size
    out = ar.copy()
    out[mask[labeled]] = 0
    return out

def label(image):
    from scipy.ndimage import label as _label
    return _label(image)

gaussian_filter = ndimage.gaussian_filter

def sobel(image):
    return cv2.Sobel(image, cv2.CV_64F, 1, 1, ksize=3)

def canny(image, sigma=1.0):
    return cv2.Canny((image * 255).astype(np.uint8), 50, 150)

print("üéâ Utilities & GPU setup ready.")

def binary_fill_holes(input):
    """Replace skimage.morphology.binary_fill_holes"""
    from scipy.ndimage import binary_fill_holes as scipy_fill_holes
    return scipy_fill_holes(input)

# Optional imports
try:
    import pyvista as pv
    PYVISTA_AVAILABLE = True
except ImportError:
    PYVISTA_AVAILABLE = False
    print("‚ö†Ô∏è PyVista not available, some mesh features disabled")

try:
    from pyacvd import Clustering
    PYACVD_AVAILABLE = True
except ImportError:
    PYACVD_AVAILABLE = False
    print("‚ö†Ô∏è PyACVD not available, mesh simplification disabled")

print("üéâ All imports and replacements ready!")


# ========================
# GPU-OPTIMIZED TRAINING UTILITIES
# ========================
# --- Safe stub: force_gpu_detection (idempotent) ---
def force_gpu_detection(verbose=True):
    """Return True if a GPU is visible and usable; configure memory growth."""
    try:
        gpus = tf.config.list_physical_devices('GPU')
        if verbose:
            print("üìã All physical devices:")
            for d in tf.config.list_physical_devices():
                print(f"  - {d}")
            print(f"üéØ GPU devices detected: {len(gpus)}")

        if gpus:
            # enable memory growth (safe to call more than once)
            for g in gpus:
                try:
                    tf.config.experimental.set_memory_growth(g, True)
                except Exception:
                    pass
            # quick matmul to confirm we can place work on GPU
            try:
                with tf.device('/GPU:0'):
                    a = tf.random.normal((256, 256))
                    b = tf.random.normal((256, 256))
                    _ = tf.reduce_sum(tf.matmul(a, b)).numpy()
                if verbose:
                    print("‚úÖ GPU detection & test OK")
                return True
            except Exception as e:
                if verbose:
                    print(f"‚ö†Ô∏è GPU visible but test failed: {e}")
                return False
        else:
            if verbose:
                print("‚ÑπÔ∏è No GPU detected")
            return False
    except Exception as e:
        if verbose:
            print(f"‚ö†Ô∏è force_gpu_detection error: {e}")
        return False
@tf.function  # Enable XLA compilation
def gpu_optimized_train_step(model, x, y):
    """XLA-optimized training step for maximum GPU utilization"""
    with tf.GradientTape() as tape:
        predictions = model(x, training=True)
        loss = tf.keras.losses.categorical_crossentropy(y, predictions)
    gradients = tape.gradient(loss, model.trainable_variables)
    model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    return loss

class GPUMemoryMonitor(tf.keras.callbacks.Callback):
    """Monitor GPU memory usage during training"""
    def on_epoch_begin(self, epoch, logs=None):
        if tf.config.list_physical_devices('GPU'):
            gpu_info = tf.config.experimental.get_memory_info('GPU:0')
            print(f"üéØ Epoch {epoch+1} - GPU Memory: {gpu_info['current'] / 1e9:.2f}GB / {gpu_info['peak'] / 1e9:.2f}GB")

def create_gpu_optimized_dataset(patches, labels, batch_size=32):
    """Create GPU-optimized dataset pipeline"""
    dataset = tf.data.Dataset.from_tensor_slices((patches, labels))
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(tf.data.AUTOTUNE)
    dataset = dataset.cache()
    return dataset
# ========================
# GPU MEMORY MANAGEMENT
# ========================

def clear_gpu_memory():
    """Clear GPU memory between training sessions"""
    K.clear_session()
    import gc
    gc.collect()

    # Clear TensorFlow GPU memory
    if tf.config.list_physical_devices('GPU'):
        try:
            # Force TensorFlow to release GPU memory
            tf.compat.v1.reset_default_graph()
            for device in tf.config.list_physical_devices('GPU'):
                tf.config.experimental.set_memory_growth(device, True)
        except:
            pass

def optimize_training_for_gpu(batch_size=32):
    """Optimize training parameters for GPU"""
    # Adjust batch size based on available GPU memory
    if strategy.num_replicas_in_sync > 1:
        effective_batch_size = batch_size * strategy.num_replicas_in_sync
        print(f"üîß Multi-GPU: Effective batch size = {effective_batch_size}")
        return effective_batch_size
    else:
        print(f"üîß Single GPU: Using batch size = {batch_size}")
        return batch_size


# Quick GPU test
print("üß™ Testing GPU acceleration...")
with tf.device('/GPU:0'):
    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])
    b = tf.constant([[1.0, 1.0], [0.0, 1.0]])
    c = tf.matmul(a, b)
    print(f"‚úÖ GPU test passed: Matrix multiplication result shape: {c.shape}")
def clear_tf_memory():
    """Clear TensorFlow memory to prevent OOM errors"""
    K.clear_session()
    gc.collect()

    # Force GPU memory cleanup
    if tf.config.list_physical_devices('GPU'):
        try:
            for gpu in tf.config.list_physical_devices('GPU'):
                tf.config.experimental.set_memory_growth(gpu, True)
        except:
            pass
# -------------------------
# Core Helper Functions
# -------------------------
def quick_forward_check(model, x_np, y_np):
    """
    Runs a tiny forward pass on 1 sample to confirm graph works.
    Returns (ok: bool, loss: float or None)
    """
    try:
        x1 = x_np[:1].astype("float32")
        y1 = y_np[:1].astype("float32")
        yhat = model(x1, training=False)
        loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y1, yhat))
        return True, float(loss.numpy())
    except Exception:
        return False, None
def set_global_seed(seed: int = 42):
    """Deterministic runs across numpy/tensorflow/python hash."""
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)

def safe_makedirs(path: str):
    os.makedirs(path, exist_ok=True)

def normalize01(x, eps=1e-8):
    x = x.astype(np.float32)
    mn, mx = np.min(x), np.max(x)
    return (x - mn) / (mx - mn + eps)

def clip01(x):
    return np.clip(x, 0.0, 1.0).astype(np.float32)

def robust_minmax_match(src, ref, eps=1e-6):
    """Histogram match using percentile anchors for robustness."""
    s1, s99 = np.percentile(src, 1), np.percentile(src, 99)
    r1, r99 = np.percentile(ref, 1), np.percentile(ref, 99)
    out = (src - s1) / (s99 - s1 + eps)
    return clip01(out) * (r99 - r1) + r1

def patchify_2d(img, patch_size=64, stride=64):
    """Return (N, H, W) patches + (y,x) positions."""
    H, W = img.shape[:2]
    ps, st = patch_size, stride
    patches, pos = [], []
    for y in range(0, max(H-ps+1, 1), st):
        for x in range(0, max(W-ps+1, 1), st):
            yy, xx = min(y, H-ps), min(x, W-ps)
            patches.append(img[yy:yy+ps, xx:xx+ps])
            pos.append((yy, xx))
    return np.stack(patches, 0), pos

def gaussian3d_kernel(size=5, sigma=1.0):
    ax = np.arange(-size//2 + 1., size//2 + 1.)
    xx, yy, zz = np.meshgrid(ax, ax, ax, indexing="ij")
    k = np.exp(-(xx**2 + yy**2 + zz**2)/(2.*sigma**2))
    return k / np.sum(k)

# -------------------------
# Advanced Quality Metrics
# -------------------------

def calculate_fid_score(real_images, generated_images):
    """Calculate FID score exactly as in paper"""
    try:
        from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input
        # Load pre-trained InceptionV3
        inception = InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))

        # Preprocess images
        def preprocess_images(images):
            if images.ndim == 3:
                images = np.stack([images]*3, axis=-1)
            images_resized = np.array([cv2.resize(img, (299, 299)) for img in images])
            return preprocess_input(images_resized)

        real_processed = preprocess_images(real_images)
        gen_processed = preprocess_images(generated_images)

        # Get features
        real_features = inception.predict(real_processed, verbose=0)
        gen_features = inception.predict(gen_processed, verbose=0)

        # Calculate FID
        mu_real, sigma_real = real_features.mean(axis=0), np.cov(real_features, rowvar=False)
        mu_gen, sigma_gen = gen_features.mean(axis=0), np.cov(gen_features, rowvar=False)

        ssdiff = np.sum((mu_real - mu_gen)**2.0)
        covmean = sqrtm(sigma_real.dot(sigma_gen))

        if np.iscomplexobj(covmean):
            covmean = covmean.real

        fid = ssdiff + np.trace(sigma_real + sigma_gen - 2.0 * covmean)
        return float(fid)
    except ImportError:
        print("‚ö†Ô∏è TensorFlow not available, using simplified FID")
        return calculate_simplified_fid(real_images, generated_images)

def calculate_simplified_fid(real_images, generated_images):
    """Simplified, always-real FID surrogate (no sqrtm)."""
    real_features = real_images.reshape(real_images.shape[0], -1).astype(np.float64)
    gen_features  = generated_images.reshape(generated_images.shape[0], -1).astype(np.float64)

    mu_r, mu_g = real_features.mean(axis=0), gen_features.mean(axis=0)
    cov_r, cov_g = np.cov(real_features, rowvar=False), np.cov(gen_features, rowvar=False)

    ssdiff = np.sum((mu_r - mu_g)**2.0)
    # Frobenius-norm surrogate for covariance cross-term
    cross = cov_r @ cov_g
    cross_term = np.linalg.norm(cross, 'fro')**0.5
    fid = float(ssdiff + np.trace(cov_r + cov_g) - 2.0 * cross_term)
    return fid
class NumpyEncoder(json.JSONEncoder):
    """Custom JSON encoder for numpy data types"""
    def default(self, obj):
        if isinstance(obj, (np.integer, np.int32, np.int64)):
            return int(obj)
        elif isinstance(obj, (np.floating, np.float32, np.float64)):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, (np.bool_)):
            return bool(obj)
        return super().default(obj)

def make_condition_maps(x):
    """
    Build edge/structure condition maps from target SEM patches.
    Input:  x in [0,1], shape (N,64,64,1) float32
    Output: cond in [-1,1], same shape (N,64,64,1)
    """
    x = np.asarray(x, dtype=np.float32)
    if x.ndim == 3:
        x = x[..., None]

    # Sobel magnitude
    gx = cv2.Sobel(x[..., 0], cv2.CV_32F, 1, 0, ksize=3)
    gy = cv2.Sobel(x[..., 0], cv2.CV_32F, 0, 1, ksize=3)
    mag = np.sqrt(gx * gx + gy * gy)

    # Normalize to [0,1] then to [-1,1]
    mag -= mag.min()
    mag /= (mag.max() + 1e-8)
    cond = mag[..., None] * 2.0 - 1.0
    return cond.astype(np.float32)
class RealisticSEMDataGenerator:
    """Generate realistic SEM-like training data from actual mineral maps"""

    def __init__(self, base_path, sample_name):
        self.base_path = base_path
        self.sample_name = sample_name
        self.mineral_processor = AdvancedMineralProcessor("Mineral_quant_all_samples.xlsx")
        self.mineral_processor.load_and_parse_excel()
    def load_and_process_real_sem_data(self, target_patch_size=64):
        """Load and process real SEM data with exact 10x10 division of 1024x1024 images"""
        print("üìä Loading and processing real SEM data with exact patch division...")

        mineral_map = self.load_mineral_map()
        bse_image = self.load_bse_image()

        all_patches = []

        # Process mineral map with exact 10x10 division
        if mineral_map is not None and mineral_map.shape == (1024, 1024):
            print("üéØ Dividing 1024x1024 mineral map into exact 10x10 grid (100 patches)")
            patch_size = 102  # 1024/10 = 102.4, so we use 102 with overlap

            for row in range(10):
                for col in range(10):
                    y_start = min(row * 102, 1024 - patch_size)
                    x_start = min(col * 102, 1024 - patch_size)
                    y_end = y_start + patch_size
                    x_end = x_start + patch_size

                    patch = mineral_map[y_start:y_end, x_start:x_end]

                    # Resize to target patch size if different
                    if patch.shape != (target_patch_size, target_patch_size):
                        patch = cv2.resize(patch, (target_patch_size, target_patch_size),
                                         interpolation=cv2.INTER_AREA)

                    all_patches.append(patch.astype(np.float32))

            print(f"‚úÖ Added {len(all_patches)} mineral map patches")

        # Process BSE image similarly
        if bse_image is not None and bse_image.shape == (1024, 1024):
            print("üéØ Dividing 1024x1024 BSE image into exact 10x10 grid")
            patch_size = 102

            for row in range(10):
                for col in range(10):
                    y_start = min(row * 102, 1024 - patch_size)
                    x_start = min(col * 102, 1024 - patch_size)
                    y_end = y_start + patch_size
                    x_end = x_start + patch_size

                    patch = bse_image[y_start:y_end, x_start:x_end]

                    if patch.shape != (target_patch_size, target_patch_size):
                        patch = cv2.resize(patch, (target_patch_size, target_patch_size),
                                         interpolation=cv2.INTER_AREA)

                    all_patches.append(patch.astype(np.float32))

            print(f"‚úÖ Added {len(all_patches) - 100} BSE image patches")

        if not all_patches:
            print("‚ö†Ô∏è No real patches created, using synthetic data")
            return self.create_synthetic_patches(100, target_patch_size)

        # Convert to numpy array and normalize
        patches_array = np.array(all_patches)
        patches_array = np.expand_dims(patches_array, axis=-1)  # Add channel dimension
        patches_array = normalize01(patches_array)

        print(f"üéØ Final training set: {patches_array.shape[0]} patches of {patches_array[0].shape}")
        return patches_array

    def load_mineral_map(self):
        """Load mineral map; tolerate various file names & folders."""
        sample_folder = os.path.join(self.base_path, self.sample_name)
        candidates = [
            "Mineral_map.tif", "mineral_map.tif", "MineralMap.tif",
            "Mineral_map.tiff", "mineral_map.tiff"
        ]
        # check sample root
        for nm in candidates:
            p = os.path.join(sample_folder, nm)
            if os.path.exists(p):
                mm = tifffile.imread(p)
                print(f"üìä Loaded mineral map: {mm.shape} from {p}")
                return mm
        # check Minerals subfolder, common exports put it there
        minerals_dir = os.path.join(sample_folder, "Minerals")
        if os.path.isdir(minerals_dir):
            for f in os.listdir(minerals_dir):
                if "mineral" in f.lower() and "map" in f.lower() and f.lower().endswith((".tif",".tiff")):
                    p = os.path.join(minerals_dir, f)
                    mm = tifffile.imread(p)
                    print(f"üìä Loaded mineral map: {mm.shape} from {p}")
                    return mm
        print("‚ùå Mineral map not found")
        return None

    def load_bse_image(self):
        """Load and process the BSE image with fallback options"""
        bse_path = self.find_bse_image()
        if bse_path:
            bse_image = tifffile.imread(bse_path)
            print(f"üìä Loaded BSE image: {bse_image.shape} from {bse_path}")

            # Convert to grayscale if needed
            if len(bse_image.shape) == 3:
                bse_image = np.mean(bse_image, axis=2)

            return bse_image
        else:
            print(f"‚ö†Ô∏è BSE image not found, will use mineral map only")
            return None

    def divide_into_patches(self, image, target_patch_size=64):
        """Divide image into patches; for 1024x1024 force EXACT 10x10=100 patches."""
        if image is None:
            return [], []

        if image.ndim == 3:
            image = image.mean(axis=2).astype(np.float32)

        h, w = image.shape[:2]
        patches, positions = [], []

        # FORCE 10x10 grid for 1024x1024 images (exactly 100 patches)
        if h == 1024 and w == 1024:
            print("üéØ Dividing 1024x1024 image into EXACT 10x10 grid (100 patches)")
            patch_size = 102  # 1024/10 = 102.4, using 102 with overlap

            for r in range(10):
                for c in range(10):
                    y0 = r * 102
                    x0 = c * 102
                    y1 = min(y0 + 102, 1024)
                    x1 = min(x0 + 102, 1024)

                    # Extract patch
                    patch = image[y0:y1, x0:x1]

                    # Resize to target size if needed
                    if patch.shape != (target_patch_size, target_patch_size):
                        patch = cv2.resize(patch, (target_patch_size, target_patch_size),
                                         interpolation=cv2.INTER_AREA)

                    patches.append(patch.astype(np.float32))
                    positions.append((r, c))

            print(f"‚úÖ Created {len(patches)} patches from 1024x1024 image")
            return patches, positions

        # generic grid
        grid_rows = max(1, h // target_patch_size)
        grid_cols = max(1, w // target_patch_size)
        for r in range(grid_rows):
            for c in range(grid_cols):
                y0 = r*target_patch_size
                x0 = c*target_patch_size
                y1 = min(y0+target_patch_size, h)
                x1 = min(x0+target_patch_size, w)
                tile = image[y0:y1, x0:x1]
                if tile.shape != (target_patch_size, target_patch_size):
                    tile = cv2.resize(tile, (target_patch_size, target_patch_size), interpolation=cv2.INTER_AREA)
                patches.append(tile.astype(np.float32))
                positions.append((r, c))
        return patches, positions



    def create_training_patches(self, num_patches=1000, target_patch_size=64):
        """Create realistic training patches from actual SEM data with consistent size"""
        print(f"üé® Creating realistic training patches for {self.sample_name}")

        mineral_map = self.load_mineral_map()
        bse_image = self.load_bse_image()

        all_patches = []

        # Use mineral map patches with consistent size - PRIORITIZE REAL DATA
        if mineral_map is not None:
            mineral_patches, mineral_positions = self.divide_into_patches(mineral_map, target_patch_size)
            if mineral_patches:
                all_patches.extend(mineral_patches)
                print(f"‚úÖ Added {len(mineral_patches)} mineral map patches ({target_patch_size}x{target_patch_size})")

        # Use BSE image patches with consistent size
        if bse_image is not None:
            bse_patches, bse_positions = self.divide_into_patches(bse_image, target_patch_size)
            if bse_patches:
                all_patches.extend(bse_patches)
                print(f"‚úÖ Added {len(bse_patches)} BSE image patches ({target_patch_size}x{target_patch_size})")

        # If we have enough real patches (like 100 from 1024x1024), use them directly
        if len(all_patches) >= 100:
            print(f"üéØ Using {len(all_patches)} real patches for training")
            # Use only real patches for better quality
            all_patches = all_patches[:num_patches]
        else:
            # If we don't have enough real patches, create synthetic ones
            current_count = len(all_patches)
            if current_count < num_patches or current_count == 0:
                additional_needed = max(num_patches - current_count, num_patches)
                print(f"üîÑ Creating {additional_needed} additional synthetic patches ({target_patch_size}x{target_patch_size})")
                synthetic_patches = self.create_synthetic_patches(additional_needed, target_patch_size)
                all_patches.extend(synthetic_patches)

            # Ensure we have the right number of patches
            all_patches = all_patches[:num_patches]

        # Verify all patches have the same size
        patch_shapes = set(patch.shape for patch in all_patches)
        if len(patch_shapes) > 1:
            print(f"‚ö†Ô∏è Inconsistent patch shapes: {patch_shapes}")
            # Resize all patches to target size
            all_patches = [cv2.resize(patch, (target_patch_size, target_patch_size))
                          if patch.shape != (target_patch_size, target_patch_size) else patch
                          for patch in all_patches]

        # Convert to numpy array and normalize
        try:
            patches_array = np.array(all_patches)
            patches_array = np.expand_dims(patches_array, axis=-1)  # Add channel dimension
            patches_array = normalize01(patches_array)

            print(f"‚úÖ Created {patches_array.shape[0]} training patches of shape {patches_array[0].shape}")
            return patches_array
        except Exception as e:
            print(f"‚ùå Error creating patches array: {e}")
            # Fallback: create synthetic patches only
            print("üîÑ Creating synthetic patches as fallback...")
            synthetic_patches = self.create_synthetic_patches(num_patches, target_patch_size)
            patches_array = np.array(synthetic_patches)
            patches_array = np.expand_dims(patches_array, axis=-1)
            patches_array = normalize01(patches_array)
            return patches_array


    def create_synthetic_patches(self, num_patches, patch_size=64):
        """Create synthetic patches that mimic real SEM texture with consistent size"""
        patches = []

        composition = self.mineral_processor.get_sample_composition(self.sample_name)
        five_phase_area = composition.get('five_phase_area', {})

        for _ in range(num_patches):
            # Create base texture with realistic mineral distribution
            base = np.zeros((patch_size, patch_size))

            # Add minerals based on composition
            y, x = np.ogrid[:patch_size, :patch_size]

            # Silicates (quartz, feldspar) - bright, angular
            silicates_frac = five_phase_area.get('Silicates', 50) / 100
            num_silicate_grains = max(1, int(silicates_frac * 15))
            for _ in range(num_silicate_grains):
                center_y, center_x = np.random.randint(10, patch_size-10, 2)
                size = np.random.randint(5, 15)
                grain = ((y - center_y)**2 + (x - center_x)**2 < size**2).astype(float)
                base += grain * np.random.uniform(0.7, 0.9)

            # Carbonates - medium gray, rounded
            carbonate_frac = five_phase_area.get('Carbonate', 20) / 100
            num_carbonate_grains = max(1, int(carbonate_frac * 10))
            for _ in range(num_carbonate_grains):
                center_y, center_x = np.random.randint(8, patch_size-8, 2)
                size = np.random.randint(4, 12)
                grain = ((y - center_y)**2 + (x - center_x)**2 < size**2).astype(float)
                base += grain * np.random.uniform(0.4, 0.6)

            # Clay - dark gray, fine texture
            clay_frac = five_phase_area.get('Clay', 20) / 100
            if clay_frac > 0:
                clay_texture = np.random.randn(patch_size, patch_size) * 0.1 * clay_frac
                base += clay_texture

            # Kerogen - very dark, organic
            kerogen_frac = five_phase_area.get('Kerogen', 5) / 100
            if kerogen_frac > 0:
                kerogen_mask = np.random.random((patch_size, patch_size)) < kerogen_frac
                base[kerogen_mask] -= 0.3

            # Add noise and normalize
            patch = base + np.random.randn(patch_size, patch_size) * 0.05
            patch = np.clip(patch, 0, 1)
            patches.append(patch)

        return patches
    def find_bse_image(self):
        """Find BSE image with tolerant names in sample root or Elements/."""
        sample_folder = os.path.join(self.base_path, self.sample_name)
        possible = ["bse","backscattered","sem","bse_image"]
        dirs = [sample_folder, os.path.join(sample_folder, "Elements")]
        for d in dirs:
            if not os.path.isdir(d):
                continue
            for f in os.listdir(d):
                fl = f.lower()
                if fl.endswith((".tif",".tiff")) and any(k in fl for k in possible):
                    return os.path.join(d, f)
        return None

def create_continuous_3d_volume(generated_patches, target_size=(128, 128, 128), mineral_composition=None):
    """Create continuous, geologically realistic 3D volume"""
    print("üîÑ Creating geologically realistic 3D volume...")

    if mineral_composition is None:
        mineral_composition = {'Silicates': 0.4, 'Clay': 0.3, 'Carbonate': 0.2, 'Kerogen': 0.05, 'Others': 0.05}

    # Process input
    if generated_patches.ndim == 5:
        volume = np.mean(generated_patches[..., 0], axis=0)
    else:
        volume = generated_patches[..., 0] if generated_patches.ndim == 4 else generated_patches

    # Resize to target
    from scipy.ndimage import zoom
    zf = [target_size[i] / volume.shape[i] for i in range(3)]
    vol = zoom(volume, zf, order=3)
    vol = np.clip(vol, 0, 1).astype(np.float32)

    # Enhanced geological features
    # 1. Multi-scale stratification
    z_coords = np.linspace(0, 6 * np.pi, vol.shape[2])
    stratification = (0.1 * np.sin(z_coords * 4)[None, None, :] +
                     0.05 * np.sin(z_coords * 12)[None, None, :])
    vol = np.clip(vol + stratification, 0, 1)

    # 2. Mineral-specific processing
    silicate_mask = vol > np.percentile(vol, 70)
    clay_mask = (vol > np.percentile(vol, 30)) & (vol <= np.percentile(vol, 70))

    # Enhance silicate regions (brighter, more continuous)
    from scipy.ndimage import gaussian_filter
    vol_silicate = gaussian_filter(vol * silicate_mask.astype(float), sigma=1.0)

    # Enhance clay regions (smoother, darker)
    vol_clay = gaussian_filter(vol * clay_mask.astype(float), sigma=2.0) * 0.8

    # Combine
    vol_enhanced = vol_silicate + vol_clay
    vol_enhanced = np.clip(vol_enhanced, 0, 1)

    # 3. Create watertight binary volume
    threshold = np.percentile(vol_enhanced, 60)  # Higher threshold for more solid material
    bw = (vol_enhanced >= threshold).astype(np.uint8)

    # 4. Morphological operations for continuity
    from scipy.ndimage import binary_closing, binary_fill_holes
    structure = np.ones((3, 3, 3))
    bw = binary_closing(bw, structure=structure)
    bw = binary_fill_holes(bw)

    # 5. Remove small disconnected components
    from scipy.ndimage import label
    labeled, num_features = label(bw)
    if num_features > 1:
        # Keep only largest component
        component_sizes = np.bincount(labeled.ravel())
        largest_component = np.argmax(component_sizes[1:]) + 1
        bw = (labeled == largest_component).astype(np.uint8)

    # 6. Final smoothing and blending
    bw_smooth = gaussian_filter(bw.astype(float), sigma=1.0)

    # 7. Blend binary structure with texture
    vol_final = vol_enhanced * 0.3 + bw_smooth * 0.7
    vol_final = np.clip(vol_final, 0, 1).astype(np.float32)

    # Quality metrics
    solid_ratio = np.sum(vol_final > 0.5) / vol_final.size
    print(f"‚úÖ Geological 3D volume created: {vol_final.shape}")
    print(f"üìä Solid volume ratio: {solid_ratio:.3f}")

    return vol_final

def export_hex_voxel_inp(volume, out_path, voxel_step=2, threshold=0.5, material=None):
    """
    Export compact, IMPORTABLE Abaqus .inp with C3D8 hex elements.
    - Correct *ELSET, *SURFACE, *DLOAD usage (face pressure on top)
    - Robust NSET formatting (no trailing commas, <=16 per line)
    - Adaptive voxel_step to target <~5 MB
    """
    import os
    os.makedirs(os.path.dirname(out_path), exist_ok=True)

    # normalize & threshold
    vol = volume.astype(np.float32)
    vol = (vol - vol.min())/(vol.max() - vol.min() + 1e-8)
    thr = float(threshold)
    V = (vol >= thr).astype(np.uint8)

    sx, sy, sz = V.shape  # assume (X,Y,Z)

    # target elements for ~<=5MB (rough guide): try a coarse grid until elements < ~200k
    def est_size(step):
        nx, ny, nz = len(range(0,sx,step)), len(range(0,sy,step)), len(range(0,sz,step))
        est_elems = max((nx-1),0)*max((ny-1),0)*max((nz-1),0)
        # ~ line per elem + node grid; rough bytes
        return est_elems
    step = max(2, int(voxel_step))
    for cand in [step, step+1, step+2, step+3, step+4]:
        if est_size(cand) < 200000:
            step = cand
            break

    xs = list(range(0, sx, step))
    ys = list(range(0, sy, step))
    zs = list(range(0, sz, step))
    nx, ny, nz = len(xs), len(ys), len(zs)
    if nx < 2 or ny < 2 or nz < 2:
        raise RuntimeError("Grid too coarse; increase resolution or volume size")

    # physical size (mm)
    Sx, Sy, Sz = 10.0, 10.0, 10.0
    dx, dy, dz = (Sx/(nx-1), Sy/(ny-1), Sz/(nz-1))

    def node_id(i,j,k): return 1 + k*(ny*nx) + j*nx + i

    elements = []
    top_elem_ids = []

    eid = 0
    for k in range(nz-1):
        k0, k1 = zs[k], zs[k+1]
        for j in range(ny-1):
            j0, j1 = ys[j], ys[j+1]
            for i in range(nx-1):
                i0, i1 = xs[i], xs[i+1]
                block = V[i0:i1, j0:j1, k0:k1]
                # majority vote include
                if block.size and block.mean() >= 0.5:
                    n000 = node_id(i,   j,   k)
                    n100 = node_id(i+1, j,   k)
                    n110 = node_id(i+1, j+1, k)
                    n010 = node_id(i,   j+1, k)
                    n001 = node_id(i,   j,   k+1)
                    n101 = node_id(i+1, j,   k+1)
                    n111 = node_id(i+1, j+1, k+1)
                    n011 = node_id(i,   j+1, k+1)
                    eid += 1
                    elements.append((eid,(n000,n100,n110,n010,n001,n101,n111,n011)))
                    if k == nz-2:
                        top_elem_ids.append(eid)

    if eid == 0:
        # ensure at least one element
        eid = 1
        elements.append((1,(node_id(0,0,0), node_id(1,0,0), node_id(1,1,0), node_id(0,1,0),
                            node_id(0,0,1), node_id(1,0,1), node_id(1,1,1), node_id(0,1,1))))
        top_elem_ids = [1]

    # write file
    with open(out_path, "w") as f:
        f.write("*HEADING\n")
        f.write("3D Shale Volume Element - Natural Microstructure\n")
        f.write("** Generated from SEM images + GAN/U-Net pipeline\n")
        f.write("*PREPRINT, ECHO=NO, MODEL=NO, HISTORY=NO, CONTACT=NO\n")
        f.write("*PART, NAME=SHALE_PART\n")
        f.write("*NODE\n")
        # nodes
        nid = 0
        for k in range(nz):
            for j in range(ny):
                for i in range(nx):
                    nid += 1
                    x = i*dx; y = j*dy; z = k*dz
                    f.write(f"{nid}, {x:.6f}, {y:.6f}, {z:.6f}\n")

        # elements
        f.write("*ELEMENT, TYPE=C3D8, ELSET=SHALE_ELEMENTS\n")
        for (eid, nodes) in elements:
            f.write(f"{eid}, {nodes[0]}, {nodes[1]}, {nodes[2]}, {nodes[3]}, {nodes[4]}, {nodes[5]}, {nodes[6]}, {nodes[7]}\n")

        # element sets
        element_count = len(elements)
        f.write("*ELSET, ELSET=SHALE_ELEMENTS, GENERATE\n")
        f.write(f"1, {element_count}, 1\n")

        if len(top_elem_ids) > 0:
            f.write("*ELSET, ELSET=TOP_ELEMS\n")
            # write in rows of 16 items, no trailing comma
            for s in range(0, len(top_elem_ids), 16):
                row = top_elem_ids[s:s+16]
                f.write(", ".join(str(x) for x in row) + "\n")

        # node sets (bottom and top surfaces)
        def write_nset(name, nodes_list):
            f.write(f"*NSET, NSET={name}\n")
            for s in range(0, len(nodes_list), 16):
                row = nodes_list[s:s+16]
                f.write(", ".join(str(x) for x in row) + "\n")

        bottom_nodes = [node_id(i,j,0) for i in range(nx) for j in range(ny)]
        top_nodes    = [node_id(i,j,nz-1) for i in range(nx) for j in range(ny)]
        # Node sets (planes are contiguous in our numbering)
        f.write("*NSET, NSET=BOTTOM_SURFACE, GENERATE\n")
        # bottom plane are nodes 1..(nx*ny)
        f.write(f"1, {nx*ny}, 1\n")

        f.write("*NSET, NSET=TOP_SURFACE, GENERATE\n")
        top_start = 1 + (nz-1)*(ny*nx)
        top_end   = top_start + (nx*ny) - 1
        f.write(f"{top_start}, {top_end}, 1\n")

        # material
        if material is None:
            material = {"E": 25.0, "nu": 0.25, "rho": 2.65e-9}
        f.write("*SOLID SECTION, ELSET=SHALE_ELEMENTS, MATERIAL=SHALE_MATERIAL\n")
        f.write("*MATERIAL, NAME=SHALE_MATERIAL\n")
        f.write("*ELASTIC\n")
        f.write(f"{material['E']:.6f}, {material['nu']:.6f}\n")
        f.write("*DENSITY\n")
        f.write(f"{material['rho']:.8e}\n")
        f.write("*END PART\n")

        # assembly
        f.write("*ASSEMBLY, NAME=ASSEMBLY_SHALE\n")
        f.write("*INSTANCE, NAME=SHALE_INSTANCE, PART=SHALE_PART\n")
        f.write("*END INSTANCE\n")
        # define a surface from the part-level elset TOP_ELEMS (face S3 on all of them)
        if len(top_elem_ids) > 0:
            f.write("*SURFACE, NAME=TOP_FACE, TYPE=ELEMENT\n")
            f.write("SHALE_INSTANCE.TOP_ELEMS, S3\n")
        f.write("*END ASSEMBLY\n")

        # analysis step with pressure on top faces and fixed bottom nodes
        f.write("*STEP, NAME=COMPRESSION_TEST, NLGEOM=NO\n")
        f.write("*STATIC\n")
        f.write("1., 1., 1e-05, 1.\n")
        # Fully fix bottom surface (all translational & rotational DOFs)
        f.write("*BOUNDARY, ENCASTRE\n")
        f.write("BOTTOM_SURFACE,\n")

        # Apply a small z-displacement (U3) on the top node set
        f.write("*BOUNDARY\n")
        f.write("TOP_SURFACE, 3, 3, -0.1\n")
        f.write("*OUTPUT, FIELD, VARIABLE=PRESELECT\n")
        f.write("*END STEP\n")

    file_size = os.path.getsize(out_path) / (1024 * 1024)
    quick_inp_sanity(out_path)
    print(f"‚úÖ Abaqus .inp exported: {out_path}")
    print(f"üì¶ File size: {file_size:.2f} MB | Elements: {eid}")
    return out_path
def export_compact_abaqus_inp(volume, out_path, target_size_mb=5, threshold=0.5, material=None):
    """
    Export compact Abaqus .inp targeting specific file size with geological realism.
    """
    import os
    os.makedirs(os.path.dirname(out_path), exist_ok=True)

    # Normalize volume
    vol = volume.astype(np.float32)
    vol = (vol - vol.min()) / (vol.max() - vol.min() + 1e-8)

    # Binary mask with morphological cleaning
    from scipy.ndimage import binary_closing, binary_opening
    bw = (vol >= threshold).astype(np.uint8)

    # Clean small artifacts
    structure = np.ones((3, 3, 3))
    bw = binary_opening(bw, structure=structure)
    bw = binary_closing(bw, structure=structure)

    # Calculate optimal voxel step for target file size
    # Estimate: ~200 bytes per element for compact format
    target_elements = (target_size_mb * 1024 * 1024) // 200
    total_voxels = np.sum(bw)

    if total_voxels == 0:
        # Fallback: use center region
        center_slice = volume.shape[0] // 2
        bw[center_slice-10:center_slice+10,
           center_slice-10:center_slice+10,
           center_slice-10:center_slice+10] = 1
        total_voxels = np.sum(bw)

    # Calculate voxel step to achieve target elements
    voxel_step = max(2, int(np.cbrt(total_voxels / target_elements)))

    print(f"üéØ Target: {target_size_mb}MB, Voxel step: {voxel_step}, Solid voxels: {total_voxels}")

    # Use the existing export function with calculated step
    return export_hex_voxel_inp(volume, out_path, voxel_step=voxel_step,
                               threshold=threshold, material=material)
def validate_abaqus_file(file_path):
    """Validate that the Abaqus .inp file is properly formatted and importable"""
    print(f"üîç Validating Abaqus file: {file_path}")

    try:
        with open(file_path, 'r') as f:
            content = f.read()

        # Check for essential sections
        required_sections = ['*HEADING', '*NODE', '*ELEMENT', '*MATERIAL', '*STEP']
        missing_sections = []

        for section in required_sections:
            if section not in content:
                missing_sections.append(section)

        if missing_sections:
            print(f"‚ùå Missing sections: {missing_sections}")
            return False

        # Count actual nodes/elements by lines under sections
        node_lines = sum(1 for ln in content.splitlines() if ln and ln[0].isdigit() and ln.count(',')>=3)
        elem_lines = sum(1 for ln in content.splitlines() if ln and ln[0].isdigit() and ln.count(',')==8)
        print(f"‚úÖ Abaqus file validation passed")
        print(f"   ‚Ä¢ Node lines: {node_lines}")
        print(f"   ‚Ä¢ Element lines: {elem_lines}")
        print(f"   ‚Ä¢ File size: {os.path.getsize(file_path) / (1024 * 1024):.2f} MB")

        return True

    except Exception as e:
        print(f"‚ùå Abaqus file validation failed: {e}")
        return False
def export_visuals(volume, vis_dir, prefix="result"):
    os.makedirs(vis_dir, exist_ok=True)
    # Save orthogonal slices
    zmid = volume.shape[2]//2
    ymid = volume.shape[1]//2
    xmid = volume.shape[0]//2
    def _norm2u8(img):
        img = img.astype(np.float32)
        img = (img - img.min())/(img.max() - img.min() + 1e-8)
        return (img*255).astype(np.uint8)

    xy = _norm2u8(volume[:,:,zmid])
    xz = _norm2u8(volume[:,ymid,:])
    yz = _norm2u8(volume[xmid,:,:])

    cv2.imwrite(os.path.join(vis_dir, f"{prefix}_xy_mid.png"), xy)
    cv2.imwrite(os.path.join(vis_dir, f"{prefix}_xz_mid.png"), xz)
    cv2.imwrite(os.path.join(vis_dir, f"{prefix}_yz_mid.png"), yz)

    # also save a z-slice grid preview (normalized)
    zs = np.linspace(0, volume.shape[2]-1, 16).astype(int)
    tiles = []
    for zi in zs:
        tiles.append(_norm2u8(volume[:,:,zi]))
    save_png_grid(np.stack(tiles), grid=(4,4), tile_size=128,
                  out_path=os.path.join(vis_dir, f"{prefix}_z_grid.png"))
    # Make montage of several z-slices

# =========================
# Coloring / Labeling / Viz Utilities (NEW)
# =========================
class MineralPalette:
    """Palette for 5-phase model with optional auto extraction from sample folder."""
    DEFAULT = OrderedDict({
        'Silicates':  (242, 242, 248),
        'Carbonate':  (230, 210, 190),
        'Clay':       (170, 160, 150),
        'Kerogen':    (40,  40,  40 ),
        'Others':     (200, 200, 210)
    })
    def __init__(self, base_path):
        self.base_path = base_path
        self.colors = MineralPalette.DEFAULT.copy()

    def try_extract_from_folder(self, sample_name):
        # placeholder for future auto-extraction; keep defaults for consistency
        return self.colors

    def rgb(self, name): return self.colors.get(name, (200,200,210))

class ColorAndExportTools:
    """Create colored slices and label TIFF stacks from intensity volumes."""
    def __init__(self, base_path, palette: MineralPalette):
        self.base_path = base_path
        self.palette = palette
        self.out_dir = os.path.join(base_path, "Visualisations")
        os.makedirs(self.out_dir, exist_ok=True)

    def _intensity_to_labels(self, volume):
        v = (volume - volume.min())/(volume.max()-volume.min() + 1e-8)
        q = np.percentile(v, [20, 40, 60, 80])
        labels = np.zeros_like(v, dtype=np.uint8)
        labels[v <= q[0]] = 4    # Others (darkest)
        labels[(v > q[0]) & (v <= q[1])] = 3  # Kerogen
        labels[(v > q[1]) & (v <= q[2])] = 2  # Clay
        labels[(v > q[2]) & (v <= q[3])] = 1  # Carbonate
        labels[v > q[3]] = 0                  # Silicates (brightest)
        return labels

    def _palette_lut(self):
        lut = np.zeros((5,3), dtype=np.uint8)
        order = ['Silicates','Carbonate','Clay','Kerogen','Others']
        for i,name in enumerate(order):
            lut[i] = self.palette.rgb(name)
        return lut

    def save_colored_center_slices(self, volume_or_labels, name_prefix):
        """Accepts intensity volume OR label volume."""
        if volume_or_labels.ndim != 3:
            return
        if volume_or_labels.dtype != np.uint8 or volume_or_labels.max()<=4:
            labels = self._intensity_to_labels(volume_or_labels)
        else:
            labels = volume_or_labels

        zmid = labels.shape[2]//2
        ymid = labels.shape[1]//2
        xmid = labels.shape[0]//2
        lut = self._palette_lut()

        def colorize(L):  # L: HxW labels
            rgb = lut[L]
            return rgb

        planes = {
            "xy": colorize(labels[:,:,zmid]),
            "xz": colorize(labels[:,ymid,:]),
            "yz": colorize(labels[xmid,:,:])
        }
        for k,img in planes.items():
            cv2.imwrite(os.path.join(self.out_dir, f"{name_prefix}_{k}_center.png"), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))

    def save_tiff_stack_labels(self, volume_or_labels, name_prefix):
        if volume_or_labels.dtype != np.uint8 or volume_or_labels.max()<=4:
            labels = self._intensity_to_labels(volume_or_labels)
        else:
            labels = volume_or_labels
        stack_path = os.path.join(self.base_path, "tiff_stack", f"{name_prefix}_labels.tiff")
        os.makedirs(os.path.dirname(stack_path), exist_ok=True)
        tifffile.imwrite(stack_path, labels.astype(np.uint8))

class ExtraVisualizer:
    def __init__(self, base_path):
        self.base_path = base_path
        self.out_dir = os.path.join(base_path, "Visualisations")
        os.makedirs(self.out_dir, exist_ok=True)

    def orthogrid(self, volume, name_prefix, n=8):
        zs = np.linspace(0, volume.shape[2]-1, n).astype(int)
        imgs = [volume[:,:,zi] for zi in zs]
        save_png_grid(np.stack(imgs), grid=(int(np.sqrt(n)), int(np.ceil(n/np.sqrt(n)))), tile_size=96,
                      out_path=os.path.join(self.out_dir, f"{name_prefix}_zgrid.png"))

    def composition_radar(self, target_comp, achieved_comp, name_prefix):
        # achieved_comp is dict phase->fraction (0..1) or percent; normalize to %
        phases = ['Silicates','Carbonate','Clay','Kerogen','Others']
        targ = np.array([target_comp.get(p,0) for p in phases], dtype=np.float32)
        ach  = np.array([achieved_comp.get(p,0) for p in phases], dtype=np.float32)
        if ach.max()<=1.0: ach = ach*100.0

        # simple polar plot
        angles = np.linspace(0, 2*np.pi, len(phases), endpoint=False)
        targ_c = np.concatenate([targ,[targ[0]]]); ach_c = np.concatenate([ach,[ach[0]]])
        ang_c  = np.concatenate([angles,[angles[0]]])

        plt.figure(figsize=(6,6))
        ax = plt.subplot(111, polar=True)
        ax.plot(ang_c, targ_c, linewidth=2)
        ax.fill(ang_c, targ_c, alpha=0.1)
        ax.plot(ang_c, ach_c, linewidth=2)
        ax.fill(ang_c, ach_c, alpha=0.1)
        ax.set_thetagrids(angles * 180/np.pi, phases)
        ax.set_title(f"Composition Radar ‚Äî {name_prefix}")
        plt.tight_layout()
        plt.savefig(os.path.join(self.out_dir, f"{name_prefix}_radar.png"), dpi=200, bbox_inches='tight')
        plt.close()

class Simple3DVisualizer:
    """Lightweight fall-back 3D viz (PNG slices already handled)."""
    def __init__(self, base_path):
        self.base_path = base_path
        self.out_dir = os.path.join(base_path, "Visualisations")
        os.makedirs(self.out_dir, exist_ok=True)

    def create_3d_volume_visualization(self, volume, name_prefix):
        # Save a MIP and a thresholded isosurface-like hint (2D)
        mip_xy = volume.max(axis=2)
        mip_xz = volume.max(axis=1)
        mip_yz = volume.max(axis=0)
        cv2.imwrite(os.path.join(self.out_dir, f"{name_prefix}_mip_xy.png"), (mip_xy*255).astype(np.uint8))
        cv2.imwrite(os.path.join(self.out_dir, f"{name_prefix}_mip_xz.png"), (mip_xz*255).astype(np.uint8))
        cv2.imwrite(os.path.join(self.out_dir, f"{name_prefix}_mip_yz.png"), (mip_yz*255).astype(np.uint8))

def enhance_volume_continuity(volume, mineral_composition):
    """
    Make volume continuous/closed:
      - multi-scale Gaussian blend (as before)
      - morphological close in 3D
      - 3D hole filling
      - clamp to [0,1]
    """
    print("üîÑ Enhancing 3D volume continuity...")
    from scipy.ndimage import gaussian_filter
    from skimage.morphology import ball
    from skimage.segmentation import flood_fill

    v = volume.astype(np.float32)
    v = (v - v.min())/(v.max()-v.min()+1e-8)

    # multi-scale blend
    sL = gaussian_filter(v, 2.0)
    sM = gaussian_filter(v, 1.0)
    sS = gaussian_filter(v, 0.5)

    silicate_frac = mineral_composition.get('Silicates', 0.4)
    clay_frac     = mineral_composition.get('Clay', 0.3)
    carb_frac     = mineral_composition.get('Carbonate', 0.2)

    wL = silicate_frac
    wM = carb_frac*0.7
    wS = clay_frac*0.5
    out = (wL*sL + wM*sM + wS*sS + 0.1*v)/(wL+wM+wS+0.1)

    # binarize moderately, close, fill holes, then soften to intensity
    thr = np.percentile(out, 55)
    B = (out >= thr).astype(np.uint8)

    # morphological close to stitch gaps
    from scipy.ndimage import binary_closing, binary_fill_holes
    B = binary_closing(B, structure=ball(2)).astype(np.uint8)
    B = binary_fill_holes(B).astype(np.uint8)

    # soften edges back to grayscale field
    out = gaussian_filter(B.astype(np.float32), 0.8)
    out = (out - out.min())/(out.max()-out.min()+1e-8)
    print("‚úÖ Volume continuity enhanced")
    return out

def calculate_mechanical_properties(volume, mineral_processor, sample_name):
    """Calculate mechanical properties based on mineral composition"""
    print("üìä Calculating mechanical properties...")

    composition = mineral_processor.get_sample_composition(sample_name)
    five_phase_area = composition.get('five_phase_area', {})

    # Calculate volume fractions from generated volume
    thresholds = np.percentile(volume, [20, 40, 60, 80])
    phase_volumes = np.zeros(5)

    phase_volumes[0] = np.sum(volume >= thresholds[3])  # Silicates
    phase_volumes[1] = np.sum((volume >= thresholds[2]) & (volume < thresholds[3]))  # Carbonate
    phase_volumes[2] = np.sum((volume >= thresholds[1]) & (volume < thresholds[2]))  # Clay
    phase_volumes[3] = np.sum((volume >= thresholds[0]) & (volume < thresholds[1]))  # Kerogen
    phase_volumes[4] = np.sum(volume < thresholds[0])  # Others

    phase_fractions = phase_volumes / np.sum(phase_volumes)

    # Calculate equivalent properties using rule of mixtures
    equivalent_modulus = 0
    equivalent_density = 0

    phase_mapping = ['Silicates', 'Carbonate', 'Clay', 'Kerogen', 'Others']
    for i, phase in enumerate(phase_mapping):
        fraction = phase_fractions[i]
        modulus = mineral_processor.get_phase_modulus(phase)
        density = mineral_processor.get_phase_density(phase)

        equivalent_modulus += fraction * modulus
        equivalent_density += fraction * density

    properties = {
        'equivalent_youngs_modulus': equivalent_modulus,
        'equivalent_density': equivalent_density,
        'phase_fractions': dict(zip(phase_mapping, phase_fractions)),
        'sample_density': composition.get('properties', {}).get('Sample Density', 2.7),
        'hardness': composition.get('properties', {}).get('Hardness', 5.5)
    }

    return properties
def estimate_achieved_composition(volume):
    """Return dict of phase->percentage from intensity thresholds (consistent with labeling)."""
    v = (volume - volume.min())/(volume.max()-volume.min() + 1e-8)
    q = np.percentile(v, [20, 40, 60, 80])
    phases = ['Silicates','Carbonate','Clay','Kerogen','Others']
    counts = {
        'Silicates': float((v > q[3]).sum()),
        'Carbonate': float(((v > q[2]) & (v <= q[3])).sum()),
        'Clay':      float(((v > q[1]) & (v <= q[2])).sum()),
        'Kerogen':   float(((v > q[0]) & (v <= q[1])).sum()),
        'Others':    float((v <= q[0]).sum())
    }
    total = sum(counts.values()) + 1e-8
    return {k: 100.0*counts[k]/total for k in phases}
# -------------------------
# Configuration Classes
# -------------------------

@dataclass
class TrainingConfig:
    batch_size: int = 32
    learning_rate: float = 0.001
    epochs: int = 100
    patch_size: int = 64
    use_mixed_precision: bool = True
    early_stopping_patience: int = 10
    validation_interval: int = 5

@dataclass
class ModelConfig:
    unet_channels: list = None
    gan_latent_dim: int = 100
    slicegan_dimensions: tuple = (64, 64, 64)

    def __post_init__(self):
        if self.unet_channels is None:
            self.unet_channels = [64, 128, 256, 512]

# -------------------------
# Advanced Mineral Processor
# -------------------------

class AdvancedMineralProcessor:
    """Advanced mineral composition processor with exact paper methodology"""

    def __init__(self, excel_path):
        # Make sure the path is absolute
        if not os.path.isabs(excel_path):
            excel_path = os.path.join(os.path.expanduser("~"), "Desktop", "Files", excel_path)
        self.excel_path = excel_path
        self.mineral_data = {}

        self.sample_mapping = {
            'sample1': 'Sample 10555\\10555',
            'sample2': 'Sample 11203\\11203',
            'sample3': 'Sample 11206\\11206',
            'sample4': 'Sample 12162\\12162',
            'sample5': 'Sample 17699\\17699',
            'sample6': 'Sample 19472\\19472',
            'sample7': 'Sample 21298\\21298',
            'sample8': 'Sample 23285\\23285'
        }
        self.five_phase_model = {
            'Silicates': ['Quartz', 'Alkali Feldspar', 'Plagioclase'],
            'Carbonate': ['Calcite', 'Dolomite', 'Ankerite', 'Siderite'],
            'Clay': ['Illite', 'Chlorite', 'Kaolinite', 'Muscovite', 'Biotite'],
            'Kerogen': [],
            'Others': ['Pyrite', 'Zircon', 'Rutile', 'Ilmenite', 'Apatite', 'Monazite', 'Unclassified']
        }

        self.youngs_modulus = {
            'Silicates': 89.6,
            'Carbonate': 74.6,
            'Clay': 22.3,
            'Kerogen': 9.2,
            'Others': 12.392
        }

        self.density_values = {
            'Silicates': 2.65,
            'Carbonate': 2.71,
            'Clay': 2.60,
            'Kerogen': 1.30,
            'Others': 3.50
        }

    def load_and_parse_excel(self):
        print("üìä Loading and parsing Excel data...")
        try:
            df = pd.read_excel(self.excel_path, sheet_name='Mineral quant_all samples', header=None)
            print(f"üìê Excel shape: {df.shape}")
            self.process_single_sheet_data(df)
            print("‚úÖ Excel data loaded and parsed successfully")
        except Exception as e:
            print(f"‚ùå Error loading Excel: {e}")
            print("üîÑ Creating realistic compositions based on paper...")
            self.create_realistic_compositions()

    def process_single_sheet_data(self, df):
        print("üìä Processing single sheet Excel data...")
        area_start = self.find_data_start(df, 'MODAL AREA%')
        wt_start = self.find_data_start(df, 'MODAL WT%')
        assay_start = self.find_data_start(df, 'ASSAY')
        properties_start = self.find_data_start(df, 'PROPERTIES')

        for sample_key, excel_key in self.sample_mapping.items():
            sample_data = {
                'five_phase_area': {},
                'five_phase_wt': {},
                'assay': {},
                'properties': {},
                'detailed_area': {},
                'detailed_wt': {}
            }

            if area_start >= 0:
                self.extract_mineral_data(df, area_start, self.find_sample_column(df, excel_key, area_start),
                                          sample_data['detailed_area'], sample_data['five_phase_area'])
            if wt_start >= 0:
                self.extract_mineral_data(df, wt_start, self.find_sample_column(df, excel_key, wt_start),
                                          sample_data['detailed_wt'], sample_data['five_phase_wt'])

            carbon_content = sample_data['assay'].get('C', 0)
            kerogen_content = carbon_content * 1.2
            sample_data['five_phase_area']['Kerogen'] = kerogen_content
            sample_data['five_phase_wt']['Kerogen'] = kerogen_content
            self.normalize_compositions(sample_data)
            self.mineral_data[sample_key] = sample_data
            print(f"‚úÖ Processed {sample_key}: {sample_data['five_phase_area']}")

    def find_data_start(self, df, keyword='MODAL AREA%'):
        """Find the exact starting row for each data section"""
        for idx, row in df.iterrows():
            for cell in row:
                if isinstance(cell, str) and keyword.lower() in cell.lower():
                    # Return the row after the header (where data actually starts)
                    return idx + 2  # +2 to skip the header and column names
        return 0

    def find_sample_column(self, df, excel_key, data_start):
        header_row = data_start - 1 if data_start > 0 else 0
        for col_idx in range(len(df.columns)):
            cell_value = df.iloc[header_row, col_idx]
            if isinstance(cell_value, str) and excel_key in cell_value:
                return col_idx
        return -1

    def extract_mineral_data(self, df, start_row, col_idx, detailed_dict, five_phase_dict):
        mineral_rows = {}

        # Find the actual data rows (skip headers)
        current_row = start_row + 1  # Skip the header row
        while current_row < len(df):
            mineral_name = df.iloc[current_row, 0]
            if not isinstance(mineral_name, str) or not mineral_name.strip():
                current_row += 1
                continue

            # Stop when we hit the next section
            if 'MODAL' in mineral_name or 'ASSAY' in mineral_name or 'PROPERTIES' in mineral_name:
                break

            try:
                value = float(df.iloc[current_row, col_idx])
                detailed_dict[mineral_name] = value
                mineral_rows[mineral_name] = value
            except (ValueError, TypeError):
                pass

            current_row += 1

        # Initialize all phases to zero
        for phase in self.five_phase_model:
            five_phase_dict[phase] = 0.0

        # Sum up minerals for each phase
        for phase, minerals in self.five_phase_model.items():
            phase_total = 0
            for mineral in minerals:
                for detailed_mineral, value in mineral_rows.items():
                    if mineral.lower() in detailed_mineral.lower():
                        phase_total += value
                        break  # Only count each mineral once
            five_phase_dict[phase] = phase_total

        # Special handling for Kerogen from carbon content
        # Find carbon content in assay section
        carbon_content = 0
        assay_start = self.find_data_start(df, 'ASSAY')
        if assay_start >= 0:
            current_row = assay_start + 1
            while current_row < len(df):
                element_name = df.iloc[current_row, 0]
                if isinstance(element_name, str) and 'C' in element_name and len(element_name.strip()) <= 3:
                    try:
                        carbon_content = float(df.iloc[current_row, col_idx])
                        break
                    except (ValueError, TypeError):
                        pass
                current_row += 1

        # Convert carbon to kerogen (approximate conversion)
        kerogen_content = carbon_content * 1.2
        five_phase_dict['Kerogen'] = kerogen_content
    def normalize_compositions(self, sample_data):
        for comp_type in ['five_phase_area', 'five_phase_wt']:
            total = sum(sample_data[comp_type].values())
            if total > 0:
                for phase in sample_data[comp_type]:
                    sample_data[comp_type][phase] = (sample_data[comp_type][phase] / total) * 100

    def create_realistic_compositions(self):
        print("üîÑ Creating realistic compositions based on paper...")
        realistic_data = {
            'sample1': {'Silicates': 45.2, 'Carbonate': 25.1, 'Clay': 18.3, 'Kerogen': 6.4, 'Others': 5.0},
            'sample2': {'Silicates': 52.7, 'Carbonate': 18.9, 'Clay': 22.1, 'Kerogen': 3.8, 'Others': 2.5},
            'sample3': {'Silicates': 38.4, 'Carbonate': 32.6, 'Clay': 15.8, 'Kerogen': 8.2, 'Others': 5.0},
            'sample4': {'Silicates': 61.3, 'Carbonate': 12.4, 'Clay': 19.6, 'Kerogen': 4.2, 'Others': 2.5},
            'sample5': {'Silicates': 42.8, 'Carbonate': 28.3, 'Clay': 16.9, 'Kerogen': 7.5, 'Others': 4.5},
            'sample6': {'Silicates': 55.1, 'Carbonate': 15.7, 'Clay': 21.3, 'Kerogen': 5.4, 'Others': 2.5},
            'sample7': {'Silicates': 47.9, 'Carbonate': 22.8, 'Clay': 17.6, 'Kerogen': 6.9, 'Others': 4.8},
            'sample8': {'Silicates': 58.6, 'Carbonate': 14.2, 'Clay': 20.1, 'Kerogen': 4.6, 'Others': 2.5}
        }
        for sample_key in self.sample_mapping.keys():
            composition = realistic_data.get(sample_key, realistic_data['sample1'])
            self.mineral_data[sample_key] = {
                'five_phase_area': composition,
                'five_phase_wt': composition,
                'assay': {'C': composition['Kerogen'] / 1.2},
                'properties': {'Sample Density': 2.70, 'Hardness': 5.5},
                'detailed_area': composition,
                'detailed_wt': composition
            }

    def get_sample_composition(self, sample_name):
        return self.mineral_data.get(sample_name, {})

    def get_phase_modulus(self, phase):
        return self.youngs_modulus.get(phase, 12.392)

    def get_phase_density(self, phase):
        return self.density_values.get(phase, 2.70)

# -------------------------
# TensorFlow Model Classes
# -------------------------

class ResidualAttentionUNet:
    """Simplified Residual Attention U-Net for faster training"""

    def __init__(self, input_size=(64, 64, 1), num_classes=5):
        self.input_size = input_size
        self.num_classes = num_classes
        self.model = self.build_simplified_model()
    def build_emergency_model(self):
        """Build ultra-simple model for emergency fallback"""
        print("üö® Building emergency ultra-simple model...")

        inputs = Input(self.input_size)

        # Ultra-simple architecture
        x = Conv2D(16, 3, activation='relu', padding='same')(inputs)
        x = MaxPooling2D(2)(x)
        x = Conv2D(32, 3, activation='relu', padding='same')(x)
        x = UpSampling2D(2)(x)
        x = Conv2D(16, 3, activation='relu', padding='same')(x)
        outputs = Conv2D(self.num_classes, 1, activation='softmax', dtype='float32')(x)

        model = Model(inputs, outputs, name='EmergencySimpleUNet')

        model.compile(
            optimizer=Adam(learning_rate=1e-3),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )

        return model
    def build_simplified_model(self):
        """Build a simplified U-Net that trains faster"""
        print("üîß Building simplified U-Net for faster training...")

        inputs = Input(self.input_size)

        # Simplified Encoder
        # Block 1
        x1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)
        x1 = Conv2D(32, 3, activation='relu', padding='same')(x1)
        p1 = MaxPooling2D(2)(x1)

        # Block 2
        x2 = Conv2D(64, 3, activation='relu', padding='same')(p1)
        x2 = Conv2D(64, 3, activation='relu', padding='same')(x2)
        p2 = MaxPooling2D(2)(x2)

        # Block 3 (Bottleneck)
        x3 = Conv2D(128, 3, activation='relu', padding='same')(p2)
        x3 = Conv2D(128, 3, activation='relu', padding='same')(x3)

        # Simplified Decoder
        # Block 4
        u2 = Conv2DTranspose(64, 2, strides=2, padding='same')(x3)
        u2 = Concatenate()([u2, x2])
        u2 = Conv2D(64, 3, activation='relu', padding='same')(u2)
        u2 = Conv2D(64, 3, activation='relu', padding='same')(u2)

        # Block 5
        u1 = Conv2DTranspose(32, 2, strides=2, padding='same')(u2)
        u1 = Concatenate()([u1, x1])
        u1 = Conv2D(32, 3, activation='relu', padding='same')(u1)
        u1 = Conv2D(32, 3, activation='relu', padding='same')(u1)

        # Output
        outputs = Conv2D(self.num_classes, 1, activation='softmax', dtype='float32')(u1)

        model = Model(inputs, outputs, name='SimplifiedResidualUNet')

        # Use simpler optimizer with lower learning rate
        model.compile(
            optimizer=Adam(learning_rate=1e-3),  # Higher learning rate for faster convergence
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )

        print("‚úÖ Simplified U-Net built successfully")
        return model

# === REPLACEMENT: Conditional pix2pix-style Generator (U-Net) ===
def build_cgen(input_shape=(64, 64, 1), cond_channels=1):
    """Generator: input = condition (e.g., edges) ‚Üí output = SEM-like image."""
    inp = Input(shape=(input_shape[0], input_shape[1], cond_channels))

    # Encoder
    def down(x, f, bn=True):
        x = Conv2D(f, 4, strides=2, padding='same', use_bias=not bn)(x)
        if bn: x = BatchNormalization()(x)
        x = LeakyReLU(0.2)(x)
        return x

    # Decoder
    def up(x, skip, f, dropout=False):
        x = Conv2DTranspose(f, 4, strides=2, padding='same', use_bias=False)(x)
        x = BatchNormalization()(x)
        if dropout: x = Dropout(0.5)(x)
        x = Activation('relu')(x)
        x = Concatenate()([x, skip])
        return x

    d1 = down(inp, 64, bn=False)     # 32x32
    d2 = down(d1, 128)               # 16x16
    d3 = down(d2, 256)               # 8x8
    d4 = down(d3, 512)               # 4x4
    d5 = down(d4, 512)               # 2x2
    d6 = down(d5, 512)               # 1x1 bottleneck

    u1 = up(d6, d5, 512, dropout=True)
    u2 = up(u1, d4, 512, dropout=True)
    u3 = up(u2, d3, 256)
    u4 = up(u3, d2, 128)
    u5 = up(u4, d1, 64)

    out = Conv2DTranspose(1, 4, strides=2, padding='same', activation='tanh')(u5)  # 64x64
    return Model(inp, out, name='CGen_UNet')

# === REPLACEMENT: PatchGAN Discriminator with SpectralNorm & Hinge ===
def build_patchgan_d(input_shape=(64, 64, 1), cond_channels=1):
    """D receives concatenated [condition, real_or_fake] along channels."""
    cond = Input(shape=(input_shape[0], input_shape[1], cond_channels))
    img  = Input(shape=(input_shape[0], input_shape[1], 1))
    x = Concatenate(axis=-1)([cond, img])  # shape: HxWx(cond+1)

    def c(x, f, s=2):
        x = SpectralNorm(Conv2D(f, 4, strides=s, padding='same', use_bias=False))(x)
        x = LeakyReLU(0.2)(x)
        return x

    x = c(x, 64, 2)    # 32x32
    x = c(x, 128, 2)   # 16x16
    x = c(x, 256, 2)   # 8x8
    x = c(x, 512, 1)   # 8x8 ‚Üí keep receptive field ~70
    out = SpectralNorm(Conv2D(1, 4, strides=1, padding='same', use_bias=False))(x)  # linear output
    return Model([cond, img], out, name='PatchGAN_D')
# === ADD: Hinge losses and pix2pix trainer ===
@tf.function
def d_hinge_loss(real_logits, fake_logits):
    return tf.reduce_mean(tf.nn.relu(1. - real_logits)) + tf.reduce_mean(tf.nn.relu(1. + fake_logits))

@tf.function
def g_hinge_loss(fake_logits):
    return -tf.reduce_mean(fake_logits)

def make_condition_maps(patches):
    """Condition = edges of BSE/mineral patch (normalized to [-1,1])."""
    # patches: (N,64,64,1) in [0,1] float
    arr = patches[...,0]
    # simple Sobel magnitude (fast & differentiable path not needed)
    gx = ndimage.sobel(arr, axis=1)
    gy = ndimage.sobel(arr, axis=2)
    mag = np.sqrt(gx*gx + gy*gy)
    mag = mag / (mag.max() + 1e-6)
    mag = (mag * 2.0 - 1.0).astype(np.float32)
    return mag[...,None]

def train_pix2pix_hinge(patches_64x64, epochs=40, batch_size=32, l1_lambda=50.0):
    """
    patches_64x64: float32 in [0,1], shape (N,64,64,1), target SEM images
    Condition = edge map. Generator maps cond‚ÜíSEM.
    """
    # Prepare data
    x_cond = make_condition_maps(patches_64x64)           # [-1,1]
    y_real = (patches_64x64 * 2.0 - 1.0).astype(np.float32)  # [-1,1]

    dataset = tf.data.Dataset.from_tensor_slices((x_cond, y_real)).shuffle(2048).batch(batch_size).prefetch(tf.data.AUTOTUNE)

    G = build_cgen(input_shape=(64,64,1), cond_channels=1)
    D = build_patchgan_d(input_shape=(64,64,1), cond_channels=1)

    g_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5, beta_2=0.999)
    d_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5, beta_2=0.999)
    mae = tf.keras.losses.MeanAbsoluteError()

    @tf.function
    def train_step(xc, yr):
        with tf.GradientTape(persistent=True) as tape:
            y_fake = G(xc, training=True)

            # Discriminator logits
            logits_real = D([xc, yr], training=True)
            logits_fake = D([xc, y_fake], training=True)

            # Losses
            dl = d_hinge_loss(logits_real, logits_fake)
            gl_gan = g_hinge_loss(logits_fake)
            gl_l1  = mae(yr, y_fake)
            gl = gl_gan + l1_lambda * gl_l1

        d_grads = tape.gradient(dl, D.trainable_variables)
        g_grads = tape.gradient(gl, G.trainable_variables)
        d_opt.apply_gradients(zip(d_grads, D.trainable_variables))
        g_opt.apply_gradients(zip(g_grads, G.trainable_variables))
        return dl, gl, gl_l1

    # Train
    for e in range(1, epochs+1):
        d_meter = g_meter = l1_meter = 0.0
        steps = 0
        for xc, yr in dataset:
            dl, gl, l1v = train_step(xc, yr)
            d_meter += dl; g_meter += gl; l1_meter += l1v; steps += 1
        if e % 5 == 0 or e == 1:
            print(f"üî• pix2pix-hinge epoch {e}/{epochs}  D:{d_meter/steps:.3f}  G:{g_meter/steps:.3f}  L1:{l1_meter/steps:.3f}")
    return G, D

class AdvancedSliceGAN3D:
    def __init__(self, latent_dim=128, volume_size=64):
        self.latent_dim = latent_dim
        self.volume_size = volume_size
        self.generator = self.build_memory_efficient_generator()
        self.discriminators = self.build_lightweight_discriminators()

        # Initialize with proper weights
        self.initialize_weights()
        print("ü§ñ Memory-optimized SliceGAN 3D Initialized")

    def initialize_weights(self):
        # Build once by running a tiny forward pass; Keras will initialize internally.
        try:
            _ = self.generator(tf.random.normal([1, self.latent_dim]), training=False)
        except Exception:
            pass
        for disc in self.discriminators.values():
            try:
                _ = disc(tf.random.normal([1, self.volume_size, self.volume_size, 1]), training=False)
            except Exception:
                pass

    def build_memory_efficient_generator(self):
        """Memory-efficient generator matching paper specifications"""
        model = Sequential(name='MemoryEfficientGenerator')
        model.add(Dense(4*4*4*512, input_dim=self.latent_dim))
        model.add(Reshape((4, 4, 4, 512)))
        model.add(BatchNormalization())
        model.add(ReLU())

        # Layer 1: 4x4x4 -> 8x8x8
        model.add(Conv3DTranspose(256, 4, strides=2, padding='same'))
        model.add(BatchNormalization())
        model.add(ReLU())

        # Layer 2: 8x8x8 -> 16x16x16
        model.add(Conv3DTranspose(128, 4, strides=2, padding='same'))
        model.add(BatchNormalization())
        model.add(ReLU())

        # Layer 3: 16x16x16 -> 32x32x32
        model.add(Conv3DTranspose(64, 4, strides=2, padding='same'))
        model.add(BatchNormalization())
        model.add(ReLU())

        # Layer 4: 32x32x32 -> 64x64x64
        model.add(Conv3DTranspose(32, 4, strides=2, padding='same'))
        model.add(BatchNormalization())
        model.add(ReLU())

        # Final layer
        model.add(Conv3DTranspose(1, 3, padding='same', activation='tanh'))
        return model

    def build_lightweight_discriminators(self):
        """Enhanced discriminators with stronger architecture for stability"""
        def build_discriminator(name_suffix):
            model = Sequential(name=f'Discriminator_{name_suffix}')

            # Input layer
            model.add(Input(shape=(self.volume_size, self.volume_size, 1)))

            # Layer 1: 64x64 -> 32x32
            model.add(Conv2D(64, 4, strides=2, padding='same'))
            model.add(LeakyReLU(0.2))
            model.add(Dropout(0.3))  # Add dropout for regularization

            # Layer 2: 32x32 -> 16x16
            model.add(Conv2D(128, 4, strides=2, padding='same'))
            model.add(BatchNormalization())
            model.add(LeakyReLU(0.2))
            model.add(Dropout(0.3))

            # Layer 3: 16x16 -> 8x8
            model.add(Conv2D(256, 4, strides=2, padding='same'))
            model.add(BatchNormalization())
            model.add(LeakyReLU(0.2))
            model.add(Dropout(0.3))

            # Layer 4: 8x8 -> 4x4
            model.add(Conv2D(512, 4, strides=2, padding='same'))
            model.add(BatchNormalization())
            model.add(LeakyReLU(0.2))
            model.add(Dropout(0.3))

            # Layer 5: 4x4 -> 2x2
            model.add(Conv2D(512, 4, strides=2, padding='same'))
            model.add(BatchNormalization())
            model.add(LeakyReLU(0.2))

            # Output layer
            model.add(Flatten())
            model.add(Dense(1, activation='sigmoid'))

            model.compile(
                optimizer=Adam(learning_rate=0.0002, beta_1=0.5),  # Slightly higher LR for discriminator
                loss='binary_crossentropy'
            )
            return model

        return {
            'xy': build_discriminator('XY'),
            'xz': build_discriminator('XZ'),
            'yz': build_discriminator('YZ')
        }

# -------------------------
# GPU-Optimized Training Functions
# -------------------------

def create_realistic_sem_data(sample_name, base_path, num_samples=1000, patch_size=64):
    """
    Build training patches from the sample folder - IMPROVED VERSION
    """
    print(f"üé® Creating realistic SEM data for {sample_name}")
    dirs = ensure_project_dirs(base_path)
    sample_dir = os.path.join(base_path, sample_name)

    # Collect all TIFF images
    tifs = []
    for root, _, files in os.walk(sample_dir):
        for fn in files:
            if fn.lower().endswith((".tif", ".tiff")):
                tifs.append(os.path.join(root, fn))

    if not tifs:
        print(f"‚ùå No TIFF images found in {sample_dir}, creating synthetic data")
        return create_synthetic_fallback_patches(num_samples, patch_size)

    all_tiles = []

    for tif_path in tifs:
        try:
            # Read image
            img = tifffile.imread(tif_path)
            print(f"üìä Loaded: {os.path.basename(tif_path)} - Shape: {img.shape}")

            # Handle different image formats
            if img.ndim == 3:
                img = img[..., 0] if img.shape[-1] in [1, 3] else np.mean(img, axis=2)

            # Ensure 2D
            if img.ndim != 2:
                img = img.squeeze()

            # Normalize to [0, 1]
            img = img.astype(np.float32)
            img = (img - img.min()) / (img.max() - img.min() + 1e-8)

            # Extract patches with overlap
            h, w = img.shape
            patch_stride = patch_size // 2  # 50% overlap

            for y in range(0, h - patch_size + 1, patch_stride):
                for x in range(0, w - patch_size + 1, patch_stride):
                    patch = img[y:y + patch_size, x:x + patch_size]

                    # Ensure correct size
                    if patch.shape == (patch_size, patch_size):
                        all_tiles.append(patch)

        except Exception as e:
            print(f"‚ö†Ô∏è Could not process {tif_path}: {e}")
            continue

    if not all_tiles:
        print("üîÑ No patches extracted, using synthetic data")
        return create_synthetic_fallback_patches(num_samples, patch_size)

    # Convert to array and limit samples
    tiles_array = np.array(all_tiles[:num_samples])
    tiles_array = np.expand_dims(tiles_array, axis=-1)  # Add channel dimension

    # Scale to [-1, 1] for GAN training
    tiles_array = tiles_array * 2.0 - 1.0

    # Save patches
    out_npz = os.path.join(dirs["Training_Data"], f"{sample_name}_patches.npz")
    np.savez_compressed(out_npz, patches=tiles_array)
    print(f"üíæ Saved {tiles_array.shape[0]} patches to {out_npz}")

    # Save visualization
    grid_path = os.path.join(dirs["Visualisations"], f"{sample_name}_patch_grid.png")
    show_tiles = (tiles_array * 0.5 + 0.5)[..., 0]  # Back to [0, 1]
    save_png_grid(show_tiles[:100], grid=(10, 10), tile_size=patch_size, out_path=grid_path)

    return tiles_array

def create_synthetic_fallback_patches(num_samples, patch_size):
    """Create synthetic mineral-like patterns as fallback"""
    patches = []
    for i in range(num_samples):
        # Create realistic mineral texture
        patch = np.random.rand(patch_size, patch_size) * 0.3  # Base

        # Add some mineral grains
        for _ in range(15):
            center_y, center_x = np.random.randint(0, patch_size, 2)
            size = np.random.randint(3, 10)
            grain = np.exp(-((np.arange(patch_size)[:, None] - center_y)**2 +
                           (np.arange(patch_size)[None, :] - center_x)**2) / (size**2))
            patch += grain * np.random.uniform(0.1, 0.3)

        patch = np.clip(patch, 0, 1)
        patches.append(patch)

    patches_array = np.array(patches)
    patches_array = np.expand_dims(patches_array, axis=-1)
    patches_array = patches_array * 2.0 - 1.0  # Scale to [-1, 1]

    return patches_array

import time, gc, numpy as np
import tensorflow as tf

# -- 0) Safe forward check used by train_unet_gpu --------------------------------
def safe_forward_check_timeout(model, x, y, timeout_sec=20):
    """
    Quickly runs a single forward-only step (no training) on CPU with timeout.
    Returns (ok, approx_loss, err_or_None).
    """
    ok = False
    approx_loss = np.nan
    err = None

    # Tiny slice, channel-safe
    x0 = x[:4]
    y0 = y[:4]
    x0 = tf.convert_to_tensor(x0, dtype=tf.float32)
    y0 = tf.convert_to_tensor(y0, dtype=tf.float32)

    # Ensure compiled (for consistent loss/meterics if later used)
    try:
        model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),
                      loss='categorical_crossentropy',
                      metrics=['accuracy'])
    except Exception:
        pass

    # Forward-only on CPU avoids first-batch cuDNN stalls on some Windows builds
    import threading
    res = {"loss": None, "err": None}

    def _run_forward():
        try:
            with tf.device('/CPU:0'):
                # lightweight warm-up
                _ = model(x0, training=False)
                # compute a quick categorical CE loss manually
                y_pred = model(x0, training=False)
                ce = tf.keras.losses.categorical_crossentropy(y0, y_pred)
                res["loss"] = float(tf.reduce_mean(ce).numpy())
        except Exception as e:
            res["err"] = e

    t = threading.Thread(target=_run_forward, daemon=True)
    t.start(); t.join(timeout_sec)

    if t.is_alive():
        err = TimeoutError(f"forward check timed out after {timeout_sec}s")
    elif res["err"] is not None:
        err = res["err"]
    else:
        ok = True
        approx_loss = res["loss"] if res["loss"] is not None else np.nan

    return ok, approx_loss, err

# -- 1) Synthetic labels used by train_unet_gpu ----------------------------------
def create_synthetic_labels(patches_gray, n_classes=5):
    """
    Fast, deterministic 5-class labels from intensity thresholds.
    Input: patches_gray (N,H,W) or (N,H,W,1) in [-1,1] or [0,1]
    Output: one-hot (N,H,W,5)
    """
    if patches_gray.ndim == 4:
        g = patches_gray[..., 0]
    else:
        g = patches_gray
    g = g.astype(np.float32)
    # Normalize to [0,1]
    g = (g - g.min()) / (g.max() - g.min() + 1e-8)

    # Percentile thresholds ‚Üí 5 bins
    t = np.percentile(g, [20, 40, 60, 80]).astype(np.float32)
    y = np.zeros(g.shape + (n_classes,), dtype=np.float32)
    y[..., 0] = (g <= t[0])
    y[..., 1] = (g >  t[0]) & (g <= t[1])
    y[..., 2] = (g >  t[1]) & (g <= t[2])
    y[..., 3] = (g >  t[2]) & (g <= t[3])
    y[..., 4] = (g >  t[3])
    return y

# -- 2) GPU mem cleanup used by DCGAN/UNet code ----------------------------------
def clear_gpu_memory():
    try:
        import tensorflow.keras.backend as K
        K.clear_session()
    except Exception:
        pass
    gc.collect()
    try:
        tf.config.experimental.reset_memory_stats('GPU:0')
    except Exception:
        pass

# -- 3) Batch size tuner used by DCGAN -------------------------------------------
def optimize_batch_size_for_gpu(suggested=32, floor=4, ceil=128):
    """
    Conservative heuristic for Windows/TF2.10: try to keep BS modest.
    """
    bs = int(suggested)
    try:
        gpus = tf.config.list_physical_devices('GPU')
        if not gpus:
            return max(floor, min(16, bs))
        # If memory info available, scale by free memory
        try:
            info = tf.config.experimental.get_memory_info('GPU:0')
            # free bytes to rough megabytes
            free_mb = info.get('current', 0)  # TF2.10 can be 'current' used; be defensive
            # If API returns used, just clamp
            if free_mb > 0:
                # fallback to suggested; TF on Windows often doesn‚Äôt expose free mem reliably
                pass
        except Exception:
            pass
    except Exception:
        pass
    # Keep modest to avoid cuDNN stalls; you can raise after first successful run
    return max(floor, min(32, ceil))

# -- 4) DCGAN/SliceGAN convenience builders (used in trainer) --------------------
def build_and_train_dcgan_from_patches(patches01, epochs=50, batch_size=32):
    """
    Builds minimal DCGAN models and trains them on 2D SEM patches in [0,1] or [-1,1].
    Returns (gen_model, disc_model) ‚Äî tf.keras.Model instances.
    """
    # Ensure shape: (N, 64, 64, 1)
    if patches01.ndim == 3:
        patches01 = np.expand_dims(patches01, -1)
    elif patches01.ndim != 4:
        patches01 = np.reshape(patches01, (-1, 64, 64, 1))

    gen = DCGAN_Generator(z_dim=100, out_hw=64, out_ch=1).model
    disc = DCGAN_Discriminator(in_hw=64, in_ch=1).model  # already compiled

    gen, disc = train_dcgan_gpu(gen, disc, patches01.astype(np.float32),
                                epochs=epochs, batch_size=batch_size)
    return gen, disc

def prepare_and_maybe_train_slicegan(existing_slicegan_like, real_2d_patches, epochs=30, batch_size=4):
    """
    If a proper SliceGAN object exists (with .generator/.discriminators/.latent_dim), trains it.
    Otherwise returns TinySliceGANFallback so generation never fails.
    """
    sg = ensure_slicegan(existing_slicegan_like)
    # If fallback was returned, it lacks discriminators ‚Üí skip training
    if isinstance(sg, TinySliceGANFallback):
        print("‚ÑπÔ∏è Using TinySliceGANFallback directly (no discriminators available).")
        return sg
    return train_slicegan_3d_gpu(sg, real_2d_patches, epochs=epochs, batch_size=batch_size)
# ======================================================================
def train_unet_gpu(model, patches, epochs=50, batch_size=32, force_cpu=False):
    """GPU-optimized U-Net training ‚Äî stable on TF 2.10 / Windows"""
    from tensorflow.keras.models import Model, Sequential
    from tensorflow.keras.layers import (
        Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate,
        Conv2DTranspose, BatchNormalization, ReLU, LeakyReLU, Flatten, Dense
    )
    from tensorflow.keras.optimizers import Adam
    print(f"üöÄ Training U-Net on {'CPU' if force_cpu else 'GPU'}: {epochs} epochs")

    # === PHASE 1: DATA VALIDATION ===
    print("üîç PHASE 1: Data validation...")
    if patches is None or len(patches) == 0:
        raise ValueError("‚ùå No training patches provided")

    print(f"üìä Input patches shape: {patches.shape}")
    print(f"üìä Input patches range: [{patches.min():.3f}, {patches.max():.3f}]")

    # === PHASE 2: DATA PREPARATION ===
    print("\nüìä PHASE 2: Data preparation...")
    if patches.ndim == 4 and patches.shape[-1] == 1:
        patches_gray = patches[..., 0]
    else:
        patches_gray = np.mean(patches, axis=-1) if patches.ndim == 4 else patches

    print(f"üìä Grayscale patches shape: {patches_gray.shape}")

    print("üîÑ Creating synthetic labels (with timeout protection)...")
    labels_categorical = create_synthetic_labels(patches_gray).astype("float32")

    if patches_gray.ndim == 3:
        patches_expanded = np.expand_dims(patches_gray, axis=-1)
    else:
        patches_expanded = patches

    print(f"üìä Final training data: {patches_expanded.shape}")
    print(f"üìä Labels shape: {labels_categorical.shape}")
    train_patches = patches_expanded
    train_labels  = labels_categorical

    # === PHASE 3: DATASET CREATION ===
    print("\nüîÑ PHASE 3: Dataset creation...")
    safe_batch_size = min(4, batch_size, len(patches_expanded))  # ‚Üê smaller first step
    steps_per_epoch = max(1, len(train_patches) // safe_batch_size)  # ‚Üê keep it tiny & quick for smoke test

    print(f"üîß Training configuration:")
    print(f"   ‚Ä¢ Batch size: {safe_batch_size}")
    print(f"   ‚Ä¢ Steps per epoch: {steps_per_epoch}")
    print(f"   ‚Ä¢ Total epochs: {epochs}")
    print(f"   ‚Ä¢ Training samples: {len(patches_expanded)}")

    # Single, stable pipeline (no warm-up with train_on_batch)
    dataset = tf.data.Dataset.from_tensor_slices((train_patches, train_labels))
    # Keep order to avoid parallel shuffle threads on Windows for the first smoke run
    # dataset = dataset.shuffle(min(1000, len(train_patches)), reshuffle_each_iteration=True)
    dataset = dataset.batch(safe_batch_size, drop_remainder=False)
    dataset = dataset.prefetch(1)

    opts = tf.data.Options()
    try:
        opts.experimental_deterministic = True
    except Exception:
        pass
    try:
        eo = opts.experimental_optimization
        if hasattr(eo, "apply_default_optimizations"): eo.apply_default_optimizations = False
        if hasattr(eo, "map_and_batch_fusion"):        eo.map_and_batch_fusion = False
        if hasattr(eo, "filter_fusion"):               eo.filter_fusion = False
        if hasattr(eo, "parallel_batch"):              eo.parallel_batch = False
        if hasattr(eo, "parallel_map"):                eo.parallel_map = False
    except Exception:
        pass
    dataset = dataset.with_options(opts)

    # === PHASE 4: MODEL VALIDATION (tiny CPU eager warm-up) ===
    print("üß™ PHASE 4: Model validation (CPU eager warm-up)...")
    try:
        model.build((None, train_patches.shape[1], train_patches.shape[2], train_patches.shape[3]))
    except Exception:
        pass

    ok, val_loss, err = safe_forward_check_timeout(model, train_patches, train_labels, timeout_sec=20)
    if ok:
        print(f"‚úÖ Forward check OK ‚Äî loss ~ {val_loss:.4f}")
    else:
        print(f"‚ùå Forward check failed ({err}). Switching to EmergencySimpleUNet...")
        from tensorflow.keras import Model
        from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D

        inputs = Input(shape=(train_patches.shape[1], train_patches.shape[2], train_patches.shape[3]))
        x = Conv2D(16, 3, activation='relu', padding='same')(inputs)
        x = MaxPooling2D(2)(x)
        x = Conv2D(32, 3, activation='relu', padding='same')(x)
        x = UpSampling2D(2)(x)
        x = Conv2D(16, 3, activation='relu', padding='same')(x)
        outputs = Conv2D(5, 1, activation='softmax', dtype='float32')(x)
        emergency = Model(inputs, outputs, name='EmergencySimpleUNet')

        emergency.compile(optimizer=tf.keras.optimizers.Adam(1e-3),
                          loss='categorical_crossentropy',
                          metrics=['accuracy'])

        ok2, val_loss2, err2 = safe_forward_check_timeout(emergency, train_patches, train_labels, timeout_sec=20)
        if ok2:
            print(f"‚úÖ Emergency model forward OK ‚Äî loss ~ {val_loss2:.4f}")
            model = emergency
        else:
            print(f"‚ùå Emergency model also failed ({err2}). Continuing without validation.")

    # === PHASE 5: CALLBACKS (define classes first, then append once) ===
    print("\n‚öôÔ∏è PHASE 5: Training configuration...")

    # --- 5.a) Dynamic steps_per_epoch (override the earlier smoke value) ---
    # Use full pass unless you explicitly opt into smoke via FAST_SMOKE=1
    SMOKE = os.environ.get("FAST_SMOKE", "0") == "1"
    steps_per_epoch = max(1, len(train_patches) // safe_batch_size)
    if SMOKE:
        # keep the tiny run in smoke mode
        steps_per_epoch = min(steps_per_epoch, 4)

    class AbortAfterBatches(tf.keras.callbacks.Callback):
        def __init__(self, max_batches=10):
            super().__init__()
            self.max_batches = max_batches
            self._count = 0
        def on_train_batch_end(self, batch, logs=None):
            self._count += 1
            if self._count >= self.max_batches:
                print(f"‚èπÔ∏è Stopping early after {self.max_batches} batches (smoke test).")
                self.model.stop_training = True

    class ComprehensiveTrainingCallback(tf.keras.callbacks.Callback):
        def __init__(self, total_epochs, steps_per_epoch):
            self.total_epochs = total_epochs
            self.steps_per_epoch = steps_per_epoch
            self.epoch_times = []
            self.start_time = time.time()
        def on_epoch_begin(self, epoch, logs=None):
            self.epoch_start = time.time()
            elapsed = time.time() - self.start_time
            avg_time = np.mean(self.epoch_times) if self.epoch_times else 0
            eta = avg_time * (self.total_epochs - epoch) if avg_time > 0 else 0
            print(f"\nüéØ Epoch {epoch+1}/{self.total_epochs} | Elapsed: {elapsed:.1f}s | ETA: {eta:.1f}s | {time.strftime('%H:%M:%S')}")
        def on_epoch_end(self, epoch, logs=None):
            epoch_time = time.time() - self.epoch_start
            self.epoch_times.append(epoch_time)
            if logs:
                loss = logs.get('loss', 'N/A')
                acc  = logs.get('accuracy', 'N/A')
                lr   = float(tf.keras.backend.get_value(self.model.optimizer.lr))
                print(f"‚úÖ Epoch {epoch+1} in {epoch_time:.1f}s | loss={loss:.4f} | acc={acc:.4f} | lr={lr:.2e}")
        def on_batch_end(self, batch, logs=None):
            if batch % max(1, self.steps_per_epoch // 4) == 0:
                progress = (batch + 1) / self.steps_per_epoch * 100
                loss = logs.get('loss', 'N/A') if logs else 'N/A'
                print(f"   ‚Ü≥ Progress: {progress:.1f}% | Batch Loss: {loss:.4f}")

    class BatchHeartbeat(tf.keras.callbacks.Callback):
        def __init__(self, steps_per_epoch):
            super().__init__()
            self.steps_per_epoch = steps_per_epoch
            self.t0 = None
        def on_train_begin(self, logs=None):
            self.t0 = time.time()
        def on_train_batch_begin(self, batch, logs=None):
            if batch == 0:
                print(f"   ‚Ü≥ Batch {batch+1}/{self.steps_per_epoch} ‚Ä¶")
        def on_train_batch_end(self, batch, logs=None):
            loss = logs.get('loss', 'N/A') if logs else 'N/A'
            print(f"   ‚Ü≥ Batch {batch+1}/{self.steps_per_epoch} done | loss={loss:.4f} | elapsed={time.time()-self.t0:.1f}s")

    callbacks = [
        tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1),
        tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True, verbose=1),
        ComprehensiveTrainingCallback(epochs, steps_per_epoch),
        BatchHeartbeat(steps_per_epoch),
    ]
    if SMOKE:
        # only insert the hard 10-batch stop in smoke mode
        callbacks.insert(2, AbortAfterBatches(max_batches=10))

    # Recompile to ensure no jit/xla sneaks in
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),
        loss='categorical_crossentropy',
        metrics=['accuracy'],
        jit_compile=False  # TF 2.10: be explicit
    )
    tf.config.set_soft_device_placement(True)

    # === PHASE 6: TRAINING EXECUTION ===
    print("\nüöÄ PHASE 6: Starting training execution...")

    # Clean Keras state before training (prevents lingering graphs/threads)
    try:
        import tensorflow.keras.backend as K
        K.clear_session()
    except Exception:
        pass
    import gc; gc.collect()

    # (A) Quick CPU NumPy smoke-step (no tf.data, no cuDNN)
    try:
        with tf.device('/CPU:0'):
            _hist_smoke = model.fit(
                train_patches[:16],        # tiny slice
                train_labels[:16],
                batch_size=4,
                epochs=1,
                verbose=1,
                shuffle=True
            )
        print("‚úÖ CPU NumPy smoke-step completed.")
    except Exception as e:
        print(f"‚ö†Ô∏è CPU NumPy smoke-step failed: {e}")

    # (B) Full U-Net training on CPU using the simple tf.data pipeline
    history = None
    try:
        with tf.device('/CPU:0'):
            # IMPORTANT: keep dataset simple (no shuffle on Windows first pass, small prefetch)
            dataset = tf.data.Dataset.from_tensor_slices((train_patches, train_labels))
            dataset = dataset.batch(safe_batch_size, drop_remainder=False)
            dataset = dataset.prefetch(1)

            opts = tf.data.Options()
            try: opts.experimental_deterministic = True
            except: pass
            try:
                eo = opts.experimental_optimization
                if hasattr(eo, "apply_default_optimizations"): eo.apply_default_optimizations = False
                if hasattr(eo, "map_and_batch_fusion"):        eo.map_and_batch_fusion = False
                if hasattr(eo, "filter_fusion"):               eo.filter_fusion = False
                if hasattr(eo, "parallel_batch"):              eo.parallel_batch = False
                if hasattr(eo, "parallel_map"):                eo.parallel_map = False
            except:
                pass
            dataset = dataset.with_options(opts)

            # Force minimal TF threading (helps avoid deadlocks on some Windows builds)
            try:
                tf.config.threading.set_inter_op_parallelism_threads(1)
                tf.config.threading.set_intra_op_parallelism_threads(1)
            except Exception:
                pass

            print("üßµ Running U-Net epoch(s) on CPU‚Ä¶")
            history = model.fit(
                dataset,
                epochs=epochs,
                steps_per_epoch=steps_per_epoch,
                callbacks=callbacks,
                verbose=1,
                shuffle=True,
                workers=0,
                use_multiprocessing=False
            )
        print("‚úÖ U-Net training completed successfully on CPU!")
    except Exception as e:
        print(f"‚ùå CPU U-Net training failed: {e}")

    if history is None:
        print("üîÑ Attempting fallback training with reduced parameters...")
        try:
            model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),
                          loss='categorical_crossentropy',
                          metrics=['accuracy'])
            with tf.device('/CPU:0'):
                history = model.fit(
                    dataset,
                    epochs=min(epochs, 5),
                    steps_per_epoch=max(1, steps_per_epoch // 2),
                    callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=2)],
                    verbose=1,
                    shuffle=True,
                    workers=0,
                    use_multiprocessing=False
                )
            print("‚úÖ Fallback training completed.")
        except Exception as e3:
            print(f"‚ùå Fallback training failed: {e3}")

    # === PHASE 7: POST-TRAINING ANALYSIS ===
    print("\nüìà PHASE 7: Post-training analysis...")
    if history and hasattr(history, 'history'):
        final_loss = history.history['loss'][-1]
        final_acc  = history.history.get('accuracy', [0])[-1]
        print(f"üìä Training Results:\n   ‚Ä¢ Final Loss: {final_loss:.4f}\n   ‚Ä¢ Final Accuracy: {final_acc:.4f}\n   ‚Ä¢ Total Epochs Completed: {len(history.history['loss'])}")
        if final_loss > 2.0: print("‚ö†Ô∏è High final loss detected.")
        if final_acc  < 0.3: print("‚ö†Ô∏è Low accuracy detected.")

    clear_gpu_memory()
    print("üéØ U-Net training pipeline completed")
    return history
# === ADD MANUAL TRAINING LOOP FUNCTION ===
def manual_training_loop(model, dataset, epochs, steps_per_epoch, callbacks):
    """Comprehensive manual training loop with full progress tracking"""
    print("üîÑ Starting COMPREHENSIVE manual training loop...")

    # Initialize history and metrics
    history = {'loss': [], 'accuracy': []}
    start_time = time.time()

    # Execute callbacks
    for callback in callbacks:
        if hasattr(callback, 'on_train_begin'):
            callback.on_train_begin()

    for epoch in range(epochs):
        print(f"\nüéØ Manual Epoch {epoch+1}/{epochs}")
        epoch_start = time.time()
        epoch_loss = 0
        epoch_accuracy = 0
        batch_count = 0

        # Execute epoch begin callbacks
        for callback in callbacks:
            if hasattr(callback, 'on_epoch_begin'):
                callback.on_epoch_begin(epoch)

        # Manual batch iteration
        for batch_idx, (x_batch, y_batch) in enumerate(dataset):
            if batch_idx >= steps_per_epoch:
                break

            # Execute batch begin callbacks
            for callback in callbacks:
                if hasattr(callback, 'on_batch_begin'):
                    callback.on_batch_begin(batch_idx)

            # Training step
            with tf.GradientTape() as tape:
                predictions = model(x_batch, training=True)
                loss = tf.keras.losses.categorical_crossentropy(y_batch, predictions)
                loss = tf.reduce_mean(loss)

            gradients = tape.gradient(loss, model.trainable_variables)
            model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))

            # Calculate metrics
            accuracy = tf.keras.metrics.categorical_accuracy(y_batch, predictions)
            accuracy = tf.reduce_mean(accuracy)

            epoch_loss += loss.numpy()
            epoch_accuracy += accuracy.numpy()
            batch_count += 1

            # Progress every 25% of batches
            if batch_idx % max(1, steps_per_epoch // 4) == 0:
                progress = (batch_idx + 1) / steps_per_epoch * 100
                print(f"   ‚Ü≥ Batch {batch_idx+1}/{steps_per_epoch} ({progress:.1f}%) - Loss: {loss.numpy():.4f}, Acc: {accuracy.numpy():.4f}")

            # Execute batch end callbacks
            for callback in callbacks:
                if hasattr(callback, 'on_batch_end'):
                    callback.on_batch_end(batch_idx, {'loss': loss.numpy(), 'accuracy': accuracy.numpy()})

        # Epoch summary
        avg_loss = epoch_loss / batch_count
        avg_accuracy = epoch_accuracy / batch_count
        history['loss'].append(avg_loss)
        history['accuracy'].append(avg_accuracy)

        epoch_time = time.time() - epoch_start
        total_time = time.time() - start_time

        print(f"‚úÖ Epoch {epoch+1} completed in {epoch_time:.1f}s")
        print(f"   ‚Ä¢ Avg Loss: {avg_loss:.4f}")
        print(f"   ‚Ä¢ Avg Accuracy: {avg_accuracy:.4f}")
        print(f"   ‚Ä¢ Total elapsed: {total_time:.1f}s")

        # Execute epoch end callbacks
        for callback in callbacks:
            if hasattr(callback, 'on_epoch_end'):
                callback.on_epoch_end(epoch, {'loss': avg_loss, 'accuracy': avg_accuracy})

        # Early stopping check
        if avg_loss < 0.1 and epoch > 5:
            print("üéØ Loss threshold reached - stopping early")
            break

# ========================
# TIMEOUT PROTECTION FUNCTION
# ========================
def train_with_timeout_protection(model, dataset, epochs, steps_per_epoch, timeout=300):
    """Training with timeout protection to prevent infinite hanging"""
    import threading
    import time

    def target():
        try:
            history = model.fit(
                dataset,
                epochs=epochs,
                steps_per_epoch=steps_per_epoch,
                verbose=1,
                callbacks=[tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=3)]
            )
            return history, None
        except Exception as e:
            return None, e

    result = [None]
    error = [None]

    def run_training():
        result[0], error[0] = target()

    thread = threading.Thread(target=run_training)
    thread.start()
    thread.join(timeout)

    if thread.is_alive():
        print(f"‚ùå Training timed out after {timeout} seconds")
        # Force stop and use manual training
        return manual_training_loop(model, dataset, min(epochs, 10), steps_per_epoch, [])

    if error[0]:
        print(f"‚ùå Training failed: {error[0]}")
        return manual_training_loop(model, dataset, min(epochs, 10), steps_per_epoch, [])

    return result[0]

# ========================
# SIMPLE DATASET FUNCTION
# ========================
# === END MANUAL TRAINING LOOP ===
def create_simple_dataset(patches, labels, batch_size=16):
    """Create simple, reliable dataset without caching that causes hanging"""
    print("üîÑ Creating simple, reliable dataset...")

    # Convert to tensors first
    patches_tensor = tf.convert_to_tensor(patches, dtype=tf.float32)
    labels_tensor = tf.convert_to_tensor(labels, dtype=tf.float32)

    # Create simple dataset
    dataset = tf.data.Dataset.from_tensor_slices((patches_tensor, labels_tensor))
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(2)  # Fixed small prefetch buffer

    # Quick validation
    for x, y in dataset.take(1):
        print(f"‚úÖ Dataset verified - Batch shape: {x.shape}, Labels: {y.shape}")

    return dataset
def debug_dataset_loading(patches, labels, batch_size=32):
    """Debug dataset loading to identify where it gets stuck - FIXED VERSION"""
    print("üîç Debugging dataset loading...")

    # Test 1: Check data shapes and types
    print(f"üìä Data shapes - Patches: {patches.shape}, Labels: {labels.shape}")
    print(f"üìä Data types - Patches: {patches.dtype}, Labels: {labels.dtype}")

    # Test 2: Create SIMPLE dataset without caching (main fix)
    print("üîÑ Creating SIMPLE dataset (no caching)...")

    try:
        # Use simpler dataset without cache() which can cause hanging
        dataset = tf.data.Dataset.from_tensor_slices((patches, labels))
        print("‚úÖ Step 1: from_tensor_slices - SUCCESS")

        dataset = dataset.batch(batch_size)
        print("‚úÖ Step 2: batch - SUCCESS")

        dataset = dataset.prefetch(2)  # Use fixed prefetch instead of AUTOTUNE
        print("‚úÖ Step 3: prefetch - SUCCESS")

    except Exception as e:
        print(f"‚ùå Dataset creation failed: {e}")
        return None

    # Test 3: Quick iteration test
    print("üîÑ Testing dataset iteration (quick test)...")
    batch_count = 0

    for batch_data, batch_labels in dataset.take(3):  # Only test 3 batches
        batch_count += 1
        print(f"‚úÖ Batch {batch_count}: data {batch_data.shape}, labels {batch_labels.shape}")

        # Quick validation
        if tf.reduce_any(tf.math.is_nan(batch_data)):
            print("‚ö†Ô∏è WARNING: NaN values detected!")
            return None

    print(f"üîç Dataset test completed: {batch_count} batches loaded")
    return dataset
# === END DATASET DEBUGGING FUNCTION ===
# === ADD TIMEOUT PROTECTION ===
import signal

class TimeoutError(Exception):
    pass

def timeout_handler(signum, frame):
    raise TimeoutError("Operation timed out")

def train_with_timeout(model, dataset, epochs, steps_per_epoch, callbacks, timeout=300):
    """Windows-safe training with thread timeout and manual fallback."""
    import threading, time

    result = {"history": None, "err": None}
    def _run():
        try:
            result["history"] = model.fit(
                dataset,
                epochs=epochs,
                steps_per_epoch=steps_per_epoch,
                callbacks=callbacks,
                verbose=1,
                validation_data=None
            )
        except Exception as e:
            result["err"] = e

    t = threading.Thread(target=_run, daemon=True)
    t.start(); t.join(timeout)

    if t.is_alive():
        print(f"‚ùå Training timed out after {timeout}s ‚Äî falling back to manual loop.")
        return manual_training_loop(model, dataset, min(epochs, 10), steps_per_epoch, callbacks)

    if result["err"] is not None:
        print(f"‚ö†Ô∏è Training failed: {result['err']} ‚Äî falling back to manual loop.")
        return manual_training_loop(model, dataset, min(epochs, 10), steps_per_epoch, callbacks)

    return result["history"]
# === END TIMEOUT PROTECTION ===
def train_dcgan_gpu(generator, discriminator, real_images, epochs=200, batch_size=32):
    """Windows/TF2.10-stable DCGAN training with eager warm-start and heartbeat."""
    print(f"üöÄ Training DCGAN on RTX 4060: {epochs} epochs")
    from tensorflow.keras.optimizers import Adam
    import tensorflow as tf, time, os

    # --- 0) Build once to ensure variables are created on GPU ---
    try:
        with tf.device('/GPU:0'):
            _ = generator(tf.random.normal([2, 100]), training=False)
            _ = discriminator(tf.zeros([2, 64, 64, 1]), training=False)
    except Exception as e:
        print(f"‚ö†Ô∏è Model build warm-up failed (continuing): {e}")

    # --- 1) Conservative batch size & dataset (avoid deadlocks) ---
    bs = optimize_batch_size_for_gpu(batch_size)
    real = tf.convert_to_tensor(real_images, dtype=tf.float32)
    if real.shape.rank == 3:
        real = tf.expand_dims(real, -1)
    # scale to [-1,1]
    rmin, rmax = tf.reduce_min(real), tf.reduce_max(real)
    real = (real - rmin) / (rmax - rmin + 1e-8)
    real = real * 2.0 - 1.0

    ds = tf.data.Dataset.from_tensor_slices(real)
    # small shuffle buffer + prefetch(1) is key on some Windows builds
    ds = ds.shuffle(min(512, max(64, bs * 8)), reshuffle_each_iteration=True)
    ds = ds.batch(bs, drop_remainder=True).prefetch(1)

    # --- 2) Optims & loss ---
    g_opt = Adam(learning_rate=2e-4, beta_1=0.5)
    d_opt = Adam(learning_rate=2e-4, beta_1=0.5)
    bce  = tf.keras.losses.BinaryCrossentropy(from_logits=False)

    # --- 3) Eager train step (stable), optional compiled step later ---
    def eager_train_step(images):
        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:
            with tf.device('/GPU:0'):
                z = tf.random.normal([tf.shape(images)[0], 100])
                fake = generator(z, training=True)

                real_out = discriminator(images, training=True)
                fake_out = discriminator(fake,   training=True)

                g_loss = bce(tf.ones_like(fake_out), fake_out)
                d_real = bce(tf.ones_like(real_out), real_out)
                d_fake = bce(tf.zeros_like(fake_out), fake_out)
                d_loss = d_real + d_fake

        g_grads = g_tape.gradient(g_loss, generator.trainable_variables)
        d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)
        g_opt.apply_gradients(zip(g_grads, generator.trainable_variables))
        d_opt.apply_gradients(zip(d_grads, discriminator.trainable_variables))
        return float(g_loss), float(d_loss)

    # After a few eager steps, we can optionally jit-compile a safe step
    @tf.function(jit_compile=False)
    def compiled_train_step(images):
        bs_ = tf.shape(images)[0]
        z   = tf.random.normal([bs_, 100])
        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:
            fake = generator(z, training=True)
            real_out = discriminator(images, training=True)
            fake_out = discriminator(fake,   training=True)
            g_loss = bce(tf.ones_like(fake_out), fake_out)
            d_real = bce(tf.ones_like(real_out), real_out)
            d_fake = bce(tf.zeros_like(fake_out), fake_out)
            d_loss = d_real + d_fake
        g_grads = g_tape.gradient(g_loss, generator.trainable_variables)
        d_grads = d_tape.gradient(d_loss, discriminator.trainable_variables)
        g_opt.apply_gradients(zip(g_grads, generator.trainable_variables))
        d_opt.apply_gradients(zip(d_grads, discriminator.trainable_variables))
        return g_loss, d_loss

    # --- 4) Smoke warm-start (eager) to avoid first-trace stalls ---
    print("üß™ DCGAN eager warm-start (2 mini-batches)‚Ä¶")
    warm_batches = 2
    wb = 0
    for xb in ds.take(warm_batches):
        gL, dL = eager_train_step(xb)
        wb += 1
        print(f"   ‚Ü≥ warm {wb}/{warm_batches} | g={gL:.4f} d={dL:.4f}")

    # Toggle smoke via env
    SMOKE = os.environ.get("FAST_SMOKE", "0") == "1"
    max_epochs = min(epochs, 5) if SMOKE else epochs
    heartbeat_every = max(1, 10)   # print every N batches

    # --- 5) Main loop with heartbeat + per-epoch timeout ---
    for epoch in range(max_epochs):
        epoch_start = time.time()
        g_sum = 0.0; d_sum = 0.0; n = 0
        print(f"\n‚ö° DCGAN Epoch {epoch+1}/{max_epochs} (bs={bs})")

        # choose step fn: compiled after warm, but fall back to eager on error
        use_compiled = True
        try:
            for bidx, batch in enumerate(ds):
                # Per-epoch timeout guard (e.g., 90s); adjust if needed
                if time.time() - epoch_start > 90:
                    print("‚è±Ô∏è Epoch timeout ‚Äî switching to eager for this epoch.")
                    use_compiled = False

                if use_compiled:
                    try:
                        g_loss_t, d_loss_t = compiled_train_step(batch)
                        g_loss = float(g_loss_t.numpy()); d_loss = float(d_loss_t.numpy())
                    except Exception as _e:
                        print(f"‚ö†Ô∏è Compiled step hiccup ‚Üí eager fallback: {_e}")
                        use_compiled = False
                        g_loss, d_loss = eager_train_step(batch)
                else:
                    g_loss, d_loss = eager_train_step(batch)

                g_sum += g_loss; d_sum += d_loss; n += 1

                if (bidx + 1) % heartbeat_every == 0:
                    print(f"   ‚Ü≥ batch {bidx+1:4d} | g={g_loss:.4f} d={d_loss:.4f}")

        except KeyboardInterrupt:
            print("‚õî Interrupted ‚Äî finishing current epoch summary.")
        except Exception as e:
            print(f"‚ùå Batch loop error (epoch {epoch+1}): {e}")
            print("‚Ü©Ô∏è Continuing with eager-only next epoch.")
            use_compiled = False

        if n == 0:
            print("‚ö†Ô∏è No batches this epoch; check dataset shapes.")
            break

        print(f"üéØ Epoch {epoch+1} | G: {g_sum/n:.4f} | D: {d_sum/n:.4f}")

        # Quick sample grid each epoch (try/except to never block)
        try:
            with tf.device('/GPU:0'):
                z = tf.random.normal([16, 100])
                gen_imgs = generator(z, training=False)
            gen_imgs = tf.clip_by_value(gen_imgs * 0.5 + 0.5, 0.0, 1.0).numpy()
            tiles = []
            for r in range(4):
                row = np.concatenate([gen_imgs[r*4+c, :, :, 0] for c in range(4)], axis=1)
                tiles.append(row)
            grid = np.concatenate(tiles, axis=0)
            vis_dir = os.path.join(os.path.dirname(__file__) if '__file__' in globals() else '.', "Visualisations")
            os.makedirs(vis_dir, exist_ok=True)
            out_png = os.path.join(vis_dir, f"dcgan_epoch_{epoch+1:03d}.png")
            import cv2
            cv2.imwrite(out_png, (grid*255).astype('uint8'))
            print(f"üñºÔ∏è Saved DCGAN preview: {out_png}")
        except Exception as _e:
            print(f"‚ö†Ô∏è Couldn‚Äôt save DCGAN preview: {_e}")

    clear_gpu_memory()
    print("‚úÖ DCGAN training completed")
    return generator, discriminator
def _dcgan_smoke_test(cgen, D, cond_batch, tgt_batch):
    """One forward/backward step to prove Stage-2 is wired correctly."""
    import tensorflow as tf
    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)
    g_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
    d_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

    @tf.function
    def step(c, y):
        with tf.GradientTape() as gt, tf.GradientTape() as dt:
            x_hat = cgen(c, training=True)
            Dy_real = D(tf.concat([c, y], axis=-1), training=True)
            Dy_fake = D(tf.concat([c, x_hat], axis=-1), training=True)

            # hinge losses
            d_loss = tf.reduce_mean(tf.nn.relu(1. - Dy_real)) + tf.reduce_mean(tf.nn.relu(1. + Dy_fake))
            l1 = tf.reduce_mean(tf.abs(y - x_hat))
            g_adv = -tf.reduce_mean(Dy_fake)
            g_loss = g_adv + 50.0 * l1

        g_grads = gt.gradient(g_loss, cgen.trainable_variables)
        d_grads = dt.gradient(d_loss, D.trainable_variables)
        g_opt.apply_gradients(zip(g_grads, cgen.trainable_variables))
        d_opt.apply_gradients(zip(d_grads, D.trainable_variables))
        return g_loss, d_loss

    gl, dl = step(cond_batch, tgt_batch)
    print(f"‚úÖ Stage-2 smoke test OK | G={float(gl):.3f} D={float(dl):.3f}")
def gradient_penalty(discriminator, real_images, fake_images):
    """Calculate gradient penalty for WGAN-GP"""
    batch_size = tf.shape(real_images)[0]
    epsilon = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)

    # Interpolate between real and fake images
    interpolated = epsilon * real_images + (1 - epsilon) * fake_images

    with tf.GradientTape() as tape:
        tape.watch(interpolated)
        interpolated_output = discriminator(interpolated, training=True)

    grads = tape.gradient(interpolated_output, interpolated)
    grads = tf.reshape(grads, [tf.shape(grads)[0], -1])
    grads_norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=1) + 1e-12)
    gradient_penalty = tf.reduce_mean((grads_norm - 1.0) ** 2)

    return gradient_penalty
def create_minimal_dcgan_generator():
    """Create minimal DCGAN generator as fallback"""
    from tensorflow.keras import Sequential
    from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, BatchNormalization, ReLU

    generator = Sequential([
        Dense(4*4*256, input_shape=(100,)),
        ReLU(),
        Reshape((4, 4, 256)),
        Conv2DTranspose(128, 4, strides=2, padding='same'),
        BatchNormalization(),
        ReLU(),
        Conv2DTranspose(64, 4, strides=2, padding='same'),
        BatchNormalization(),
        ReLU(),
        Conv2DTranspose(32, 4, strides=2, padding='same'),
        BatchNormalization(),
        ReLU(),
        Conv2DTranspose(1, 4, strides=2, padding='same', activation='tanh')
    ], name='Generator_Fallback')

    return generator
def train_slicegan_3d_gpu(slicegan, real_patches, epochs=30, batch_size=4):
    """GPU-optimized 3D SliceGAN training (single-GPU, TF2.10-safe)."""
    from tensorflow.keras.optimizers import Adam
    print(f"üöÄ Training 3D SliceGAN on GPU: {epochs} epochs")
    # If slicegan lacks proper discriminators/generator, skip training and return a safe fallback
    if not (hasattr(slicegan, "generator") and hasattr(slicegan, "discriminators") and slicegan.discriminators):
        print("‚ö†Ô∏è SliceGAN object missing discriminators ‚Üí skipping training and returning fallback.")
        return ensure_slicegan(slicegan)
    generator = slicegan.generator
    discriminators = slicegan.discriminators

    gen_opt = Adam(learning_rate=0.0002, beta_1=0.5)
    disc_opts = {name: Adam(learning_rate=0.0002, beta_1=0.5) for name in discriminators.keys()}
    bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)

    @tf.function
    def train_discriminators_step(real_slices):
        """One step updating all discriminators."""
        batch_size = tf.shape(real_slices)[0]
        noise = tf.random.normal([batch_size, slicegan.latent_dim])
        with tf.GradientTape(persistent=True) as tape:
            gen_vol = generator(noise, training=True)
            total_losses = {}
            for axis_name, disc in discriminators.items():
                if axis_name == 'xy':
                    fake_slices = gen_vol[:, :, :, tf.shape(gen_vol)[3]//2, 0]
                elif axis_name == 'xz':
                    fake_slices = gen_vol[:, :, tf.shape(gen_vol)[2]//2, :, 0]
                else:  # 'yz'
                    fake_slices = gen_vol[:, tf.shape(gen_vol)[1]//2, :, :, 0]
                fake_slices = tf.expand_dims(fake_slices, -1)

                real_out = disc(tf.cast(real_slices, tf.float32), training=True)
                fake_out = disc(tf.cast(fake_slices, tf.float32), training=True)

                real_loss = bce(tf.ones_like(real_out), real_out)
                fake_loss = bce(tf.zeros_like(fake_out), fake_out)
                disc_loss = 0.5 * (real_loss + fake_loss)
                total_losses[axis_name] = disc_loss

        for axis_name, disc in discriminators.items():
            grads = tape.gradient(total_losses[axis_name], disc.trainable_variables)
            disc_opts[axis_name].apply_gradients(zip(grads, disc.trainable_variables))
        del tape
        mean_disc = tf.add_n(list(total_losses.values())) / float(len(total_losses))
        return mean_disc

    @tf.function
    def train_generator_step():
        """One step updating the generator to fool all discriminators."""
        batch_size = tf.constant(batch_size_tf, dtype=tf.int32)
        noise = tf.random.normal([batch_size, slicegan.latent_dim])
        with tf.GradientTape() as tape:
            gen_vol = generator(noise, training=True)
            gen_loss = 0.0
            for axis_name, disc in discriminators.items():
                if axis_name == 'xy':
                    fake_slices = gen_vol[:, :, :, tf.shape(gen_vol)[3]//2, 0]
                elif axis_name == 'xz':
                    fake_slices = gen_vol[:, :, tf.shape(gen_vol)[2]//2, :, 0]
                else:
                    fake_slices = gen_vol[:, tf.shape(gen_vol)[1]//2, :, :, 0]
                fake_slices = tf.expand_dims(fake_slices, -1)
                fake_out = disc(tf.cast(fake_slices, tf.float32), training=False)
                gen_loss += bce(tf.ones_like(fake_out), fake_out)
            gen_loss = gen_loss / float(len(discriminators))
        grads = tape.gradient(gen_loss, generator.trainable_variables)
        gen_opt.apply_gradients(zip(grads, generator.trainable_variables))
        return gen_loss

    # Prepare dataset of real slices (take center slices once to simplify)
    def extract_center_slices(patches):
        # patches: (N, 64, 64, 1) ‚Üí already 2D; we just ensure shape (N, 64, 64, 1)
        if patches.ndim == 3:  # (N,64,64)
            patches4 = np.expand_dims(patches, -1)
        elif patches.ndim == 4:
            patches4 = patches
        else:
            patches4 = np.reshape(patches, (-1, 64, 64, 1))
        return patches4.astype(np.float32)

    real_slices = extract_center_slices(real_patches)  # (N,64,64,1)
    ds = tf.data.Dataset.from_tensor_slices(real_slices).shuffle(1024).batch(batch_size).prefetch(2)

    # Tensor for @tf.function capture
    global batch_size_tf
    batch_size_tf = tf.constant(batch_size, dtype=tf.int32)

    # Main loop: a few D steps then one G step (standard)
    for epoch in range(epochs):
        disc_losses = []
        gen_losses = []
        for real_batch in ds:
            # 2 discriminator steps per 1 generator step is common
            d1 = train_discriminators_step(real_batch)
            d2 = train_discriminators_step(real_batch)
            disc_losses.append((d1 + d2) * 0.5)
            g = train_generator_step()
            gen_losses.append(g)

        mean_d = float(tf.reduce_mean(disc_losses))
        mean_g = float(tf.reduce_mean(gen_losses))
        print(f"üéØ SliceGAN Epoch {epoch+1}/{epochs} | G: {mean_g:.4f} | D: {mean_d:.4f}")

    print("‚úÖ 3D SliceGAN training completed")
    return slicegan

def train_pix2pix_hinge(
    patches,            # (N,64,64,1) in [0,1]
    epochs=10,
    batch_size=16,
    l1_lambda=50.0,
    max_steps_per_epoch=60,     # hard cap so you always see progress
    quick_start=True            # do 1 epoch first to prove it works
):
    import tensorflow as tf
    import numpy as np
    from tensorflow.keras import layers, Model

    # --------- build condition maps (edges) once ----------
    def _to_edges(x):
        # simple Sobel magnitude; stay TF for speed
        kx = tf.constant([[1,0,-1],[2,0,-2],[1,0,-1]], tf.float32)
        ky = tf.transpose(kx)
        kx = tf.reshape(kx, [3,3,1,1]); ky = tf.reshape(ky, [3,3,1,1])
        gx = tf.nn.conv2d(x, kx, 1, "SAME"); gy = tf.nn.conv2d(x, ky, 1, "SAME")
        mag = tf.sqrt(gx*gx + gy*gy + 1e-8)
        mag = (mag - tf.reduce_min(mag)) / (tf.reduce_max(mag) - tf.reduce_min(mag) + 1e-8)
        return mag

    patches = tf.convert_to_tensor(patches, tf.float32)  # (N,64,64,1) [0,1]
    cond = _to_edges(patches) * 2.0 - 1.0                # [-1,1]
    tgt  = patches * 2.0 - 1.0                           # [-1,1]

    N = int(patches.shape[0])
    steps_per_epoch = max(1, min(max_steps_per_epoch, N // batch_size))

    # --------- define G (U-Net-ish) ----------
    def Conv(c, k, s=1):  # spectral norm wrapper optional; plain Conv2D is fine on CPU
        return layers.Conv2D(c, k, strides=s, padding="same", use_bias=False)

    def Down(x, c):
        x = Conv(c, 4, 2)(x); x = layers.LeakyReLU(0.2)(x)
        return x

    def Up(x, skip, c):
        x = layers.UpSampling2D(2)(x); x = Conv(c, 3)(x); x = layers.ReLU()(x)
        x = layers.Concatenate()([x, skip]); return x

    cin = layers.Input((64,64,1))
    d1 = Down(cin, 64)           # 32
    d2 = Down(d1, 128)           # 16
    d3 = Down(d2, 256)           # 8
    b  = Conv(512, 3)(d3); b = layers.ReLU()(b)
    u2 = Up(b, d2, 256)          # 16
    u1 = Up(u2, d1, 128)         # 32
    u0 = layers.UpSampling2D(2)(u1)
    out = Conv(1, 3)(u0)
    gout = layers.Activation("tanh")(out)
    G = Model(cin, gout, name="pix2pix_G")

    # --------- define D (PatchGAN) ----------
    din = layers.Input((64,64,2))  # cond||img
    x = Conv(64, 4, 2)(din);  x = layers.LeakyReLU(0.2)(x)     # 32
    x = Conv(128,4, 2)(x);    x = layers.LeakyReLU(0.2)(x)     # 16
    x = Conv(256,4, 2)(x);    x = layers.LeakyReLU(0.2)(x)     # 8
    x = Conv(512,4, 1)(x);    x = layers.LeakyReLU(0.2)(x)
    logit = Conv(1, 3, 1)(x)                                   # patch logits
    D = Model(din, logit, name="pix2pix_D")

    g_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
    d_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

    @tf.function
    def train_step(c, y):
        with tf.GradientTape() as gt, tf.GradientTape() as dt:
            y_hat = G(c, training=True)
            Dy_r  = D(tf.concat([c, y], axis=-1), training=True)
            Dy_f  = D(tf.concat([c, y_hat], axis=-1), training=True)

            # Hinge GAN losses
            d_loss = tf.reduce_mean(tf.nn.relu(1. - Dy_r)) + tf.reduce_mean(tf.nn.relu(1. + Dy_f))
            g_adv  = -tf.reduce_mean(Dy_f)
            l1     = tf.reduce_mean(tf.abs(y - y_hat))
            g_loss = g_adv + l1_lambda * l1

        g_grads = gt.gradient(g_loss, G.trainable_variables)
        d_grads = dt.gradient(d_loss, D.trainable_variables)
        g_opt.apply_gradients(zip(g_grads, G.trainable_variables))
        d_opt.apply_gradients(zip(d_grads, D.trainable_variables))
        return g_loss, d_loss, l1

    # --------- dataset with finite steps ----------
    ds = tf.data.Dataset.from_tensor_slices((cond, tgt)).shuffle(min(4096, N)).batch(batch_size).prefetch(2)
    it = iter(ds.repeat())  # manual stepping allows hard cap per epoch

    # ---- optional smoke test (1 step) ----
    _dcgan_smoke_test(G, D, *next(it))

    # --------- training loop with visible progress ----------
    for ep in range(1, epochs + 1):
        pb = tf.keras.utils.Progbar(steps_per_epoch, unit_name="step")
            # --- epoch accumulators ---
        gl_sum = 0.0
        dl_sum = 0.0
        l1_sum = 0.0
        for s in range(steps_per_epoch):
            c_b, y_b = next(it)
            gl, dl, l1 = train_step(c_b, y_b)
            # accumulate for epoch averages
            gl_sum += float(gl)
            dl_sum += float(dl)
            l1_sum += float(l1)

            # ‚úÖ Progress heartbeat every 20 steps
            if (s + 1) % 20 == 0 or (s + 1) == steps_per_epoch:
                tf.print(f"   ‚Ü≥ Stage-2 progress ‚Äî epoch:", ep, "step:", s + 1,
                         "| g_loss:", tf.round(gl, 3), "| d_loss:", tf.round(dl, 3))

            pb.update(s + 1, values=[("g", float(gl)), ("d", float(dl)), ("l1", float(l1))])

        # safe epoch averages
        avg_g  = gl_sum / max(1, steps_per_epoch)
        avg_d  = dl_sum / max(1, steps_per_epoch)
        avg_l1 = l1_sum / max(1, steps_per_epoch)
        print(f"‚úÖ Epoch {ep}/{(1 if quick_start else epochs)} | G={avg_g:.3f} D={avg_d:.3f} L1={avg_l1:.3f}")

    return G, D
# ---------------------------
# DCGAN Robust Helpers
# ---------------------------
def _safe_dcgan_dataset(real_images, batch_size=32):
    """Deterministic, tiny-prefetch dataset to avoid Windows/RTX stalls."""
    import tensorflow as tf
    x = tf.convert_to_tensor(real_images, dtype=tf.float32)
    if x.shape.rank == 3:  # (N,64,64)
        x = tf.expand_dims(x, -1)
    # Scale to [-1,1] robustly (even if already scaled)
    rmin = tf.reduce_min(x); rmax = tf.reduce_max(x)
    x = (x - rmin) / (rmax - rmin + 1e-8)
    x = x * 2.0 - 1.0
    ds = tf.data.Dataset.from_tensor_slices(x)
    ds = ds.shuffle(buffer_size=min(4096, x.shape[0]*4), reshuffle_each_iteration=True)
    ds = ds.batch(batch_size, drop_remainder=True)
    ds = ds.prefetch(1)  # keep tiny
    # turn off aggressive tf.data fusions on TF 2.10 Windows
    opts = tf.data.Options()
    try:
        opts.experimental_deterministic = True
        eo = opts.experimental_optimization
        if hasattr(eo, "apply_default_optimizations"): eo.apply_default_optimizations = False
        if hasattr(eo, "map_and_batch_fusion"):        eo.map_and_batch_fusion = False
        if hasattr(eo, "filter_fusion"):               eo.filter_fusion = False
        if hasattr(eo, "parallel_batch"):              eo.parallel_batch = False
        if hasattr(eo, "parallel_map"):                eo.parallel_map = False
    except Exception:
        pass
    return ds.with_options(opts)

class _DCGANWatchdog:
    """Time/Batch watchdog; aborts if no progress for `stall_sec` or total exceeds `max_time_sec`."""
    def __init__(self, max_time_sec=900, stall_sec=120):
        import time
        self.start = time.time()
        self.last_tick = time.time()
        self.max_time = max_time_sec
        self.stall = stall_sec
        self._batches = 0

    def tick(self):
        import time
        self._batches += 1
        self.last_tick = time.time()

    def should_abort(self):
        import time
        now = time.time()
        if (now - self.start) > self.max_time:
            print(f"‚è∞ DCGAN max time {self.max_time}s exceeded ‚Äî aborting safely.")
            return True
        if (now - self.last_tick) > self.stall:
            print(f"üßä DCGAN stall > {self.stall}s detected ‚Äî aborting this stage.")
            return True
        return False

def train_dcgan_gpu_robust(
    generator,
    discriminator,
    real_images,
    epochs=50,
    batch_size=32,
    max_time_sec=900,
    stall_sec=120,
    per_batch_log_every=10,
    gpu_smoke=True,
    gpu_smoke_timeout=8,
    max_gpu_smokes=1
):
    """
    Trains a DCGAN with hard caps on time, no dataset rebuild loops,
    and a single optional GPU smoke test. If anything smells bad ‚Üí CPU.
    """
    import time, threading
    import tensorflow as tf
    import numpy as np

    # ---------- Decide device ----------
    force_dev = os.environ.get("DCGAN_FORCE_DEVICE", "").upper().strip()
    skip_smoke = os.environ.get("DCGAN_SKIP_GPU_SMOKE", "0") == "1"
    have_gpu = bool(tf.config.list_physical_devices("GPU"))
    use_gpu = (force_dev != "CPU") and have_gpu

    # ---------- Optional GPU smoke (once) ----------
    if use_gpu and gpu_smoke and not skip_smoke:
        def _smoke_job(flag):
            try:
                with tf.device("/GPU:0"):
                    # deterministic generator (determinism was enabled earlier)
                    g = tf.random.Generator.from_seed(42)
                    z = g.normal((min(8, batch_size), 100))
                    _ = generator(z, training=False)
                    # tiny real batch to make sure data path is OK
                    x = tf.convert_to_tensor(real_images[:min(8, len(real_images))], dtype=tf.float32)
                    _ = discriminator(x, training=False)
                flag["ok"] = True
            except Exception:
                flag["ok"] = False

        flag = {"ok": False}
        t = threading.Thread(target=_smoke_job, args=(flag,), daemon=True)
        t.start(); t.join(gpu_smoke_timeout)
        if not flag["ok"] or t.is_alive():
            print(f"‚è±Ô∏è GPU smoke timed out/faulted ‚Üí using CPU for DCGAN.", flush=True)
            use_gpu = False
        else:
            print("‚úÖ GPU smoke passed ‚Äî proceeding on GPU.", flush=True)
    elif use_gpu and skip_smoke:
        print("‚è≠Ô∏è Skipping GPU smoke by request ‚Äî proceeding on GPU.", flush=True)

    device_str = "/GPU:0" if use_gpu else "/CPU:0"
    print(f"üß≠ DCGAN device: {('GPU' if use_gpu else 'CPU')}", flush=True)

    # ---------- Prep data once (no rebuilds) ----------
    imgs = real_images.astype(np.float32)
    if imgs.ndim == 3:  # (N,H,W) ‚Üí (N,H,W,1)
        imgs = imgs[..., None]

    ds = tf.data.Dataset.from_tensor_slices(imgs).shuffle(min(len(imgs), 1000))
    ds = ds.batch(min(batch_size, len(imgs))).prefetch(1)

    # ---------- Losses & optim ----------
    bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)
    d_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
    g_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

    # labels
    real_lab = tf.constant(1.0, dtype=tf.float32)
    fake_lab = tf.constant(0.0, dtype=tf.float32)

    # ---------- Train steps ----------
    @tf.function(jit_compile=False)
    def d_step(real_batch):
        z = tf.random.normal((tf.shape(real_batch)[0], 100), seed=42)  # seeded
        fake = generator(z, training=True)

        with tf.GradientTape() as tape:
            pred_real = discriminator(real_batch, training=True)
            pred_fake = discriminator(fake,        training=True)
            d_loss = bce(tf.ones_like(pred_real)*real_lab, pred_real) + \
                     bce(tf.ones_like(pred_fake)*fake_lab, pred_fake)
        grads = tape.gradient(d_loss, discriminator.trainable_variables)
        d_opt.apply_gradients(zip(grads, discriminator.trainable_variables))
        return d_loss

    @tf.function(jit_compile=False)
    def g_step(batch_sz):
        z = tf.random.normal((batch_sz, 100), seed=123)  # seeded
        with tf.GradientTape() as tape:
            fake = generator(z, training=True)
            pred = discriminator(fake, training=True)
            g_loss = bce(tf.ones_like(pred)*real_lab, pred)
        grads = tape.gradient(g_loss, generator.trainable_variables)
        g_opt.apply_gradients(zip(grads, generator.trainable_variables))
        return g_loss

    # ---------- Watchdogs ----------
    start_time = time.time()
    last_batch_time = time.time()

    def timed_out():
        return (time.time() - start_time) > max_time_sec

    # ---------- Main loop (no retries/rebuilds) ----------
    step = 0
    for epoch in range(1, int(epochs)+1):
        if timed_out():
            print(f"‚èπÔ∏è DCGAN max_time_sec hit ({max_time_sec}s). Ending.", flush=True)
            break

        for real_batch in ds:
            if timed_out():
                print(f"‚èπÔ∏è DCGAN max_time_sec hit ({max_time_sec}s). Ending.", flush=True)
                break

            with tf.device(device_str):
                # Discriminator, then Generator
                d_loss = d_step(real_batch)
                g_loss = g_step(tf.shape(real_batch)[0])

            step += 1
            now = time.time()
            if (now - last_batch_time) > stall_sec:
                print(f"‚èπÔ∏è Stall watchdog: >{stall_sec}s since last batch. Ending.", flush=True)
                break
            last_batch_time = now

            if step % per_batch_log_every == 0:
                print(f"   üß© step={step} | epoch={epoch}/{epochs} | "
                      f"d_loss={float(d_loss):.4f} | g_loss={float(g_loss):.4f} | device={'GPU' if use_gpu else 'CPU'}",
                      flush=True)

        else:
            # finished epoch normally
            continue
        # broke inner loop (timeout/stall) ‚Üí leave
        break

    print("‚úÖ DCGAN stage complete (robust).", flush=True)
    return generator, discriminator
# =========================
# Tiny 3D SliceGAN fallback (generator-only; fast & robust)
# =========================
class TinySliceGANFallback:
    """Lightweight 3D generator so generation works even if SliceGAN training fails."""
    def __init__(self, latent_dim: int = 128, volume_size: int = 64):
        from tensorflow.keras import Model
        from tensorflow.keras.layers import Input, Dense, Reshape, Conv3DTranspose, BatchNormalization, ReLU, Activation
        self.latent_dim = latent_dim
        self.volume_size = volume_size

        z = Input((self.latent_dim,))
        x = Dense((self.volume_size//8)*(self.volume_size//8)*(self.volume_size//8)*256)(z)
        x = ReLU()(x)
        x = Reshape((self.volume_size//8, self.volume_size//8, self.volume_size//8, 256))(x)
        x = Conv3DTranspose(128, 4, strides=2, padding="same")(x); x = BatchNormalization()(x); x = ReLU()(x)
        x = Conv3DTranspose(64,  4, strides=2, padding="same")(x); x = BatchNormalization()(x); x = ReLU()(x)
        x = Conv3DTranspose(32,  4, strides=2, padding="same")(x); x = BatchNormalization()(x); x = ReLU()(x)
        x = Conv3DTranspose(1,   3, strides=1, padding="same")(x)
        out = Activation("tanh")(x)  # [-1,1]
        from tensorflow.keras import Model as KModel
        self.generator = KModel(z, out, name="tiny_3d_generator")

# Ensure we always have a usable generator/latent_dim
def ensure_slicegan(slicegan_obj):
    if getattr(slicegan_obj, "generator", None) is not None and getattr(slicegan_obj, "latent_dim", None) is not None:
        return slicegan_obj
    print("‚ö†Ô∏è SliceGAN object incomplete ‚Üí using TinySliceGANFallback.")
    return TinySliceGANFallback(latent_dim=128, volume_size=64)
# ========= 2) Safe builder: create & train DCGAN the right way =========
def build_and_train_dcgan_from_patches(patches01, epochs=50, batch_size=32):
    """
    Builds minimal DCGAN models and trains them on 2D SEM patches in [0,1] or [-1,1] range.
    Returns (gen_model, disc_model) ‚Äî both are tf.keras.Model instances.
    """
    # Ensure proper shape: (N, 64, 64, 1)
    if patches01.ndim == 3:
        patches01 = np.expand_dims(patches01, -1)
    elif patches01.ndim != 4:
        patches01 = np.reshape(patches01, (-1, 64, 64, 1))

    # Build minimal DCGAN models (use .model ‚Äì NOT wrappers)
    gen = DCGAN_Generator(z_dim=100, out_hw=64, out_ch=1).model
    disc = DCGAN_Discriminator(in_hw=64, in_ch=1).model  # already compiled

    # Train
    gen, disc = train_dcgan_gpu_robust(
        generator=gen,
        discriminator=disc,
        real_images=patches01.astype(np.float32),
        epochs=epochs,
        batch_size=batch_size,
        max_time_sec=900,
        stall_sec=120,
        per_batch_log_every=10,
        gpu_smoke=True
    )


# ========= 3) Ensure SliceGAN object is valid before training or generation =========
def prepare_and_maybe_train_slicegan(existing_slicegan_like, real_2d_patches, epochs=30, batch_size=4):
    """
    If a proper SliceGAN object exists (with .generator/.discriminators/.latent_dim), trains it.
    Otherwise returns TinySliceGANFallback so generation never fails.
    """
    sg = ensure_slicegan(existing_slicegan_like)
    # If fallback was returned, skip training (no discriminators there)
    if isinstance(sg, TinySliceGANFallback):
        print("‚ÑπÔ∏è Using TinySliceGANFallback directly (no discriminators available).")
        return sg
    # Train on real patches (center slices path)
    sg = train_slicegan_3d_gpu(sg, real_2d_patches, epochs=epochs, batch_size=batch_size)
    return sg
def save_volume_preview_slices(volume, out_dir, prefix="volume"):
    """Save central XY/XZ/YZ slices + histogram for quick QA."""
    import matplotlib
    matplotlib.use("Agg")
    import matplotlib.pyplot as plt
    os.makedirs(out_dir, exist_ok=True)

    D, H, W = volume.shape
    zc, yc, xc = D//2, H//2, W//2

    # orthogonal slices
    fig, axes = plt.subplots(1, 3, figsize=(12, 4))
    axes[0].imshow(volume[zc], cmap='gray');  axes[0].set_title(f'XY z={zc}'); axes[0].axis('off')
    axes[1].imshow(volume[:, yc, :], cmap='gray'); axes[1].set_title(f'XZ y={yc}'); axes[1].axis('off')
    axes[2].imshow(volume[:, :, xc], cmap='gray'); axes[2].set_title(f'YZ x={xc}'); axes[2].axis('off')
    plt.tight_layout()
    plt.savefig(os.path.join(out_dir, f"{prefix}_orthogonal.png"), dpi=200, bbox_inches="tight")
    plt.close()

    # histogram
    plt.figure(figsize=(5,3))
    plt.hist(volume.ravel(), bins=64)
    plt.title("Voxel Intensity Histogram"); plt.tight_layout()
    plt.savefig(os.path.join(out_dir, f"{prefix}_hist.png"), dpi=200, bbox_inches="tight")
    plt.close()
def generate_final_3d_volume(
    slicegan_model,
    mineral_processor,
    sample_name,
    num_volumes: int = 1,
    save_path: str = "output",
    target_size: tuple = (192, 192, 192),
):
    """
    Generate a closed, continuous 3D volume from a (SliceGAN-like) generator and export:
      ‚Ä¢ 16-bit TIFF stack (x2: main + tiff_stack)
      ‚Ä¢ .npy volume
      ‚Ä¢ Visual preview PNG(s) if export_visuals() exists
      ‚Ä¢ Abaqus .inp (using export_compact_abaqus_inp or export_hex_voxel_inp fallback)
      ‚Ä¢ mechanical_properties_*.json

    Returns
    -------
    (volume_3d_float32_in_[0,1], properties_dict)
    """
    import os, json
    import numpy as np
    import tensorflow as tf
    import tifffile
    from scipy import ndimage

    # --- helpers used only inside this function ---
    class _NumpyEncoder(json.JSONEncoder):
        def default(self, o):
            import numpy as _np
            if isinstance(o, _np.ndarray):
                return o.tolist()
            if hasattr(o, "item"):
                try:
                    return o.item()
                except Exception:
                    pass
            return super().default(o)

    def _safe_dirs(base_root):
        # Prefer ensure_project_dirs if present; otherwise make a minimal set
        try:
            return ensure_project_dirs(base_root)  # noqa: F821
        except Exception:
            d = {
                "Training_Data": os.path.join(base_root, "Training_Data"),
                "Visualisations": os.path.join(base_root, "Visualisations"),
                "tiff_stack": os.path.join(base_root, "tiff_stack"),
                "abaqus": os.path.join(base_root, "abaqus"),
            }
            for p in d.values():
                os.makedirs(p, exist_ok=True)
            return d

    def _contrast_stretch01(vol, p_lo=1.0, p_hi=99.0):
        vmin = float(np.percentile(vol, p_lo))
        vmax = float(np.percentile(vol, p_hi))
        if vmax > vmin:
            vol = (vol - vmin) / (vmax - vmin)
        return np.clip(vol, 0.0, 1.0).astype(np.float32)

    def _validate_comp(five_phase):
        try:
            vals = np.array(list(five_phase.values()), dtype=float)
            if len(vals) == 0 or not np.isfinite(vals).all():
                raise ValueError
            s = float(vals.sum())
            if s <= 0:
                raise ValueError
            # normalize to 100 if it isn't already
            if abs(s - 100.0) > 1e-3:
                five_phase = {k: (float(v) / s) * 100.0 for k, v in five_phase.items()}
            return five_phase
        except Exception:
            print("   [COMP] Invalid/empty composition ‚Üí using defaults")
            return {"Silicates": 40.0, "Carbonate": 20.0, "Clay": 25.0, "Kerogen": 10.0, "Others": 5.0}

    def _approx_mech_props(vol, mp, sample_name, five_phase):
        # If calculate_mechanical_properties exists, use it; otherwise simple rule of mixtures
        try:
            return calculate_mechanical_properties(vol, mp, sample_name)  # noqa: F821
        except NameError:
            pass
        except Exception as e:
            print(f"   [MECH] detailed properties failed: {e} ‚Üí using mixture approx")

        # Simple volume-agnostic mixture using provided five_phase percentages
        E = 0.0
        rho = 0.0
        s = sum(float(v) for v in five_phase.values()) or 100.0
        for phase, pct in five_phase.items():
            frac = float(pct) / s
            try:
                Em = float(mp.get_phase_modulus(phase))
            except Exception:
                Em = 25.0
            try:
                rhom = float(mp.get_phase_density(phase))
            except Exception:
                rhom = 2.65
            E += frac * Em
            rho += frac * rhom
        return {
            "equivalent_youngs_modulus": float(E),
            "equivalent_density": float(rho),
            "phase_fractions": {k: float(v) / s for k, v in five_phase.items()},
        }

    # ---------- 0) Validate generator ----------
    if slicegan_model is None or not hasattr(slicegan_model, "generator"):
        print("‚ùå Invalid SliceGAN model provided ‚Üí fallback volume")
        return create_fallback_volume(sample_name, save_path, target_size)  # noqa: F821

    try:
        # ensure_slicegan should return the same object or a TinySliceGAN fallback
        try:
            slicegan_model = ensure_slicegan(slicegan_model)  # noqa: F821
        except NameError:
            # If ensure_slicegan is not defined, assume the passed model is usable
            pass

        print(f"üéØ Generating {num_volumes} continuous 3D volume(s) for {sample_name}...")
        os.makedirs(save_path, exist_ok=True)

        # ---------- 1) Run generator ----------
        tf.config.set_visible_devices([], 'GPU')  # Force CPU inference

        print("   [A] Sampling latent and running generator ...")
        zdim = int(getattr(slicegan_model, "latent_dim", 128))
        z = tf.random.normal([max(1, num_volumes), zdim])
        gen = slicegan_model.generator(z, training=False).numpy()
        gen = gen.astype(np.float32)
        print(f"   [A] Raw gen shape: {tuple(gen.shape)}, range=({gen.min():.4f},{gen.max():.4f})")

        # Expect TANH output in [-1,1] ‚Üí map to [0,1]; otherwise clip
        if float(gen.min()) < 0.0:
            gen = (gen * 0.5 + 0.5).astype(np.float32)
        else:
            gen = np.clip(gen, 0.0, 1.0).astype(np.float32)
        print(f"   [A] Normalized gen range=({gen.min():.4f},{gen.max():.4f})")

        # ---------- 2) Ensure 5D layout & extract one volume ----------
        print("   [B] Ensuring 5D layout and extracting single volume ...")
        if gen.ndim != 5:
            raise RuntimeError(f"Generator output must be 5D [N,D,H,W,C] or [N,H,W,D,C], got {gen.shape}")

        N, A, B, C, ch = gen.shape
        if ch != 1:
            raise RuntimeError(f"Last channel dimension must be 1, got {ch}")

        # Heuristic for orientation. If first three spatial dims are equal (e.g., 64,64,64), assume [N,D,H,W,1].
        # If the 4th is the one that matches (i.e., H,W,D), transpose.
        if A != B or B != C:
            # Ambiguous, but if gen[:1,:,:,:,0] slices along axis 3 look 2D, it's H,W,D ‚Üí transpose
            # We‚Äôll use a simple rule: if C is the "odd one" compared to A/B and equals A or B from a rotated view.
            # Safer path: prefer [N,D,H,W,1]. If the output looks wrong later, user can flip axes.
            vol = gen[0, ..., 0]  # (A,B,C)
        else:
            # Perfect cube ‚Üí assume already [D,H,W]
            vol = gen[0, ..., 0]  # (D,H,W)

        if vol.shape != target_size:
            zooms = tuple(t / s for t, s in zip(target_size, vol.shape))
            print(f"   [B] Resizing volume {vol.shape} ‚Üí {target_size} with zoom={tuple(round(z,3) for z in zooms)}")
            vol = ndimage.zoom(vol, zooms, order=1)  # linear, stable
        print(f"   [B] Post-size volume: {vol.shape}, range=({vol.min():.4f},{vol.max():.4f})")

        # ---------- 3) Composition ----------
        comp = {}
        try:
            comp = mineral_processor.get_sample_composition(sample_name) or {}
        except Exception as e:
            print(f"   [COMP] mineral_processor error: {e} ‚Üí using defaults")
        five_phase = _validate_comp(comp.get("five_phase_area", {}))
        print(f"   [COMP] Using composition: {five_phase}")

        # ---------- 4) Continuity / closure ----------
        print("   [C] Creating continuous/closed volume ...")
        vol_cont = None
        try:
            # Some impls expect 5D tensor
            vol_cont_5d = create_continuous_3d_volume(  # noqa: F821
                vol[None, ..., None],
                target_size=target_size,
                mineral_composition=five_phase,
            )
            vol_cont = np.asarray(vol_cont_5d)[0, ..., 0]
        except NameError:
            print("   [C] create_continuous_3d_volume not found ‚Üí skipping continuity step")
        except Exception as e:
            print(f"   [C] continuity step failed ({e}) ‚Üí using resized generator output")

        if vol_cont is None or vol_cont.shape != target_size:
            vol_cont = vol

        # Contrast stretch for visualization / IO robustness
        vol_final = _contrast_stretch01(vol_cont, 1.0, 99.0)

        # ---------- 5) Mechanical properties ----------
        print("   [D] Estimating mechanical properties ...")
        properties = _approx_mech_props(vol_final, mineral_processor, sample_name, five_phase)
        mat = {
            "E": float(properties.get("equivalent_youngs_modulus", 25.0)),
            "nu": 0.25,
            "rho": float(properties.get("equivalent_density", 2.65) * 1e-9),  # tonne/mm^3-ish
        }

        # ---------- 6) Paths & directories ----------
        vol_name = f"3d_volume_{sample_name}_realistic"
        # Derive a sensible base root for structured outputs
        if os.path.splitext(save_path)[1] == "":
            base_root = os.path.dirname(save_path)
        else:
            base_root = os.path.dirname(os.path.dirname(save_path))
        if not base_root:
            base_root = "."
        dirs = _safe_dirs(base_root)
        os.makedirs(save_path, exist_ok=True)
        print(f"   [PATHS] base_root={os.path.abspath(base_root)} | save_path={os.path.abspath(save_path)}")

        # ---------- 7) Save TIFF / NPY / Visuals ----------
        print("   [E] Saving volume artifacts ...")
        vout = vol_final.astype(np.float32)
        print(f"   [E] vout stats: min={vout.min():.4f} max={vout.max():.4f} mean={vout.mean():.4f}")

        # TIFF (main)
        tiff_main = os.path.join(save_path, f"{vol_name}.tiff")
        print(f"      ‚Üí TIFF (main): {tiff_main}")
        tifffile.imwrite(tiff_main, (vout * 65535).astype(np.uint16), bigtiff=False)

        # NPY
        npy_main = os.path.join(save_path, f"{vol_name}.npy")
        np.save(npy_main, vout)

        # TIFF (stack dir)
        tiff_stack_path = os.path.join(dirs["tiff_stack"], f"{vol_name}.tiff")
        print(f"      ‚Üí TIFF (stack): {tiff_stack_path}")
        tifffile.imwrite(tiff_stack_path, (vout * 65535).astype(np.uint16), bigtiff=False)
        save_volume_preview_slices(vol, save_path, prefix=vol_name)
        save_volume_preview_slices(vol, dirs["Visualisations"], prefix=vol_name)
        # Visual preview (if available)
        try:
            export_visuals(vout, save_path, prefix=vol_name)  # noqa: F821
            export_visuals(vout, dirs["Visualisations"], prefix=vol_name)  # noqa: F821
        except NameError:
            pass
        except Exception as e:
            print(f"   [E] export_visuals failed: {e}")

        # ---------- 8) Abaqus export ----------
        print("   [F] Abaqus export ...")
        try:
            # Optional refinement before meshing
            try:
                vol_closed = enhance_volume_continuity(vout, five_phase)  # noqa: F821
            except NameError:
                vol_closed = vout
            except Exception as e:
                print(f"   [F] enhance_volume_continuity failed: {e} ‚Üí using vout")
                vol_closed = vout

            thr = float(np.percentile(vol_closed, 55.0))
            inp_path = os.path.join(dirs["abaqus"], f"{vol_name}.inp")

            try:
                export_compact_abaqus_inp(vol_closed, inp_path, target_size_mb=5, threshold=thr, material=mat)  # noqa: F821
            except NameError:
                print("   [F] export_compact_abaqus_inp not found ‚Üí trying export_hex_voxel_inp")
                try:
                    export_hex_voxel_inp(volume=vol_closed, out_path=inp_path, voxel_step=3, threshold=thr, material=mat)  # noqa: F821
                except NameError:
                    # Minimal placeholder if no exporters exist
                    with open(inp_path, "w") as f:
                        f.write("*HEADING\nMinimal placeholder due to missing exporters\n")
                    print("   [F] Wrote minimal placeholder INP file (exporters unavailable).")
        except Exception as e:
            print(f"   [F] Abaqus export failed: {e}")

        # ---------- 9) Properties JSON ----------
        try:
            with open(os.path.join(save_path, f"mechanical_properties_{sample_name}.json"), "w") as f:
                json.dump(properties, f, indent=2, cls=_NumpyEncoder)
        except Exception as e:
            print(f"   [G] Could not write mechanical properties JSON: {e}")

        print(f"üíæ Saved continuous 3D volume + Abaqus INP for {sample_name}")
        print(
            f"üìä Equivalent E = {properties.get('equivalent_youngs_modulus', 0.0):.2f} GPa"
            f"  |  œÅ ‚âà {properties.get('equivalent_density', 0.0):.2f} g/cm¬≥"
        )
        return vout, properties

    except Exception as e:
        print(f"‚ùå generate_final_3d_volume failed: {e}")
        return create_fallback_volume(sample_name, save_path, target_size)  # noqa: F821








def create_fallback_volume(sample_name, save_path, target_size):
    """Create a simple fallback volume when main generation fails"""
    import numpy as np
    from scipy.ndimage import gaussian_filter

    print("üîÑ Creating fallback volume...")

    # Create simple volume
    volume = np.random.rand(*target_size).astype(np.float32)
    volume = gaussian_filter(volume, sigma=2.0)
    volume = (volume > 0.5).astype(np.float32)

    # Simple properties
    properties = {
        'equivalent_youngs_modulus': 25.0,
        'equivalent_density': 2.65,
        'phase_fractions': {'Silicates': 0.4, 'Carbonate': 0.25, 'Clay': 0.25, 'Kerogen': 0.05, 'Others': 0.05}
    }

    # Save basic files
    os.makedirs(save_path, exist_ok=True)
    tifffile.imwrite(os.path.join(save_path, f"3d_volume_{sample_name}_fallback.tiff"),
                    (volume * 65535).astype(np.uint16))

    print("‚úÖ Fallback volume created")
    return volume, properties
def calculate_equivalent_modulus(volumes, mineral_processor):
    """Calculate equivalent modulus for generated 3D volumes"""
    print("üìä Calculating equivalent modulus for 3D volumes...")

    equivalent_moduli = []

    # Define phase mapping with proper ordering
    phase_mapping = {
        0: 'Silicates',
        1: 'Carbonate',
        2: 'Clay',
        3: 'Kerogen',
        4: 'Others'
    }

    for i, volume in enumerate(volumes):
        # Ensure volume is properly normalized
        volume_norm = (volume - np.min(volume)) / (np.max(volume) - np.min(volume) + 1e-8)

        # Use more distinct thresholds for better phase separation
        thresholds = np.percentile(volume_norm, [15, 35, 65, 85])
        phase_volume = np.zeros_like(volume_norm, dtype=np.int8)

        # Assign phases with better separation
        phase_volume[volume_norm <= thresholds[0]] = 4  # Kerogen (darkest)
        phase_volume[(volume_norm > thresholds[0]) & (volume_norm <= thresholds[1])] = 3  # Clay
        phase_volume[(volume_norm > thresholds[1]) & (volume_norm <= thresholds[2])] = 2  # Others
        phase_volume[(volume_norm > thresholds[2]) & (volume_norm <= thresholds[3])] = 1  # Carbonate
        phase_volume[volume_norm > thresholds[3]] = 0  # Silicates (brightest)

        # Calculate volume fractions
        total_voxels = volume_norm.size
        phase_fractions = {}

        for phase_id, phase_name in phase_mapping.items():
            fraction = np.sum(phase_volume == phase_id) / total_voxels
            phase_fractions[phase_name] = fraction

        # Calculate equivalent modulus using rule of mixtures
        equivalent_modulus = 0
        for phase_name, fraction in phase_fractions.items():
            phase_modulus = mineral_processor.get_phase_modulus(phase_name)
            equivalent_modulus += fraction * phase_modulus

        equivalent_moduli.append(equivalent_modulus)
        print(f"üìà Volume {i+1}: Equivalent Modulus = {equivalent_modulus:.2f} GPa")
        print(f"   Phase fractions: {phase_fractions}")

    return np.array(equivalent_moduli)

def save_training_artifacts(models, volumes, moduli, save_path="output"):
    """Save all training artifacts and results"""
    print(f"üíæ Saving training artifacts to: {save_path}...")

    os.makedirs(save_path, exist_ok=True)

    # Save models
    for name, model in models.items():
        if name == 'unet':
            model.model.save(os.path.join(save_path, "trained_unet.h5"))
        elif name == 'dcgan_generator':
            model.save(os.path.join(save_path, "trained_dcgan_generator.h5"))
        elif name == 'slicegan':
            model.generator.save(os.path.join(save_path, "trained_slicegan_generator.h5"))

    # Save volumes and moduli
    np.save(os.path.join(save_path, "generated_3d_volumes.npy"), volumes)
    np.save(os.path.join(save_path, "equivalent_moduli.npy"), moduli)

    # Save summary with proper error handling
    summary = {
        'num_volumes_generated': len(volumes) if volumes is not None else 0,
        'volume_shape': volumes[0].shape if volumes is not None and len(volumes) > 0 else 'N/A',
        'mean_modulus': float(np.mean(moduli)) if moduli is not None and len(moduli) > 0 else 0.0,
        'std_modulus': float(np.std(moduli)) if moduli is not None and len(moduli) > 0 else 0.0,
        'min_modulus': float(np.min(moduli)) if moduli is not None and len(moduli) > 0 else 0.0,
        'max_modulus': float(np.max(moduli)) if moduli is not None and len(moduli) > 0 else 0.0
    }

    try:
        with open(os.path.join(save_path, "training_summary.json"), 'w') as f:
            json.dump(summary, f, indent=2, cls=NumpyEncoder)
        print("‚úÖ Training summary saved")
    except Exception as e:
        print(f"‚ö†Ô∏è Could not save training summary: {e}")

    print(f"‚úÖ All artifacts saved to '{save_path}'")
    return summary
# -------------------------
# Main Training Pipeline
# -------------------------

class TensorFlowShaleTrainer:
    def __init__(self, base_path, excel_filename):
        self.base_path = base_path
        # Ensure excel_filename is absolute path
        if not os.path.isabs(excel_filename):
            self.excel_filename = os.path.join(base_path, excel_filename)
        else:
            self.excel_filename = excel_filename
        self.models = {}

        # Check if paths exist
        if not os.path.exists(self.base_path):
            print(f"‚ö†Ô∏è Warning: Base path {self.base_path} does not exist")
        if not os.path.exists(self.excel_filename):
            print(f"‚ö†Ô∏è Warning: Excel file {self.excel_filename} does not exist")

    def train_ultra_fast(self, sample_name, epochs_unet=20, epochs_dcgan=50, epochs_slicegan=10):
        """ULTRA-FAST training pipeline with comprehensive error handling"""
        import os
        print(f"üöÄ STARTING ULTRA-FAST TENSORFLOW TRAINING for {sample_name}")
        print(f"üìà Training configuration:")
        print(f"   ‚Ä¢ U-Net: {epochs_unet} epochs")
        print(f"   ‚Ä¢ DCGAN: {epochs_dcgan} epochs")
        print(f"   ‚Ä¢ SliceGAN: {epochs_slicegan} epochs")

        # Create realistic training data from actual SEM images
        print("üìä Generating training data from real SEM images...")
        patches = create_realistic_sem_data(sample_name, self.base_path, num_samples=1000, patch_size=64)

        # Stage 1: Ultra-fast U-Net with comprehensive error handling
        print("\nüéØ Stage 1: Training U-Net (With Comprehensive Error Handling)")
        try:
            unet = ResidualAttentionUNet(input_size=(64, 64, 1), num_classes=5)

            # Train with conservative parameters and timeout protection
            print("üîÑ Attempting U-Net training with safety measures...")
            unet_history = train_unet_gpu(
                unet.model,
                patches,
                epochs=min(epochs_unet, 2),
                batch_size=8,
                force_cpu=True  # ‚Üê pin U-Net to CPU to avoid CUDA/cuDNN first-batch stall
            )
            self.models['unet'] = unet
            print("‚úÖ U-Net training completed successfully!")

        except Exception as e:
            print(f"‚ùå U-Net training failed: {e}")
            print("üîÑ Creating minimal U-Net as fallback...")
            try:
                minimal_model = create_minimal_unet(input_size=(64, 64, 1), num_classes=5)
                self.models['unet'] = type('Object', (), {'model': minimal_model})()
                print("‚úÖ Minimal U-Net created as fallback")
            except Exception as e2:
                print(f"‚ùå Minimal U-Net also failed: {e2}")
                print("üîÑ Skipping U-Net entirely to continue pipeline...")
                self.models['unet'] = skip_problematic_training_and_continue()

        # Clear memory after U-Net stage
        clear_gpu_memory()
        print("üßπ Cleared memory after U-Net stage")
        # ===== STAGE-2 WARM-UP (SAFE & SHORT) =====
        # Place this EXACTLY after "üßπ Cleared memory after U-Net stage"
        # and BEFORE printing "üéØ Stage 2: Training Conditional PatchGAN ..."
        import time
        import numpy as np
        import tensorflow as tf

        print("‚öôÔ∏è Warming up TensorFlow JIT & cuDNN before Stage-2... (max ~3s)")

        t0 = time.time()
        used_device = "CPU"
        try:
            gpus = tf.config.list_logical_devices('GPU')
            if gpus:
                # Do a tiny matmul on GPU to ensure kernels are loaded
                with tf.device('/GPU:0'):
                    a = tf.random.normal([256, 256])
                    b = tf.random.normal([256, 256])
                    _ = tf.linalg.matmul(a, b)[:1, :1].numpy()  # forces sync
                used_device = "GPU"

                # Tiny 3x3 conv pass to trigger cuDNN once (very fast)
                x = tf.random.normal([1, 16, 16, 1])
                conv = tf.keras.layers.Conv2D(8, 3, padding='same', activation=None)
                _ = conv(x).numpy()  # forces cuDNN/conv kernels to init
            else:
                # CPU fallback sanity op
                _ = np.dot(np.random.randn(64, 64), np.random.randn(64, 64))
            dt = time.time() - t0
            print(f"‚úÖ Warm-up ok in {dt:.2f}s on {used_device}\n")
        except Exception as e:
            dt = time.time() - t0
            print(f"‚ö†Ô∏è Warm-up skipped after {dt:.2f}s: {e}\n")
        # ============================================================
        # üéØ Stage 2: Conditional PatchGAN (pix2pix-hinge, spectral norm)
        #     Uses the same `patches` from Stage 1 as SEM targets.
        #     Condition = edge maps computed from the patches.
        # ============================================================
        import numpy as np
        print("\nüéØ Stage 2: Training Conditional PatchGAN (pix2pix-hinge, spectral norm)")

        # `patches` must be float32 in [0,1], shape (N,64,64,1) from Stage 1
        if 'patches' not in locals() and 'patches' not in globals():
            raise RuntimeError("Stage 2 requires `patches` from Stage 1 (shape: (N,64,64,1) in [0,1]).")

        # patches: (N,64,64,1) in [0,1] from Stage 1
        cgen, patchd = train_pix2pix_hinge(
            patches,
            epochs=max(epochs_dcgan, 2),   # keep your arg; function will quick-start with 1 epoch
            batch_size=16,                 # 16 keeps CPU snappy
            l1_lambda=50.0,
            max_steps_per_epoch=60,        # shows progress quickly
            quick_start=True               # runs 1 quick epoch first; set False later
        )
        self.models['cgan_generator'] = cgen
        self.models['cgan_discriminator'] = patchd
        print("‚úÖ pix2pix-hinge stage completed - Proceeding to SliceGAN / 3D")

        # ============================================================
        # üñºÔ∏è  quick visualization of 2D generator output
        # ============================================================
        import os, numpy as np, tifffile, matplotlib.pyplot as plt
        try:
            print("üñºÔ∏è Generating sample 2D outputs from trained pix2pix-hinge generator...")
            sample_c = patches[:8] * 2.0 - 1.0       # [-1,1]
            fake = cgen(sample_c, training=False).numpy()
            fake = (fake + 1.0) * 0.5                # back to [0,1]
            outdir = os.path.join(self.base_path, "output", sample_name)
            os.makedirs(outdir, exist_ok=True)
            grid = np.block([[fake[i*4+j, ..., 0] for j in range(4)] for i in range(2)])
            plt.imsave(os.path.join(outdir, "pix2pix_grid.png"), grid, cmap="gray")
            tifffile.imwrite(os.path.join(outdir, "pix2pix_tiles.tiff"),
                             (fake[...,0]*65535).astype(np.uint16))
            print(f"‚úÖ Saved Stage-2 previews to: {outdir}")
        except Exception as e:
            print(f"‚ö†Ô∏è Stage-2 visualization skipped: {e}")
        # ============================================================
        # üéØ Stage 3: 3D Volume Generation with Phase Enforcement
        #     1) Sample a 3D grayscale volume (SliceGAN if available; fallback otherwise)
        #     2) Enforce five-phase fractions (Silicates, Carbonate, Clay, Kerogen, Others)
        #     3) Save TIFF/NPY/visuals and export Abaqus .inp
        # ============================================================
        print("\nüéØ Stage 3: Generating 3D Volume with Phase Mapping")

        import time, os, numpy as np
        t0_stage = time.time()

        # ---------- Small inline helper: enforce five-phase fractions ----------
        def _enforce_phase_fractions(vol01, five_phase_pct,
                                     phase_order=('Silicates','Carbonate','Clay','Kerogen','Others')):
            """
            vol01: 3D float32 in [0,1], shape (D,H,W)
            five_phase_pct: dict with % per phase
            returns: int8 labels (0..4) following phase_order
            """
            v = np.asarray(vol01, dtype=np.float32)
            flat = v.ravel()
            N = flat.size
            tgt = np.array([max(0.0, float(five_phase_pct.get(k, 0.0))) for k in phase_order], dtype=np.float64)
            s = tgt.sum()
            if s <= 0: tgt = np.array([94.0,3.0,2.0,0.5,0.5], dtype=np.float64)
            tgt = tgt / tgt.sum()
            order_idx = np.argsort(-flat)  # bright‚Üídark (silicates brightest)
            cuts = np.cumsum(np.round(tgt * N)).astype(int)
            cuts[-1] = N
            labels = np.empty(N, dtype=np.int8)
            start = 0
            for pid, end in enumerate(cuts):
                idx = order_idx[start:end]
                labels[idx] = pid
                start = end
            return labels.reshape(v.shape)

        # ---------- get SliceGAN (if trained) or fallback volume ----------
        try:
            if 'slicegan' in self.models and hasattr(self.models['slicegan'], 'generator'):
                print("üß† Using trained SliceGAN generator")
                z = tf.random.normal([1, getattr(self.models['slicegan'], 'latent_dim', 128)])
                vol = self.models['slicegan'].generator(z, training=False).numpy()[0, :, :, :, 0]
            else:
                print("‚ö†Ô∏è SliceGAN missing ‚Üí using procedural geological fallback")
                vol = self._create_simple_geological_volume()  # your fast procedural method

            # Normalize to [0,1] robustly
            vmin, vmax = float(np.percentile(vol, 1.0)), float(np.percentile(vol, 99.0))
            vol = np.clip((vol - vmin) / (vmax - vmin + 1e-8), 0.0, 1.0).astype(np.float32)
            print(f"‚úÖ 3D grayscale volume ready: {vol.shape}")

        except Exception as e:
            print(f"‚ùå Volume sampling failed: {e}")
            vol = np.random.rand(128, 128, 128).astype(np.float32)
            print(f"üîÑ Fallback random volume: {vol.shape}")

        # ---------- Map grayscale to five phases using Excel composition ----------
        try:
            comp = AdvancedMineralProcessor(self.excel_filename)
            comp.load_and_parse_excel()
            phases_pct = comp.get_sample_composition(sample_name).get('five_phase_area', {})
        except Exception as e:
            print(f"‚ö†Ô∏è Excel parsing failed, using neutral fractions: {e}")
            phases_pct = {'Silicates': 70, 'Carbonate': 10, 'Clay': 15, 'Kerogen': 2.5, 'Others': 2.5}

        phase_order = ('Silicates','Carbonate','Clay','Kerogen','Others')
        phase_vol = _enforce_phase_fractions(vol, phases_pct, phase_order=phase_order)

        # ---------- Save outputs ----------
        print("\nüíæ PHASE B: Saving outputs...")
        dirs = ensure_project_dirs(self.base_path)

        # Save labeled TIFF (compact) + grayscale preview
        try:
            tifffile.imwrite(os.path.join(dirs["tiff_stack"], f"{sample_name}_phase_labels.tiff"),
                             phase_vol.astype(np.uint8))
            tifffile.imwrite(os.path.join(dirs["tiff_stack"], f"{sample_name}_sliceGAN_gray.tiff"),
                             (vol * 65535).astype(np.uint16))
            print(f"‚úÖ TIFFs saved to: {dirs['tiff_stack']}")
        except Exception as e:
            print(f"‚ö†Ô∏è TIFF save failed: {e}")

        # Save NPY volumes
        try:
            out_root = os.path.join(self.base_path, "output", sample_name)
            os.makedirs(out_root, exist_ok=True)
            np.save(os.path.join(out_root, f"3d_gray_{sample_name}.npy"), vol)
            np.save(os.path.join(out_root, f"3d_phase_{sample_name}.npy"), phase_vol.astype(np.int8))
            print(f"‚úÖ NPY volumes saved to: {out_root}")
        except Exception as e:
            print(f"‚ö†Ô∏è NPY save failed: {e}")

        # Quick visuals
        try:
            export_visuals(vol, dirs["Visualisations"], prefix=f"{sample_name}_3d_gray")
            export_visuals((phase_vol / 4.0).astype(np.float32), dirs["Visualisations"], prefix=f"{sample_name}_3d_phase")
            print("‚úÖ Visuals saved")
        except Exception as e:
            print(f"‚ö†Ô∏è Visuals failed: {e}")

        # ---------- Abaqus export (hex voxels) ----------
        print("\nüì¶ PHASE C: Generating Abaqus file...")
        try:
            # Choose a representative ‚Äúsolid‚Äù mask for meshing; e.g., silicates + carbonate
            solid_mask = np.logical_or(phase_vol == 0, phase_vol == 1).astype(np.float32)
            abaqus_path = os.path.join(dirs["abaqus"], f"3d_volume_{sample_name}.inp")

            # Equivalent properties from phase labels (optional: keep your earlier calculator)
            try:
                props = calculate_mechanical_properties(vol, comp, sample_name)
                Eeq = float(props.get('equivalent_youngs_modulus', 25.0))
                rho = float(props.get('equivalent_density', 2.65)) * 1e-9  # tonne/mm^3 approx.
            except Exception:
                Eeq, rho = 25.0, 2.65e-9

            _ = export_hex_voxel_inp(
                volume=solid_mask,               # binary field for voxels
                out_path=abaqus_path,
                voxel_step=3,                    # adjust for size/speed
                threshold=0.5,
                material={"E": Eeq, "nu": 0.25, "rho": rho}
            )
            print(f"‚úÖ Abaqus file: {abaqus_path}")
        except Exception as e:
            print(f"‚ö†Ô∏è Abaqus export failed: {e}")

        # ---------- Final summary ----------
        print("\nüìä PHASE D: Final summary")
        total_time = time.time() - t0_stage
        print(f"‚úÖ Stage 3 completed in {total_time:.1f}s")
        print(f"üéØ Final 3D volumes: gray={vol.shape}, labels={phase_vol.shape}")
        print("üéâ PIPELINE COMPLETED SUCCESSFULLY!")
        print("============================================================\n")

        return self.models

    def _create_simple_3d_generator(self, latent_dim=128, volume_size=64):
        """Create a simple 3D generator that won't hang"""
        import tensorflow as tf
        from tensorflow.keras import Sequential
        from tensorflow.keras.layers import Dense, Reshape, Conv3DTranspose, ReLU

        generator = Sequential([
            Dense(4*4*4*128, input_shape=(latent_dim,)),
            ReLU(),
            Reshape((4, 4, 4, 128)),
            Conv3DTranspose(64, 4, strides=2, padding='same'),
            ReLU(),
            Conv3DTranspose(32, 4, strides=2, padding='same'),
            ReLU(),
            Conv3DTranspose(16, 4, strides=2, padding='same'),
            ReLU(),
            Conv3DTranspose(1, 3, padding='same', activation='tanh')
        ], name='Simple_3D_Generator')

        # Build it
        _ = generator(tf.random.normal([1, latent_dim]))

        class Simple3DModel:
            def __init__(self, generator, latent_dim):
                self.generator = generator
                self.latent_dim = latent_dim
                self.discriminators = {}  # Add this to avoid errors

        return Simple3DModel(generator, latent_dim)
    def _create_mineral_map_patches(self, sample_name, num_patches=500, patch_size=64):
        """Create patches from mineral map images only for DCGAN training"""
        import os
        import numpy as np
        import tifffile
        import cv2

        sample_dir = os.path.join(self.base_path, sample_name)
        mineral_patches = []

        # Look for mineral map images specifically
        mineral_keywords = ['mineral', 'mineral_map', 'mineralmap', 'map']

        print(f"üîç Searching for mineral map images in: {sample_dir}")

        for root, _, files in os.walk(sample_dir):
            for filename in files:
                if filename.lower().endswith(('.tif', '.tiff')):
                    # Check if it's a mineral map image
                    is_mineral_map = any(keyword in filename.lower() for keyword in mineral_keywords)
                    if is_mineral_map and 'legend' not in filename.lower():
                        try:
                            filepath = os.path.join(root, filename)
                            img = tifffile.imread(filepath)
                            print(f"üé® Loading mineral map: {filename} - Shape: {img.shape}")

                            # Handle different image formats
                            if img.ndim == 3:
                                # For color mineral maps, we can use one channel or convert to grayscale
                                if img.shape[-1] == 3:  # RGB
                                    # Use the first channel or convert to grayscale
                                    img_gray = np.mean(img, axis=2)
                                else:
                                    img_gray = img[..., 0]  # Use first channel
                            else:
                                img_gray = img

                            # Normalize
                            img_gray = img_gray.astype(np.float32)
                            img_gray = (img_gray - img_gray.min()) / (img_gray.max() - img_gray.min() + 1e-8)

                            # Extract patches with overlap
                            h, w = img_gray.shape
                            patches_from_this_image = 0
                            max_patches_per_image = num_patches // 3  # Limit per image

                            for y in range(0, h - patch_size, patch_size // 2):  # 50% overlap
                                for x in range(0, w - patch_size, patch_size // 2):
                                    if patches_from_this_image >= max_patches_per_image:
                                        break
                                    patch = img_gray[y:y+patch_size, x:x+patch_size]
                                    if patch.shape == (patch_size, patch_size):
                                        mineral_patches.append(patch)
                                        patches_from_this_image += 1

                            print(f"‚úÖ Extracted {patches_from_this_image} patches from {filename}")

                        except Exception as e:
                            print(f"‚ö†Ô∏è Could not process {filename}: {e}")

        if mineral_patches:
            # Convert to array and scale to [-1, 1] for DCGAN
            patches_array = np.array(mineral_patches)
            patches_array = np.expand_dims(patches_array, axis=-1)  # Add channel dimension
            patches_array = patches_array * 2.0 - 1.0  # Scale to [-1, 1]

            print(f"üéØ Created {len(patches_array)} mineral map patches total")
            return patches_array
        else:
            print("‚ùå No mineral map patches could be extracted")
            return None

    def _train_dcgan_simple(self, real_patches, epochs=3, batch_size=16):
        """Simple DCGAN training that's less likely to hang"""
        import tensorflow as tf
        import time
        import numpy as np

        print(f"üöÄ Starting simple DCGAN training: {epochs} epochs")

        # Create models
        generator = self._create_simple_dcgan_generator()
        discriminator = self._create_dcgan_discriminator()

        # Simple training loop
        cross_entropy = tf.keras.losses.BinaryCrossentropy()
        g_optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)
        d_optimizer = tf.keras.optimizers.Adam(0.0002, 0.5)

        @tf.function
        def train_step(images):
            batch_size = tf.shape(images)[0]
            noise = tf.random.normal([batch_size, 100])

            with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
                generated_images = generator(noise, training=True)

                real_output = discriminator(images, training=True)
                fake_output = discriminator(generated_images, training=True)

                real_loss = cross_entropy(tf.ones_like(real_output), real_output)
                fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
                disc_loss = real_loss + fake_loss

                gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)

            # Apply gradients
            d_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)
            g_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)

            d_optimizer.apply_gradients(zip(d_gradients, discriminator.trainable_variables))
            g_optimizer.apply_gradients(zip(g_gradients, generator.trainable_variables))

            return disc_loss, gen_loss

        # Simple dataset
        dataset = tf.data.Dataset.from_tensor_slices(real_patches)
        dataset = dataset.shuffle(1000).batch(batch_size).prefetch(1)

        # Quick training
        for epoch in range(epochs):
            start_time = time.time()
            total_d_loss = 0
            total_g_loss = 0
            num_batches = 0

            for batch in dataset:
                d_loss, g_loss = train_step(batch)
                total_d_loss += d_loss
                total_g_loss += g_loss
                num_batches += 1

            if num_batches > 0:
                avg_d_loss = total_d_loss / num_batches
                avg_g_loss = total_g_loss / num_batches
                epoch_time = time.time() - start_time

                print(f"‚úÖ Epoch {epoch+1}/{epochs} | Time: {epoch_time:.1f}s | "
                      f"D Loss: {avg_d_loss:.4f} | G Loss: {avg_g_loss:.4f}")

            # Generate samples every epoch
            self._generate_dcgan_samples(generator, epoch + 1)

        print("üéØ DCGAN training completed!")
        return generator, discriminator
    def _create_simple_dcgan_generator(self):
        """Create a simple DCGAN generator"""
        import tensorflow as tf
        from tensorflow.keras import Sequential
        from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, BatchNormalization, ReLU

        generator = Sequential([
            Dense(4*4*512, input_shape=(100,)),
            BatchNormalization(),
            ReLU(),
            Reshape((4, 4, 512)),

            Conv2DTranspose(256, 4, strides=2, padding='same'),
            BatchNormalization(),
            ReLU(),

            Conv2DTranspose(128, 4, strides=2, padding='same'),
            BatchNormalization(),
            ReLU(),

            Conv2DTranspose(64, 4, strides=2, padding='same'),
            BatchNormalization(),
            ReLU(),

            Conv2DTranspose(1, 4, strides=2, padding='same', activation='tanh')
        ], name='DCGAN_Generator')

        return generator

    def _create_dcgan_discriminator(self):
        """Create DCGAN discriminator"""
        import tensorflow as tf
        from tensorflow.keras import Sequential
        from tensorflow.keras.layers import Conv2D, LeakyReLU, Dropout, Flatten, Dense, BatchNormalization

        discriminator = Sequential([
            Conv2D(64, 4, strides=2, padding='same', input_shape=(64, 64, 1)),
            LeakyReLU(0.2),
            Dropout(0.3),

            Conv2D(128, 4, strides=2, padding='same'),
            BatchNormalization(),
            LeakyReLU(0.2),
            Dropout(0.3),

            Conv2D(256, 4, strides=2, padding='same'),
            BatchNormalization(),
            LeakyReLU(0.2),
            Dropout(0.3),

            Conv2D(512, 4, strides=2, padding='same'),
            BatchNormalization(),
            LeakyReLU(0.2),
            Dropout(0.3),

            Flatten(),
            Dense(1, activation='sigmoid')
        ], name='DCGAN_Discriminator')

        discriminator.compile(
            optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),
            loss='binary_crossentropy',
            metrics=['accuracy']
        )

        return discriminator
    def _train_dcgan_working(self, real_patches, epochs=2, batch_size=16):
        """
        Robust, non-stall DCGAN training:
          ‚Ä¢ deterministic tf.data (no fancy fusions)
          ‚Ä¢ tiny prefetch, drop_remainder
          ‚Ä¢ CPU device by default (avoid Windows GPU first-batch stalls)
          ‚Ä¢ warmup forward passes
          ‚Ä¢ per-batch progress + stall watchdog
        Returns: trained generator (Keras Model)
        """
        import os, time
        import numpy as np
        import tensorflow as tf

        print(f"üöÄ Starting DCGAN training: {epochs} epochs, batch_size={batch_size}")

        # ---------- Sanitize data ----------
        x = np.asarray(real_patches)
        if x.ndim == 3:  # (N,H,W) -> (N,H,W,1)
            x = x[..., None]
        x = x.astype(np.float32)

        # Normalize to [-1,1] if not already
        xmin, xmax = float(x.min()), float(x.max())
        if xmin >= 0.0 and xmax <= 1.0:
            x = x * 2.0 - 1.0
        else:
            # robust minmax to [-1,1]
            p1, p99 = np.percentile(x, [1, 99])
            denom = (p99 - p1) if (p99 > p1) else (xmax - xmin + 1e-8)
            x = (x - p1) / (denom + 1e-8)
            x = np.clip(x, 0, 1) * 2.0 - 1.0

        # ---------- Build models ----------
        generator     = self._create_simple_dcgan_generator()
        discriminator = self._create_dcgan_discriminator()
        print("‚úÖ Models created, preparing dataset...")

        # ---------- Deterministic tf.data pipeline ----------
        ds = tf.data.Dataset.from_tensor_slices(x)
        ds = ds.shuffle(buffer_size=min(2048, x.shape[0]*4), seed=42, reshuffle_each_iteration=True)
        ds = ds.batch(min(batch_size, x.shape[0]), drop_remainder=True)
        ds = ds.prefetch(1)

        # Disable aggressive tf.data fusions that sometimes hang on Windows
        opts = tf.data.Options()
        try:
            opts.experimental_deterministic = True
            eo = opts.experimental_optimization
            if hasattr(eo, "apply_default_optimizations"): eo.apply_default_optimizations = False
            if hasattr(eo, "map_and_batch_fusion"):        eo.map_and_batch_fusion = False
            if hasattr(eo, "filter_fusion"):               eo.filter_fusion = False
            if hasattr(eo, "parallel_batch"):              eo.parallel_batch = False
            if hasattr(eo, "parallel_map"):                eo.parallel_map = False
        except Exception:
            pass
        ds = ds.with_options(opts)

        # ---------- Optimizers / losses ----------
        g_opt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)
        d_opt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)
        bce   = tf.keras.losses.BinaryCrossentropy()

        # ---------- Warmup (compile kernels & catch shape issues early) ----------
        with tf.device('/CPU:0'):
            try:
                warm = next(iter(ds))
            except StopIteration:
                raise RuntimeError("No batches available for DCGAN training (dataset empty after batching).")
            # one forward through G and D
            _ = generator(tf.random.normal([warm.shape[0], 100]), training=False)
            _ = discriminator(warm, training=False)
        print("üî• Warmup complete ‚Äî starting epochs")

        # ---------- Stall watchdog ----------
        MAX_EPOCH_SEC = 600      # hard cap per epoch
        STALL_SEC     = 45       # if a single step takes > this, abort epoch
        start_time_all = time.time()

        # Train steps (eager, no @tf.function to avoid long compile)
        def d_step(real_batch):
            bs = tf.shape(real_batch)[0]
            noise = tf.random.normal([bs, 100])
            with tf.GradientTape() as tape:
                fake = generator(noise, training=True)
                pr   = discriminator(real_batch, training=True)
                pf   = discriminator(fake, training=True)
                d_loss = bce(tf.ones_like(pr), pr) + bce(tf.zeros_like(pf), pf)
            grads = tape.gradient(d_loss, discriminator.trainable_variables)
            d_opt.apply_gradients(zip(grads, discriminator.trainable_variables))
            return d_loss

        def g_step(batch_size_i):
            noise = tf.random.normal([batch_size_i, 100])
            with tf.GradientTape() as tape:
                fake = generator(noise, training=True)
                pf   = discriminator(fake, training=True)
                g_loss = bce(tf.ones_like(pf), pf)
            grads = tape.gradient(g_loss, generator.trainable_variables)
            g_opt.apply_gradients(zip(grads, generator.trainable_variables))
            return g_loss

        # ---------- Main loop ----------
        with tf.device('/CPU:0'):
            global_step = 0
            for epoch in range(1, int(epochs) + 1):
                print(f"üîÅ Starting epoch {epoch}/{epochs}")
                epoch_start = time.time()
                last_tick   = time.time()
                d_sum = 0.0
                g_sum = 0.0
                n_batches = 0

                for batch in ds:
                    # Stall / timeout checks
                    now = time.time()
                    if now - epoch_start > MAX_EPOCH_SEC:
                        print(f"‚èπÔ∏è Epoch time exceeded {MAX_EPOCH_SEC}s ‚Äî stopping epoch {epoch}.")
                        break
                    if now - last_tick > STALL_SEC:
                        print(f"üßä Stall detected (> {STALL_SEC}s since last batch) ‚Äî stopping epoch {epoch}.")
                        break

                    # Steps
                    d_loss = d_step(batch)
                    g_loss = g_step(int(batch.shape[0]))

                    # Progress
                    global_step += 1
                    n_batches   += 1
                    d_sum += float(d_loss.numpy())
                    g_sum += float(g_loss.numpy())
                    last_tick = now

                    if (global_step % 10) == 0:
                        print(f"   ‚Ü≥ step {global_step:5d} | d_loss={float(d_loss):.4f} | g_loss={float(g_loss):.4f}", flush=True)

                if n_batches > 0:
                    print(f"‚úÖ Epoch {epoch}/{epochs} done | "
                          f"avg D={d_sum/n_batches:.4f} | avg G={g_sum/n_batches:.4f} | "
                          f"time={time.time()-epoch_start:.1f}s")
                else:
                    print(f"‚ö†Ô∏è No batches consumed in epoch {epoch} ‚Äî stopping training.")
                    break

                # quick sample each epoch
                try:
                    self._generate_dcgan_samples_simple(generator, epoch)
                except Exception as e:
                    print(f"‚ö†Ô∏è Sample gen failed: {e}")

        print(f"üéØ DCGAN training completed in {time.time()-start_time_all:.1f}s total.")
        return generator
    def _create_simple_geological_volume(self, size=(128, 128, 128)):
        """Create a simple geological-looking 3D volume without complex models"""
        import numpy as np
        from scipy.ndimage import gaussian_filter

        print("üèóÔ∏è Building geological volume...")

        # Start with random noise
        volume = np.random.rand(*size).astype(np.float32)

        # Add geological stratification
        z_coords = np.linspace(0, 4*np.pi, size[2])
        for i in range(size[0]):
            for j in range(size[1]):
                # Add layered structure
                layer_pattern = 0.3 * np.sin(z_coords * 2 + i*0.1 + j*0.1)
                volume[i, j, :] += layer_pattern

        # Apply smoothing for realistic continuity
        volume = gaussian_filter(volume, sigma=1.0)

        # Normalize to [0, 1]
        volume = (volume - volume.min()) / (volume.max() - volume.min() + 1e-8)

        # Create binary-ish volume (more realistic for rocks)
        threshold = np.percentile(volume, 60)
        volume = (volume > threshold).astype(np.float32)

        # Final smoothing
        volume = gaussian_filter(volume, sigma=0.5)
        volume = np.clip(volume, 0.0, 1.0)

        print(f"‚úÖ Geological volume created: {volume.shape}")
        return volume
    def _generate_dcgan_samples_simple(self, generator, epoch, sample_name="sample1"):
        """Quick sample generation"""
        import tensorflow as tf
        import numpy as np
        import os
        import cv2

        try:
            # Generate samples
            noise = tf.random.normal([16, 100])
            samples = generator(noise, training=False)
            samples = (samples * 0.5 + 0.5).numpy()

            # Use the correct path
            vis_dir = os.path.join(self.base_path, "Visualisations")
            os.makedirs(vis_dir, exist_ok=True)  # This ensures the folder exists

            # Create grid
            grid_rows = []
            for i in range(4):
                row = np.concatenate([samples[i*4+j, :, :, 0] for j in range(4)], axis=1)
                grid_rows.append(row)
            grid = np.concatenate(grid_rows, axis=0)

            # Save with correct filename
            filename = os.path.join(vis_dir, f"{sample_name}_dcgan_epoch_{epoch:02d}.png")
            success = cv2.imwrite(filename, (grid * 255).astype(np.uint8))

            if success:
                print(f"üíæ Saved DCGAN samples: {filename}")
            else:
                print(f"‚ùå Failed to save: {filename}")

        except Exception as e:
            print(f"‚ö†Ô∏è Could not generate DCGAN samples: {e}")
    def _train_dcgan_comprehensive(self, real_patches, epochs=10, batch_size=16):
        """Comprehensive DCGAN training with proper error handling"""
        import tensorflow as tf
        import time
        import numpy as np  # ADD THIS IMPORT

        print(f"üöÄ Starting comprehensive DCGAN training: {epochs} epochs, batch_size={batch_size}")

        # Ensure proper data format
        if real_patches.ndim == 3:
            real_patches = np.expand_dims(real_patches, -1)

        # Normalize to [-1, 1] if needed
        if real_patches.min() >= 0:
            real_patches = real_patches * 2.0 - 1.0

        # Create models
        generator = self._create_simple_dcgan_generator()
        discriminator = self._create_dcgan_discriminator()

        print(f"‚úÖ Generator parameters: {generator.count_params():,}")
        print(f"‚úÖ Discriminator parameters: {discriminator.count_params():,}")

        # Optimizers
        g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)
        d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)

        # Loss function
        cross_entropy = tf.keras.losses.BinaryCrossentropy()

        # Training metrics
        g_loss_metric = tf.keras.metrics.Mean()
        d_loss_metric = tf.keras.metrics.Mean()

        @tf.function
        def train_step(images):
            batch_size = tf.shape(images)[0]

            # Generate noise
            noise = tf.random.normal([batch_size, 100])

            with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
                # Generate images
                generated_images = generator(noise, training=True)

                # Discriminator predictions
                real_output = discriminator(images, training=True)
                fake_output = discriminator(generated_images, training=True)

                # Calculate losses
                real_loss = cross_entropy(tf.ones_like(real_output), real_output)
                fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
                disc_loss = real_loss + fake_loss

                gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)

            # Apply gradients
            gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)
            gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)

            d_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))
            g_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))

            return disc_loss, gen_loss

        # Create dataset
        dataset = tf.data.Dataset.from_tensor_slices(real_patches)
        dataset = dataset.shuffle(buffer_size=1000)
        dataset = dataset.batch(batch_size)
        dataset = dataset.prefetch(tf.data.AUTOTUNE)

        # Training loop
        for epoch in range(epochs):
            start_time = time.time()

            # Reset metrics
            g_loss_metric.reset_states()
            d_loss_metric.reset_states()

            # Train on batches
            for image_batch in dataset:
                disc_loss, gen_loss = train_step(image_batch)
                d_loss_metric(disc_loss)
                g_loss_metric(gen_loss)

            # Epoch summary
            epoch_time = time.time() - start_time
            g_loss = g_loss_metric.result()
            d_loss = d_loss_metric.result()

            print(f"‚úÖ Epoch {epoch+1}/{epochs} | Time: {epoch_time:.1f}s | "
                  f"G Loss: {g_loss:.4f} | D Loss: {d_loss:.4f}")

            # Generate sample images every few epochs
            if (epoch + 1) % 2 == 0 or epoch == epochs - 1:
                self._generate_dcgan_samples(generator, epoch + 1)

        print("üéØ DCGAN training completed successfully!")
        return generator, discriminator

    def _generate_dcgan_samples(self, generator, epoch, sample_name="sample1"):
        """Generate and save DCGAN sample images"""
        import tensorflow as tf
        import matplotlib.pyplot as plt
        import os
        import numpy as np

        try:
            # Generate samples
            noise = tf.random.normal([16, 100])
            generated_images = generator(noise, training=False)
            generated_images = (generated_images * 0.5 + 0.5).numpy()  # [-1,1] -> [0,1]

            # Create visualization directory
            vis_dir = os.path.join(self.base_path, "Visualisations")
            os.makedirs(vis_dir, exist_ok=True)

            # Create figure
            fig, axes = plt.subplots(4, 4, figsize=(8, 8))
            for i, ax in enumerate(axes.flat):
                ax.imshow(generated_images[i, :, :, 0], cmap='gray')
                ax.axis('off')

            plt.suptitle(f'DCGAN Generated Samples - Epoch {epoch}')
            plt.tight_layout()

            # Save figure
            filename = os.path.join(vis_dir, f"{sample_name}_dcgan_epoch_{epoch:02d}.png")
            plt.savefig(filename, dpi=150, bbox_inches='tight')
            plt.close()

            print(f"üíæ Saved DCGAN samples: {filename}")

        except Exception as e:
            print(f"‚ö†Ô∏è Could not generate DCGAN samples: {e}")

# -------------------------
# Visualization and Results
# -------------------------

def visualize_results(models, outdir="output", show=False):
    import os
    import matplotlib
    matplotlib.use("Agg")  # non-interactive; never blocks
    import matplotlib.pyplot as plt

    os.makedirs(outdir, exist_ok=True)

    # ---- DCGAN grid ----
    if 'cgan_generator' in models:
        print("üé® Generating conditional (pix2pix) samples...")
        # Take a few target patches just to produce their conditions
        # If you saved patches to disk, load them; otherwise skip plotting
        try:
            # example: use a small synthetic condition for preview
            demo = np.random.rand(16,64,64,1).astype(np.float32)
            cond = make_condition_maps(demo)  # [-1,1]
            pred = models['cgan_generator'](cond, training=False).numpy()  # [-1,1]
            pred = (pred + 1.0) * 0.5  # back to [0,1]

            plt.figure(figsize=(10,10))
            for i in range(16):
                plt.subplot(4,4,i+1)
                plt.imshow(pred[i,:,:,0], cmap='gray', vmin=0, vmax=1)
                plt.axis('off')
            plt.suptitle('pix2pix-Hinge Generated SEM-like Images')
            plt.tight_layout()
            plt.savefig(os.path.join(output_path, 'pix2pix_sem_samples.png'), dpi=300, bbox_inches='tight')
            plt.show()
        except Exception as _:
            print("‚ö†Ô∏è Preview skipped (no sample conditions).")
    # ---- SliceGAN orthogonal slices ----
    if 'slicegan' in models and hasattr(models['slicegan'], 'generator') and models['slicegan'].generator is not None:
        print("üé® Generating 3D SliceGAN samples...")
        noise = tf.random.normal([1, getattr(models['slicegan'], 'latent_dim', 128)])
        generated_volume = models['slicegan'].generator(noise)
        v = generated_volume[0, :, :, :, 0].numpy()

        fig, axes = plt.subplots(2, 3, figsize=(12, 8))
        slices = [0, v.shape[2]//4, v.shape[2]//2, 3*v.shape[2]//4, v.shape[2]-1]
        for i, z in enumerate(slices[:3]):
            axes[0, i].imshow(v[:, :, z], cmap='viridis')
            axes[0, i].set_title(f'XY z={z}'); axes[0, i].axis('off')
        for i, y in enumerate(slices[2:5]):
            axes[1, i].imshow(v[:, y, :], cmap='viridis')
            axes[1, i].set_title(f'XZ y={y}'); axes[1, i].axis('off')

        plt.suptitle('3D SliceGAN Generated Volume Slices')
        plt.tight_layout()
        plt.savefig(os.path.join(outdir, 'slicegan_generated_volume.png'), dpi=300, bbox_inches='tight')
        if show:
            plt.show()
        plt.close()

def export_abaqus_input(volume, properties, output_path="abaqus_model.inp"):
    """Export Abaqus input file for the generated 3D model"""
    print("üì§ Exporting Abaqus input file...")

    # Create simple Abaqus input file
    with open(output_path, 'w') as f:
        f.write("*HEADING\n")
        f.write(f"3D Shale Model - Equivalent Young's Modulus: {properties['equivalent_youngs_modulus']:.2f} GPa\n")
        f.write("**\n")
        f.write("*PREPRINT, ECHO=NO, MODEL=NO, HISTORY=NO, CONTACT=NO\n")
        f.write("**\n")
        f.write("** PARTS\n")
        f.write("**\n")
        f.write("*PART, NAME=SHALE_MODEL\n")
        f.write("**\n")
        f.write("** MATERIALS\n")
        f.write("**\n")
        f.write("*MATERIAL, NAME=SHALE_MATERIAL\n")
        f.write("*ELASTIC\n")
        f.write(f"{properties['equivalent_youngs_modulus']:.2f}, 0.3\n")
        f.write("*DENSITY\n")
        f.write(f"{properties['equivalent_density']:.2f}\n")
        f.write("**\n")
        f.write("** END OF DATA\n")

    print(f"‚úÖ Abaqus input file saved: {output_path}")
def save_models(models):
    """Save trained models"""
    print("\nüíæ SAVING MODELS...")

    for name, model in models.items():
        if name == 'unet':
            model.model.save('trained_unet_model.h5')
            print(f"‚úÖ Saved U-Net as 'trained_unet_model.h5'")
        elif name == 'dcgan_generator':
            model.save('trained_dcgan_generator.h5')
            print(f"‚úÖ Saved DCGAN Generator as 'trained_dcgan_generator.h5'")
        elif name == 'dcgan_discriminator':
            model.save('trained_dcgan_discriminator.h5')
            print(f"‚úÖ Saved DCGAN Discriminator as 'trained_dcgan_discriminator.h5'")
        elif name == 'slicegan':
            model.generator.save('trained_slicegan_generator.h5')
            print(f"‚úÖ Saved SliceGAN Generator as 'trained_slicegan_generator.h5'")

def print_training_summary(models, total_time):
    """Print comprehensive training summary"""
    print("\n" + "="*50)
    print("üéØ TRAINING SUMMARY")
    print("="*50)
    print(f"‚è±Ô∏è  Total Training Time: {total_time:.1f} seconds")
    print(f"ü§ñ Models Trained: {len(models)}")
    print("\nüìà Model Details:")
    print("  ‚Ä¢ Residual Attention U-Net - Semantic Segmentation")
    print("  ‚Ä¢ DCGAN - 2D Image Generation")
    print("  ‚Ä¢ 3D SliceGAN - Volume Generation")
    print("\nüéØ Next Steps:")
    print("  ‚Ä¢ Use U-Net for mineral phase segmentation")
    print("  ‚Ä¢ Generate new SEM images with DCGAN")
    print("  ‚Ä¢ Create 3D volumes with SliceGAN")
    print("  ‚Ä¢ Load models for inference: keras.models.load_model('model_name.h5')")
    print("="*50)

# ========================
# FINAL GPU VERIFICATION
# ========================

def verify_gpu_setup():
    """Final verification that GPU is properly configured"""
    print("\nüîç Final GPU Setup Verification...")

    # Check GPU devices
    gpus = tf.config.list_physical_devices('GPU')
    if not gpus:
        print("‚ùå CRITICAL: No GPU detected! Running on CPU will be very slow.")
        return False

    print(f"‚úÖ GPU detected: {len(gpus)} device(s)")

    # Test GPU computation
    try:
        with tf.device('/GPU:0'):
            # Large computation to verify GPU is working
            a = tf.random.normal((1000, 1000))
            b = tf.random.normal((1000, 1000))
            c = tf.matmul(a, b)
            result = tf.reduce_sum(c)

        print("‚úÖ GPU computation test passed")
        print(f"‚úÖ Mixed precision policy: {tf.keras.mixed_precision.global_policy().name}")
        return True

    except Exception as e:
        print(f"‚ùå GPU computation test failed: {e}")
        return False
    # =========================
# FORCE GPU VERIFICATION
# =========================
def force_gpu_usage():
    """Force TensorFlow to use GPU"""
    print("\nüîç Force GPU Usage Verification...")

    # List all devices
    devices = tf.config.get_visible_devices()
    print("Visible devices:")
    for device in devices:
        print(f"  - {device}")

    # Force GPU placement
    with tf.device('/gpu:0'):
        a = tf.random.normal((1000, 1000))
        b = tf.random.normal((1000, 1000))
        c = tf.matmul(a, b)
        print(f"‚úÖ GPU Matrix multiplication: {c.device}")

        # Check if it's really on GPU
        if 'GPU' in c.device:
            print("üéâ SUCCESS: TensorFlow is using GPU!")
            return True
        else:
            print("‚ùå WARNING: TensorFlow is not using GPU")
            return False


# -------------------------
# Usage
# -------------------------
if __name__ == "__main__":
    # ========= SAFETY SHIMS (kept inside __main__ so upstream NameErrors don‚Äôt crash the run) =========
    # Keras symbols some of your builders use
    try:
        # Core containers
        from tensorflow.keras import Sequential, Model

        # Frequently used layers (2D + 3D + misc)
        from tensorflow.keras.layers import (
            Input, Dense, Flatten, Reshape,
            Conv2D, Conv3D, Conv2DTranspose, Conv3DTranspose,
            MaxPooling2D, MaxPooling3D, UpSampling2D, UpSampling3D,
            BatchNormalization, LayerNormalization,
            Activation, ReLU, LeakyReLU,
            Dropout, SpatialDropout3D,
            Add, Multiply, Concatenate,
            GlobalAveragePooling2D, GlobalAveragePooling3D,
            ZeroPadding3D, Cropping3D
        )

        # Optims
        from tensorflow.keras.optimizers import Adam, RMSprop

    except Exception as _e:
        # Minimal emergency fallbacks so NameError won't crash
        from tensorflow.keras import Input  # noqa
        from tensorflow.keras.layers import Activation, ReLU, LeakyReLU  # noqa
        from tensorflow.keras.optimizers import Adam  # noqa

    # Minimal U-Net fallback used by your trainer on failure
    if 'create_minimal_unet' not in globals():
        def create_minimal_unet(input_size=(64, 64, 1), num_classes=5):
            inputs = Input(input_size)
            x = tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu')(inputs)
            x = tf.keras.layers.MaxPooling2D()(x)
            x = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')(x)
            x = tf.keras.layers.UpSampling2D()(x)
            out = tf.keras.layers.Conv2D(num_classes, 1, activation='softmax', dtype='float32')(x)
            model = tf.keras.Model(inputs, out)
            model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),
                          loss='categorical_crossentropy',
                          metrics=['accuracy'])
            return model

    # Final ‚Äúskip and continue‚Äù stub so exception paths don‚Äôt crash
    if 'skip_problematic_training_and_continue' not in globals():
        def skip_problematic_training_and_continue():
            class _Dummy: pass
            d = _Dummy()
            d.model = None
            return d

    # GPU helpers (light-weight versions if not already defined)
    if 'force_gpu_detection' not in globals():
        def force_gpu_detection(verbose=True):
            try:
                gpus = tf.config.list_physical_devices('GPU')
                if verbose:
                    print("üìã All physical devices:")
                    for d in tf.config.list_physical_devices():
                        print(f"  - {d}")
                    print(f"üéØ GPU devices detected: {len(gpus)}")
                if gpus:
                    for g in gpus:
                        try: tf.config.experimental.set_memory_growth(g, True)
                        except Exception: pass
                    try:
                        with tf.device('/GPU:0'):
                            a = tf.random.normal((256, 256))
                            b = tf.random.normal((256, 256))
                            _ = tf.reduce_sum(tf.matmul(a, b)).numpy()
                        if verbose: print("‚úÖ GPU detection & test OK")
                        return True
                    except Exception as e:
                        if verbose: print(f"‚ö†Ô∏è GPU visible but test failed: {e}")
                        return False
                else:
                    if verbose: print("‚ÑπÔ∏è No GPU detected")
                    return False
            except Exception as e:
                if verbose: print(f"‚ö†Ô∏è force_gpu_detection error: {e}")
                return False

    if 'setup_gpu_strategy' not in globals():
        def setup_gpu_strategy():
            try:
                gpus = tf.config.list_physical_devices('GPU')
                if gpus:
                    for g in gpus:
                        try: tf.config.experimental.set_memory_growth(g, True)
                        except Exception: pass
                    strat = tf.distribute.OneDeviceStrategy("/GPU:0")
                    pol = tf.keras.mixed_precision.Policy('float32')  # stay float32 to avoid stalls on some Windows builds
                    tf.keras.mixed_precision.set_global_policy(pol)
                    print(f"‚úÖ Strategy: {strat}; precision: {pol.name}")
                    return strat
            except Exception as e:
                print(f"‚ö†Ô∏è setup_gpu_strategy fallback to CPU: {e}")
            strat = tf.distribute.OneDeviceStrategy("/CPU:0")
            pol = tf.keras.mixed_precision.Policy('float32')
            tf.keras.mixed_precision.set_global_policy(pol)
            print(f"‚úÖ Strategy: {strat}; precision: {pol.name}")
            return strat

    if 'verify_gpu_setup' not in globals():
        def verify_gpu_setup():
            print("\nüîç Final GPU Setup Verification...")
            gpus = tf.config.list_physical_devices('GPU')
            if not gpus:
                print("‚ùå CRITICAL: No GPU detected!")
                return False
            print(f"‚úÖ GPU detected: {len(gpus)} device(s)")
            try:
                with tf.device('/GPU:0'):
                    a = tf.random.normal((1000, 1000))
                    b = tf.random.normal((1000, 1000))
                    _ = tf.reduce_sum(tf.matmul(a, b))
                print("‚úÖ GPU computation test passed")
                print(f"‚úÖ Mixed precision policy: {tf.keras.mixed_precision.global_policy().name}")
                return True
            except Exception as e:
                print(f"‚ùå GPU computation test failed: {e}")
                return False

    if 'validate_abaqus_file' not in globals():
        def validate_abaqus_file(path):
            try:
                ok = quick_inp_sanity(path) if 'quick_inp_sanity' in globals() else True
                print("‚úÖ Abaqus file validation passed" if ok else "‚ö†Ô∏è Abaqus file needs attention")
                return ok
            except Exception as e:
                print(f"‚ö†Ô∏è Validation skipped: {e}")
                return False

    if 'export_visuals' not in globals():
        def export_visuals(vol, out_dir, prefix="volume"):
            os.makedirs(out_dir, exist_ok=True)
            midz = vol.shape[2]//2 if vol.ndim==3 else 0
            img = (np.clip(vol[..., midz] if vol.ndim==3 else vol, 0, 1)*255).astype(np.uint8)
            out = os.path.join(out_dir, f"{prefix}_preview.png")
            cv2.imwrite(out, img)
            print(f"üñºÔ∏è Saved preview: {out}")

    if 'estimate_achieved_composition' not in globals():
        def estimate_achieved_composition(volume):
            v = (volume - volume.min())/(volume.max()-volume.min()+1e-8)
            qs = np.percentile(v, [20,40,60,80])
            bins = [v <= qs[0],
                    (v>qs[0])&(v<=qs[1]),
                    (v>qs[1])&(v<=qs[2]),
                    (v>qs[2])&(v<=qs[3]),
                    (v>qs[3])]
            names = ["Silicates","Carbonate","Clay","Kerogen","Others"]
            return {n: float(b.sum()/v.size) for n,b in zip(names,bins)}

    # Tiny SliceGAN fallback so generate_final_3d_volume can proceed even if training skipped
    def build_tiny_slicegan(latent_dim=128, base=16):
        """Very small 3D generator: z -> (64,64,64,1) in [-1,1] via tanh."""
        z = Input((latent_dim,))
        x = Dense(base*base*base*64, activation='relu')(z)
        x = Reshape((base, base, base, 64))(x)              # 16^3
        x = Conv3DTranspose(64, 3, strides=2, padding='same', activation='relu')(x)  # 32^3
        x = BatchNormalization()(x)
        x = Conv3DTranspose(32, 3, strides=2, padding='same', activation='relu')(x)  # 64^3
        x = BatchNormalization()(x)
        x = Conv3D(16, 3, padding='same', activation='relu')(x)
        out = Conv3D(1, 1, activation='tanh')(x)
        gen = tf.keras.Model(z, out, name="tiny_sliceGAN_generator")
        class _Tiny:
            pass
        m = _Tiny()
        m.latent_dim = latent_dim
        m.generator = gen
        return m

    # ========= ORIGINAL MAIN FLOW =========
    print("=" * 60)
    print("üéØ GPU ACCELERATION CHECK")
    print("=" * 60)

    # Force GPU detection
    gpu_available = force_gpu_detection()

    if not gpu_available:
        print("‚ùå WARNING: Running on CPU - performance will be slow!")
        print("üí° Tips to enable GPU:")
        print("   ‚Ä¢ Install CUDA 11.8 and cuDNN 8.6")
        print("   ‚Ä¢ Update NVIDIA drivers")
        print("   ‚Ä¢ Check tensorflow-gpu installation")
    else:
        print("‚úÖ GPU acceleration enabled!")

    # Setup GPU strategy
    strategy = setup_gpu_strategy()
    if verify_gpu_setup():
        print("üéâ GPU setup verified! Starting main pipeline...")
    else:
        print("‚ö†Ô∏è  GPU setup issues detected. Pipeline may run slowly.")

    base_path = r"C:\Users\Á∫¢Á±≥\Desktop\Files"
    excel_filename = "Mineral_quant_all_samples.xlsx"
    sample_mapping = {
        '1': 'sample1', '2': 'sample2', '3': 'sample3', '4': 'sample4',
        '5': 'sample5', '6': 'sample6', '7': 'sample7', '8': 'sample8'
    }

    # Usage:
    #   python this_script.py 3      -> processes sample3
    #   or set env SAMPLE_ID=3
    arg_sample_id = None
    if len(sys.argv) >= 2 and sys.argv[1].isdigit():
        arg_sample_id = sys.argv[1]
    else:
        arg_sample_id = os.environ.get("SAMPLE_ID", "1")

    if arg_sample_id not in sample_mapping:
        raise SystemExit("‚ùå Provide a sample number 1-8 (argv or env SAMPLE_ID).")

    sample_to_process = sample_mapping[arg_sample_id]
    print("=" * 60)
    print(f"‚ö° PROCESSING ONE SAMPLE ONLY: {sample_to_process}")
    print("=" * 60)

    excel_absolute_path = os.path.join(base_path, excel_filename)
    out_root = os.path.join(base_path, "output", sample_to_process)
    os.makedirs(out_root, exist_ok=True)

    # 0) Ensure folders
    dirs = ensure_project_dirs(base_path)

    start_time = time.time()
    try:
        # 1) Train ULTRA-FAST on this single sample
        trainer = TensorFlowShaleTrainer(base_path, excel_absolute_path)
        models = trainer.train_ultra_fast(sample_name=sample_to_process,
                                          epochs_unet=2, epochs_dcgan=2, epochs_slicegan=2)

        # === HARDENING: guarantee a usable SliceGAN-like object ===
        slicegan_model = None
        if isinstance(models, dict):
            slicegan_model = models.get('slicegan')

        need_tiny = (
            slicegan_model is None or
            not hasattr(slicegan_model, 'latent_dim') or
            not hasattr(slicegan_model, 'generator') or
            slicegan_model.generator is None
        )
        if need_tiny:
            print("‚ö†Ô∏è SliceGAN missing or incomplete ‚Üí building TinySliceGAN fallback.")
            slicegan_model = build_tiny_slicegan(latent_dim=128, base=16)
            if isinstance(models, dict):
                models['slicegan'] = slicegan_model

        # 2) Generate final closed 3D volume + Abaqus INP
        try:
            mineral_processor = AdvancedMineralProcessor(excel_absolute_path)
            mineral_processor.load_and_parse_excel()
        except Exception as e:
            print(f"‚ö†Ô∏è AdvancedMineralProcessor unavailable ({e}); using lightweight defaults")
            class _MP:
                def get_sample_composition(self, s):
                    return {'five_phase_area': {"Silicates":40,"Carbonate":20,"Clay":25,"Kerogen":10,"Others":5}}
            mineral_processor = _MP()

        volume, properties = generate_final_3d_volume(
            slicegan_model, mineral_processor, sample_to_process,
            num_volumes=1, save_path=out_root, target_size=(128, 128, 128)
        )

        # ---- Color export + viz + composition analysis ----
        try:
            palette = MineralPalette(base_path)
            palette.try_extract_from_folder(sample_to_process)
            color_tools = ColorAndExportTools(base_path, palette)
            extra_viz = ExtraVisualizer(base_path)
            vol_viz = Simple3DVisualizer(base_path)

            # Colored slices + label TIFF stack
            color_tools.save_colored_center_slices(volume, f"{sample_to_process}_realistic")
            color_tools.save_tiff_stack_labels(volume, f"{sample_to_process}_realistic")

            # Orthogrid slices & 3D volume visualization
            extra_viz.orthogrid(volume, f"{sample_to_process}_realistic", n=8)
            vol_viz.create_3d_volume_visualization(volume, f"{sample_to_process}_realistic")
        except Exception as e:
            print(f"‚ö†Ô∏è Visualization tools unavailable ({e}); continuing with core outputs only")

        # Composition radar
        try:
            mineral_processor_for_comp = AdvancedMineralProcessor(excel_absolute_path)
            mineral_processor_for_comp.load_and_parse_excel()
            target_comp = mineral_processor_for_comp.get_sample_composition(sample_to_process).get('five_phase_area', {})
        except Exception:
            target_comp = {'Silicates':40,'Carbonate':20,'Clay':25,'Kerogen':10,'Others':5}
        achieved_comp = estimate_achieved_composition(volume)
        try:
            extra_viz.composition_radar(target_comp, achieved_comp, f"{sample_to_process}_realistic")
        except Exception:
            pass

        # ===== VALIDATION AND QUALITY CHECKS =====
        abaqus_file = os.path.join(dirs["abaqus"], f"3d_volume_{sample_to_process}_realistic.inp")
        if os.path.exists(abaqus_file):
            validate_abaqus_file(abaqus_file)
        else:
            print("‚ö†Ô∏è Abaqus file not found for validation")
            try:
                print("üîÑ Attempting to recreate Abaqus file...")
                threshold_value = float(np.percentile(volume, 60))
                mat = {"E": float(properties.get('equivalent_youngs_modulus', 30.0)),
                       "nu": 0.25,
                       "rho": float(properties.get('equivalent_density', 2.5) * 1e-9)}
                export_hex_voxel_inp(volume, abaqus_file, voxel_step=2, threshold=threshold_value, material=mat)
                if os.path.exists(abaqus_file):
                    validate_abaqus_file(abaqus_file)
            except Exception as e:
                print(f"‚ùå Failed to recreate Abaqus file: {e}")

        # Save high-quality visualizations
        print("üé® Generating high-quality visualizations...")
        export_visuals(volume, dirs["Visualisations"], prefix=f"3d_volume_{sample_to_process}_realistic")

        # Create comparison with original SEM
        try:
            if 'create_realistic_sem_data' in globals():
                original_patches_nn = create_realistic_sem_data(sample_to_process, base_path, num_samples=16, patch_size=64)
                orig_vis = (original_patches_nn*0.5+0.5)[...,0]
                save_png_grid(orig_vis, grid=(4, 4), tile_size=64,
                              out_path=os.path.join(dirs["Visualisations"], f"{sample_to_process}_original_sem.png"))
                print(f"üíæ Saved original SEM comparison")
        except Exception as e:
            print(f"‚ö†Ô∏è Could not create original SEM comparison: {e}")

        # Ensure TIFF stack is saved
        tiff_stack_file = os.path.join(dirs["tiff_stack"], f"3d_volume_{sample_to_process}_realistic.tiff")
        if not os.path.exists(tiff_stack_file):
            print("üîÑ Saving TIFF stack...")
            try:
                tifffile.imwrite(tiff_stack_file, (volume * 65535).astype(np.uint16))
                print(f"üíæ Saved TIFF stack: {tiff_stack_file}")
            except Exception as e:
                print(f"‚ùå Failed to save TIFF stack: {e}")

        # 3) Save artifacts & visuals
        try:
            save_training_artifacts(models, [volume], [properties.get('equivalent_youngs_modulus', 0.0)], save_path=out_root)
        except Exception as e:
            print(f"‚ö†Ô∏è Could not save training artifacts: {e}")
        try:
            visualize_results(models, outdir=os.path.join(r"C:\Users\Á∫¢Á±≥\Desktop\Files\output\sample1", "plots"), show=False)
        except Exception as e:
            print(f"‚ö†Ô∏è visualize_results failed: {e}")

        # ===== ADD FOLDER VERIFICATION HERE =====
        print("\nüîç Verifying output files...")
        output_folders = ['Training_Data', 'Visualisations', 'tiff_stack', 'abaqus']
        for folder in output_folders:
            folder_path = os.path.join(base_path, folder)
            if os.path.exists(folder_path):
                files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]
                print(f"üìÅ {folder}: {len(files)} files")
                for file in files[:5]:
                    print(f"   ‚Ä¢ {file}")
                if len(files) > 5:
                    print(f"   ‚Ä¢ ... and {len(files) - 5} more")
            else:
                print(f"‚ùå {folder}: Folder not found")

        # Verify specific critical files
        critical_files = [
            os.path.join(dirs["tiff_stack"], f"3d_volume_{sample_to_process}_realistic.tiff"),
            os.path.join(dirs["abaqus"], f"3d_volume_{sample_to_process}_realistic.inp"),
            os.path.join(dirs["Training_Data"], f"{sample_to_process}_patches.npz")
        ]

        print("\nüîç Checking critical files:")
        for file_path in critical_files:
            if os.path.exists(file_path):
                size_mb = os.path.getsize(file_path) / (1024 * 1024)
                print(f"‚úÖ {os.path.basename(file_path)}: {size_mb:.2f} MB")
            else:
                print(f"‚ùå {os.path.basename(file_path)}: NOT FOUND")

        print("\n" + "=" * 80)
        print("üéØ SINGLE-SAMPLE PIPELINE COMPLETED")
        print("=" * 80)
        print(f"‚è±Ô∏è  Time: {time.time() - start_time:.1f}s")
        print(f"üìÅ Outputs:")
        print(f"    ‚Ä¢ Training data: {dirs['Training_Data']}")
        print(f"    ‚Ä¢ Visuals:       {dirs['Visualisations']}")
        print(f"    ‚Ä¢ TIFF stacks:   {dirs['tiff_stack']}")
        print(f"    ‚Ä¢ Abaqus INP:    {os.path.join(base_path, 'abaqus')}")
        print(f"    ‚Ä¢ Sample output: {out_root}")

    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
